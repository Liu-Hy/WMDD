r_bn:  3.0
lr:  0.25
bc loaded
bc shape (10, 1, 512)
getting batchnorm for class 0
getting batchnorm for class 1
getting batchnorm for class 2
getting batchnorm for class 3
getting batchnorm for class 4
getting batchnorm for class 5
getting batchnorm for class 6
getting batchnorm for class 7
getting batchnorm for class 8
getting batchnorm for class 9
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Execution time for computing per-class batchnorm statistics: 46.292680 seconds
get_images call
class_per_batch  10 batch_size  100 args.ipc  1
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
start_cls 0 end_cls 10
Length of input 10 is different from effective batch size 10
------------iteration 0----------
total loss 6619.127171404368
main criterion 31.144749529368042
weighted_aux_loss 6587.982421875
loss_r_bn_feature 2195.994140625
------------iteration 100----------
total loss 1276.1513111683666
main criterion 11.793034801179186
weighted_aux_loss 1264.3582763671875
loss_r_bn_feature 421.4527587890625
------------iteration 200----------
total loss 1186.3430241390467
main criterion 9.6898258968593
weighted_aux_loss 1176.6531982421875
loss_r_bn_feature 392.2177429199219
------------iteration 300----------
total loss 1281.6998374688085
main criterion 9.418099187558393
weighted_aux_loss 1272.28173828125
loss_r_bn_feature 424.0939025878906
------------iteration 400----------
total loss 1768.6943113720304
main criterion 12.363012543905342
weighted_aux_loss 1756.331298828125
loss_r_bn_feature 585.4437866210938
------------iteration 500----------
total loss 1190.9593231925974
main criterion 9.252047801972381
weighted_aux_loss 1181.707275390625
loss_r_bn_feature 393.90240478515625
------------iteration 600----------
total loss 1259.8289371751898
main criterion 10.879230143939775
weighted_aux_loss 1248.94970703125
loss_r_bn_feature 416.3165588378906
------------iteration 700----------
total loss 1159.7002369978225
main criterion 8.582561216572548
weighted_aux_loss 1151.11767578125
loss_r_bn_feature 383.70587158203125
------------iteration 800----------
total loss 1404.929032302452
main criterion 10.229691482139469
weighted_aux_loss 1394.6993408203125
loss_r_bn_feature 464.8997802734375
------------iteration 900----------
total loss 920.3014552298355
main criterion 8.359804839210447
weighted_aux_loss 911.941650390625
loss_r_bn_feature 303.9805603027344
------------iteration 1000----------
total loss 826.3330220316675
main criterion 7.878920469167524
weighted_aux_loss 818.4541015625
loss_r_bn_feature 272.8180236816406
------------iteration 1100----------
total loss 1146.9649654859745
main criterion 8.951903962536996
weighted_aux_loss 1138.0130615234375
loss_r_bn_feature 379.3376770019531
------------iteration 1200----------
total loss 1093.6655143709236
main criterion 10.136095425611105
weighted_aux_loss 1083.5294189453125
loss_r_bn_feature 361.1764831542969
------------iteration 1300----------
total loss 756.161391708142
main criterion 7.178359481579464
weighted_aux_loss 748.9830322265625
loss_r_bn_feature 249.6610107421875
------------iteration 1400----------
total loss 808.7585105713507
main criterion 7.609828930725718
weighted_aux_loss 801.148681640625
loss_r_bn_feature 267.049560546875
------------iteration 1500----------
total loss 591.5977142929223
main criterion 6.707455503859785
weighted_aux_loss 584.8902587890625
loss_r_bn_feature 194.96340942382812
------------iteration 1600----------
total loss 525.4192163548461
main criterion 5.8807642064085615
weighted_aux_loss 519.5384521484375
loss_r_bn_feature 173.17947387695312
------------iteration 1700----------
total loss 1777.93062765402
main criterion 14.168420622769988
weighted_aux_loss 1763.76220703125
loss_r_bn_feature 587.9207153320312
------------iteration 1800----------
total loss 596.0132907302619
main criterion 6.532455769324374
weighted_aux_loss 589.4808349609375
loss_r_bn_feature 196.49362182617188
------------iteration 1900----------
total loss 734.2742253952297
main criterion 7.749262016323474
weighted_aux_loss 726.5249633789062
loss_r_bn_feature 242.17498779296875
=> using pytorch pre-trained model 'resnet18'
process data from ../recover/syn_data/imagenette/310
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 1/300 [00:01<07:45,  1.56s/it]  1%|          | 2/300 [00:01<04:24,  1.13it/s]  1%|          | 3/300 [00:02<03:18,  1.50it/s]  1%|▏         | 4/300 [00:02<02:48,  1.76it/s]  2%|▏         | 5/300 [00:03<02:32,  1.94it/s]  2%|▏         | 6/300 [00:03<02:22,  2.06it/s]  2%|▏         | 7/300 [00:04<02:15,  2.16it/s]  3%|▎         | 8/300 [00:04<02:10,  2.24it/s]  3%|▎         | 9/300 [00:04<02:07,  2.28it/s]  3%|▎         | 10/300 [00:05<02:04,  2.34it/s]  4%|▎         | 11/300 [00:05<02:02,  2.36it/s]  4%|▍         | 12/300 [00:06<02:01,  2.37it/s]  4%|▍         | 13/300 [00:06<02:00,  2.38it/s]  5%|▍         | 14/300 [00:06<01:59,  2.39it/s]  5%|▌         | 15/300 [00:07<01:58,  2.40it/s]  5%|▌         | 16/300 [00:07<01:58,  2.40it/s]  6%|▌         | 17/300 [00:08<01:58,  2.39it/s]  6%|▌         | 18/300 [00:08<01:57,  2.40it/s]  6%|▋         | 19/300 [00:09<01:57,  2.39it/s]  7%|▋         | 20/300 [00:09<01:56,  2.40it/s]  7%|▋         | 21/300 [00:09<01:57,  2.38it/s]  7%|▋         | 22/300 [00:10<01:56,  2.39it/s]  8%|▊         | 23/300 [00:10<01:56,  2.38it/s]  8%|▊         | 24/300 [00:11<01:55,  2.39it/s]  8%|▊         | 25/300 [00:11<01:55,  2.39it/s]  9%|▊         | 26/300 [00:12<01:55,  2.37it/s]  9%|▉         | 27/300 [00:12<01:55,  2.37it/s]  9%|▉         | 28/300 [00:12<01:55,  2.36it/s] 10%|▉         | 29/300 [00:13<01:54,  2.36it/s] 10%|█         | 30/300 [00:13<01:54,  2.35it/s] 10%|█         | 31/300 [00:14<01:53,  2.36it/s] 11%|█         | 32/300 [00:14<01:53,  2.36it/s] 11%|█         | 33/300 [00:14<01:52,  2.37it/s] 11%|█▏        | 34/300 [00:15<01:51,  2.39it/s] 12%|█▏        | 35/300 [00:15<01:51,  2.38it/s] 12%|█▏        | 36/300 [00:16<01:50,  2.39it/s] 12%|█▏        | 37/300 [00:16<01:50,  2.38it/s] 13%|█▎        | 38/300 [00:17<01:49,  2.39it/s] 13%|█▎        | 39/300 [00:17<01:49,  2.39it/s] 13%|█▎        | 40/300 [00:17<01:47,  2.41it/s] 14%|█▎        | 41/300 [00:18<01:47,  2.40it/s] 14%|█▍        | 42/300 [00:18<01:47,  2.40it/s] 14%|█▍        | 43/300 [00:19<01:47,  2.39it/s] 15%|█▍        | 44/300 [00:19<01:46,  2.39it/s] 15%|█▌        | 45/300 [00:19<01:46,  2.39it/s] 15%|█▌        | 46/300 [00:20<01:45,  2.40it/s] 16%|█▌        | 47/300 [00:20<01:45,  2.39it/s] 16%|█▌        | 48/300 [00:21<01:45,  2.39it/s] 16%|█▋        | 49/300 [00:21<01:45,  2.38it/s] 17%|█▋        | 50/300 [00:22<01:44,  2.39it/s] 17%|█▋        | 51/300 [00:22<01:44,  2.38it/s] 17%|█▋        | 52/300 [00:22<01:44,  2.38it/s] 18%|█▊        | 53/300 [00:23<01:43,  2.39it/s] 18%|█▊        | 54/300 [00:23<01:42,  2.39it/s] 18%|█▊        | 55/300 [00:24<01:43,  2.38it/s] 19%|█▊        | 56/300 [00:24<01:41,  2.39it/s] 19%|█▉        | 57/300 [00:24<01:41,  2.39it/s] 19%|█▉        | 58/300 [00:25<01:41,  2.39it/s] 20%|█▉        | 59/300 [00:25<01:40,  2.39it/s] 20%|██        | 60/300 [00:26<01:40,  2.39it/s] 20%|██        | 61/300 [00:26<01:39,  2.39it/s] 21%|██        | 62/300 [00:27<01:39,  2.39it/s] 21%|██        | 63/300 [00:27<01:38,  2.40it/s] 21%|██▏       | 64/300 [00:27<01:39,  2.38it/s] 22%|██▏       | 65/300 [00:28<01:39,  2.37it/s] 22%|██▏       | 66/300 [00:28<01:39,  2.36it/s] 22%|██▏       | 67/300 [00:29<01:38,  2.37it/s] 23%|██▎       | 68/300 [00:29<01:37,  2.37it/s] 23%|██▎       | 69/300 [00:30<01:37,  2.37it/s] 23%|██▎       | 70/300 [00:30<01:36,  2.38it/s] 24%|██▎       | 71/300 [00:30<01:36,  2.38it/s] 24%|██▍       | 72/300 [00:31<01:36,  2.37it/s] 24%|██▍       | 73/300 [00:31<01:35,  2.38it/s] 25%|██▍       | 74/300 [00:32<01:35,  2.38it/s] 25%|██▌       | 75/300 [00:32<01:34,  2.38it/s] 25%|██▌       | 76/300 [00:32<01:33,  2.39it/s] 26%|██▌       | 77/300 [00:33<01:33,  2.38it/s] 26%|██▌       | 78/300 [00:33<01:33,  2.38it/s] 26%|██▋       | 79/300 [00:34<01:33,  2.38it/s] 27%|██▋       | 80/300 [00:34<01:32,  2.37it/s] 27%|██▋       | 81/300 [00:35<01:32,  2.37it/s] 27%|██▋       | 82/300 [00:35<01:31,  2.39it/s] 28%|██▊       | 83/300 [00:35<01:31,  2.38it/s] 28%|██▊       | 84/300 [00:36<01:30,  2.39it/s] 28%|██▊       | 85/300 [00:36<01:29,  2.39it/s] 29%|██▊       | 86/300 [00:37<01:29,  2.38it/s] 29%|██▉       | 87/300 [00:37<01:29,  2.39it/s] 29%|██▉       | 88/300 [00:38<01:28,  2.39it/s] 30%|██▉       | 89/300 [00:38<01:28,  2.40it/s] 30%|███       | 90/300 [00:38<01:27,  2.39it/s] 30%|███       | 91/300 [00:39<01:27,  2.38it/s] 31%|███       | 92/300 [00:39<01:27,  2.37it/s] 31%|███       | 93/300 [00:40<01:27,  2.38it/s] 31%|███▏      | 94/300 [00:40<01:25,  2.41it/s] 32%|███▏      | 95/300 [00:40<01:24,  2.42it/s] 32%|███▏      | 96/300 [00:41<01:23,  2.45it/s] 32%|███▏      | 97/300 [00:41<01:22,  2.45it/s] 33%|███▎      | 98/300 [00:42<01:22,  2.45it/s] 33%|███▎      | 99/300 [00:42<01:21,  2.46it/s] 33%|███▎      | 100/300 [00:42<01:21,  2.46it/s] 34%|███▎      | 101/300 [00:43<01:20,  2.46it/s] 34%|███▍      | 102/300 [00:43<01:20,  2.47it/s] 34%|███▍      | 103/300 [00:44<01:19,  2.47it/s] 35%|███▍      | 104/300 [00:44<01:19,  2.46it/s] 35%|███▌      | 105/300 [00:44<01:19,  2.46it/s] 35%|███▌      | 106/300 [00:45<01:19,  2.45it/s] 36%|███▌      | 107/300 [00:45<01:18,  2.45it/s] 36%|███▌      | 108/300 [00:46<01:18,  2.45it/s] 36%|███▋      | 109/300 [00:46<01:18,  2.44it/s] 37%|███▋      | 110/300 [00:47<01:17,  2.44it/s] 37%|███▋      | 111/300 [00:47<01:16,  2.46it/s] 37%|███▋      | 112/300 [00:47<01:16,  2.46it/s] 38%|███▊      | 113/300 [00:48<01:15,  2.47it/s] 38%|███▊      | 114/300 [00:48<01:15,  2.48it/s] 38%|███▊      | 115/300 [00:49<01:15,  2.46it/s] 39%|███▊      | 116/300 [00:49<01:14,  2.47it/s] 39%|███▉      | 117/300 [00:49<01:13,  2.47it/s] 39%|███▉      | 118/300 [00:50<01:14,  2.43it/s] 40%|███▉      | 119/300 [00:50<01:14,  2.43it/s] 40%|████      | 120/300 [00:51<01:14,  2.42it/s] 40%|████      | 121/300 [00:51<01:14,  2.41it/s] 41%|████      | 122/300 [00:51<01:14,  2.40it/s] 41%|████      | 123/300 [00:52<01:14,  2.38it/s] 41%|████▏     | 124/300 [00:52<01:13,  2.38it/s] 42%|████▏     | 125/300 [00:53<01:13,  2.37it/s] 42%|████▏     | 126/300 [00:53<01:13,  2.37it/s] 42%|████▏     | 127/300 [00:54<01:12,  2.38it/s] 43%|████▎     | 128/300 [00:54<01:12,  2.36it/s] 43%|████▎     | 129/300 [00:54<01:12,  2.36it/s] 43%|████▎     | 130/300 [00:55<01:12,  2.35it/s] 44%|████▎     | 131/300 [00:55<01:11,  2.37it/s] 44%|████▍     | 132/300 [00:56<01:10,  2.37it/s] 44%|████▍     | 133/300 [00:56<01:09,  2.39it/s] 45%|████▍     | 134/300 [00:57<01:09,  2.38it/s] 45%|████▌     | 135/300 [00:57<01:09,  2.38it/s] 45%|████▌     | 136/300 [00:57<01:08,  2.39it/s] 46%|████▌     | 137/300 [00:58<01:08,  2.38it/s] 46%|████▌     | 138/300 [00:58<01:07,  2.38it/s] 46%|████▋     | 139/300 [00:59<01:07,  2.38it/s] 47%|████▋     | 140/300 [00:59<01:07,  2.38it/s] 47%|████▋     | 141/300 [00:59<01:06,  2.39it/s] 47%|████▋     | 142/300 [01:00<01:06,  2.39it/s] 48%|████▊     | 143/300 [01:00<01:05,  2.40it/s] 48%|████▊     | 144/300 [01:01<01:05,  2.39it/s] 48%|████▊     | 145/300 [01:01<01:04,  2.39it/s] 49%|████▊     | 146/300 [01:02<01:04,  2.40it/s] 49%|████▉     | 147/300 [01:02<01:04,  2.39it/s] 49%|████▉     | 148/300 [01:02<01:03,  2.39it/s] 50%|████▉     | 149/300 [01:03<01:03,  2.38it/s] 50%|█████     | 150/300 [01:03<01:02,  2.38it/s] 50%|█████     | 151/300 [01:04<01:02,  2.38it/s] 51%|█████     | 152/300 [01:04<01:02,  2.37it/s] 51%|█████     | 153/300 [01:04<01:01,  2.37it/s] 51%|█████▏    | 154/300 [01:05<01:01,  2.37it/s] 52%|█████▏    | 155/300 [01:05<01:00,  2.38it/s] 52%|█████▏    | 156/300 [01:06<01:00,  2.39it/s] 52%|█████▏    | 157/300 [01:06<00:59,  2.39it/s] 53%|█████▎    | 158/300 [01:07<00:59,  2.39it/s] 53%|█████▎    | 159/300 [01:07<00:58,  2.39it/s] 53%|█████▎    | 160/300 [01:07<00:58,  2.40it/s] 54%|█████▎    | 161/300 [01:08<00:57,  2.40it/s] 54%|█████▍    | 162/300 [01:08<00:57,  2.39it/s] 54%|█████▍    | 163/300 [01:09<00:57,  2.38it/s] 55%|█████▍    | 164/300 [01:09<00:56,  2.39it/s] 55%|█████▌    | 165/300 [01:10<00:56,  2.39it/s] 55%|█████▌    | 166/300 [01:10<00:56,  2.39it/s] 56%|█████▌    | 167/300 [01:10<00:55,  2.38it/s] 56%|█████▌    | 168/300 [01:11<00:55,  2.39it/s] 56%|█████▋    | 169/300 [01:11<00:54,  2.40it/s] 57%|█████▋    | 170/300 [01:12<00:54,  2.40it/s] 57%|█████▋    | 171/300 [01:12<00:53,  2.40it/s] 57%|█████▋    | 172/300 [01:12<00:53,  2.41it/s] 58%|█████▊    | 173/300 [01:13<00:52,  2.44it/s] 58%|█████▊    | 174/300 [01:13<00:51,  2.44it/s] 58%|█████▊    | 175/300 [01:14<00:51,  2.45it/s] 59%|█████▊    | 176/300 [01:14<00:50,  2.46it/s] 59%|█████▉    | 177/300 [01:14<00:49,  2.48it/s] 59%|█████▉    | 178/300 [01:15<00:49,  2.48it/s] 60%|█████▉    | 179/300 [01:15<00:48,  2.48it/s] 60%|██████    | 180/300 [01:16<00:48,  2.48it/s] 60%|██████    | 181/300 [01:16<00:48,  2.47it/s] 61%|██████    | 182/300 [01:16<00:47,  2.46it/s] 61%|██████    | 183/300 [01:17<00:47,  2.46it/s] 61%|██████▏   | 184/300 [01:17<00:46,  2.48it/s] 62%|██████▏   | 185/300 [01:18<00:46,  2.48it/s] 62%|██████▏   | 186/300 [01:18<00:45,  2.49it/s] 62%|██████▏   | 187/300 [01:18<00:45,  2.47it/s] 63%|██████▎   | 188/300 [01:19<00:45,  2.46it/s] 63%|██████▎   | 189/300 [01:19<00:45,  2.46it/s] 63%|██████▎   | 190/300 [01:20<00:44,  2.46it/s] 64%|██████▎   | 191/300 [01:20<00:44,  2.46it/s] 64%|██████▍   | 192/300 [01:21<00:44,  2.45it/s] 64%|██████▍   | 193/300 [01:21<00:43,  2.46it/s] 65%|██████▍   | 194/300 [01:21<00:43,  2.46it/s] 65%|██████▌   | 195/300 [01:22<00:42,  2.47it/s] 65%|██████▌   | 196/300 [01:22<00:42,  2.46it/s] 66%|██████▌   | 197/300 [01:23<00:42,  2.43it/s] 66%|██████▌   | 198/300 [01:23<00:42,  2.41it/s] 66%|██████▋   | 199/300 [01:23<00:41,  2.41it/s] 67%|██████▋   | 200/300 [01:24<00:41,  2.41it/s] 67%|██████▋   | 201/300 [01:24<00:41,  2.40it/s] 67%|██████▋   | 202/300 [01:25<00:40,  2.41it/s] 68%|██████▊   | 203/300 [01:25<00:40,  2.39it/s] 68%|██████▊   | 204/300 [01:25<00:40,  2.38it/s] 68%|██████▊   | 205/300 [01:26<00:39,  2.39it/s] 69%|██████▊   | 206/300 [01:26<00:39,  2.39it/s] 69%|██████▉   | 207/300 [01:27<00:38,  2.39it/s] 69%|██████▉   | 208/300 [01:27<00:38,  2.38it/s] 70%|██████▉   | 209/300 [01:28<00:38,  2.39it/s] 70%|███████   | 210/300 [01:28<00:37,  2.39it/s] 70%|███████   | 211/300 [01:28<00:37,  2.37it/s] 71%|███████   | 212/300 [01:29<00:37,  2.38it/s] 71%|███████   | 213/300 [01:29<00:36,  2.38it/s] 71%|███████▏  | 214/300 [01:30<00:35,  2.39it/s] 72%|███████▏  | 215/300 [01:30<00:35,  2.38it/s] 72%|███████▏  | 216/300 [01:31<00:35,  2.39it/s] 72%|███████▏  | 217/300 [01:31<00:34,  2.39it/s] 73%|███████▎  | 218/300 [01:31<00:34,  2.39it/s] 73%|███████▎  | 219/300 [01:32<00:33,  2.39it/s] 73%|███████▎  | 220/300 [01:32<00:33,  2.40it/s] 74%|███████▎  | 221/300 [01:33<00:32,  2.40it/s] 74%|███████▍  | 222/300 [01:33<00:32,  2.40it/s] 74%|███████▍  | 223/300 [01:33<00:32,  2.40it/s] 75%|███████▍  | 224/300 [01:34<00:31,  2.39it/s] 75%|███████▌  | 225/300 [01:34<00:31,  2.38it/s] 75%|███████▌  | 226/300 [01:35<00:31,  2.36it/s] 76%|███████▌  | 227/300 [01:35<00:30,  2.36it/s] 76%|███████▌  | 228/300 [01:36<00:30,  2.39it/s] 76%|███████▋  | 229/300 [01:36<00:29,  2.40it/s] 77%|███████▋  | 230/300 [01:36<00:28,  2.43it/s] 77%|███████▋  | 231/300 [01:37<00:28,  2.43it/s] 77%|███████▋  | 232/300 [01:37<00:28,  2.42it/s] 78%|███████▊  | 233/300 [01:38<00:27,  2.43it/s] 78%|███████▊  | 234/300 [01:38<00:27,  2.44it/s] 78%|███████▊  | 235/300 [01:38<00:26,  2.45it/s] 79%|███████▊  | 236/300 [01:39<00:26,  2.44it/s] 79%|███████▉  | 237/300 [01:39<00:25,  2.45it/s] 79%|███████▉  | 238/300 [01:40<00:25,  2.45it/s] 80%|███████▉  | 239/300 [01:40<00:24,  2.46it/s] 80%|████████  | 240/300 [01:40<00:24,  2.46it/s] 80%|████████  | 241/300 [01:41<00:23,  2.47it/s] 81%|████████  | 242/300 [01:41<00:23,  2.48it/s] 81%|████████  | 243/300 [01:42<00:23,  2.47it/s] 81%|████████▏ | 244/300 [01:42<00:22,  2.47it/s] 82%|████████▏ | 245/300 [01:42<00:22,  2.48it/s] 82%|████████▏ | 246/300 [01:43<00:21,  2.48it/s] 82%|████████▏ | 247/300 [01:43<00:21,  2.48it/s] 83%|████████▎ | 248/300 [01:44<00:21,  2.46it/s] 83%|████████▎ | 249/300 [01:44<00:20,  2.47it/s] 83%|████████▎ | 250/300 [01:44<00:20,  2.46it/s] 84%|████████▎ | 251/300 [01:45<00:19,  2.47it/s] 84%|████████▍ | 252/300 [01:45<00:19,  2.44it/s] 84%|████████▍ | 253/300 [01:46<00:19,  2.42it/s] 85%|████████▍ | 254/300 [01:46<00:19,  2.41it/s] 85%|████████▌ | 255/300 [01:47<00:18,  2.41it/s] 85%|████████▌ | 256/300 [01:47<00:18,  2.40it/s] 86%|████████▌ | 257/300 [01:47<00:17,  2.39it/s] 86%|████████▌ | 258/300 [01:48<00:17,  2.40it/s] 86%|████████▋ | 259/300 [01:48<00:17,  2.39it/s] 87%|████████▋ | 260/300 [01:49<00:16,  2.38it/s] 87%|████████▋ | 261/300 [01:49<00:16,  2.38it/s] 87%|████████▋ | 262/300 [01:50<00:16,  2.37it/s] 88%|████████▊ | 263/300 [01:50<00:15,  2.38it/s] 88%|████████▊ | 264/300 [01:50<00:15,  2.40it/s] 88%|████████▊ | 265/300 [01:51<00:14,  2.39it/s] 89%|████████▊ | 266/300 [01:51<00:14,  2.40it/s] 89%|████████▉ | 267/300 [01:52<00:13,  2.39it/s] 89%|████████▉ | 268/300 [01:52<00:13,  2.37it/s] 90%|████████▉ | 269/300 [01:52<00:13,  2.38it/s] 90%|█████████ | 270/300 [01:53<00:12,  2.38it/s] 90%|█████████ | 271/300 [01:53<00:12,  2.37it/s] 91%|█████████ | 272/300 [01:54<00:11,  2.38it/s] 91%|█████████ | 273/300 [01:54<00:11,  2.37it/s] 91%|█████████▏| 274/300 [01:55<00:10,  2.38it/s] 92%|█████████▏| 275/300 [01:55<00:10,  2.38it/s] 92%|█████████▏| 276/300 [01:55<00:10,  2.39it/s] 92%|█████████▏| 277/300 [01:56<00:09,  2.38it/s] 93%|█████████▎| 278/300 [01:56<00:09,  2.38it/s] 93%|█████████▎| 279/300 [01:57<00:08,  2.38it/s] 93%|█████████▎| 280/300 [01:57<00:08,  2.38it/s] 94%|█████████▎| 281/300 [01:57<00:08,  2.37it/s] 94%|█████████▍| 282/300 [01:58<00:07,  2.39it/s] 94%|█████████▍| 283/300 [01:58<00:07,  2.39it/s] 95%|█████████▍| 284/300 [01:59<00:06,  2.38it/s] 95%|█████████▌| 285/300 [01:59<00:06,  2.39it/s] 95%|█████████▌| 286/300 [02:00<00:05,  2.40it/s] 96%|█████████▌| 287/300 [02:00<00:05,  2.40it/s] 96%|█████████▌| 288/300 [02:00<00:05,  2.39it/s] 96%|█████████▋| 289/300 [02:01<00:04,  2.39it/s] 97%|█████████▋| 290/300 [02:01<00:04,  2.38it/s] 97%|█████████▋| 291/300 [02:02<00:03,  2.39it/s] 97%|█████████▋| 292/300 [02:02<00:03,  2.39it/s] 98%|█████████▊| 293/300 [02:03<00:02,  2.39it/s] 98%|█████████▊| 294/300 [02:03<00:02,  2.39it/s] 98%|█████████▊| 295/300 [02:03<00:02,  2.40it/s] 99%|█████████▊| 296/300 [02:04<00:01,  2.40it/s] 99%|█████████▉| 297/300 [02:04<00:01,  2.39it/s] 99%|█████████▉| 298/300 [02:05<00:00,  2.39it/s]100%|█████████▉| 299/300 [02:05<00:00,  2.40it/s]100%|██████████| 300/300 [02:05<00:00,  2.39it/s]100%|██████████| 300/300 [02:05<00:00,  2.38it/s]
W&B disabled.
W&B online. Running your script from this directory will now sync to the cloud.
wandb: Currently logged in as: hl57. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /media/techt/One Touch/DD/SRe2L/train/wandb/run-20231023_134624-o7zlv2ye
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sky-488
wandb: ⭐️ View project at https://wandb.ai/hl57/final_rn18_fkd
wandb: 🚀 View run at https://wandb.ai/hl57/final_rn18_fkd/runs/o7zlv2ye
======= FKD: dataset info ======
path: ../relabel/FKD_cutmix_fp16/imagenette/310/
num img: 10
batch size: 10
max epoch: 300
================================
load data successfully
=> loading student model 'resnet18'
TRAIN Iter 0: lr = 0.001000,	loss = 0.016285,	Top-1 err = 90.000000,	Top-5 err = 60.000000,	train_time = 3.013928
TEST Iter 0: loss = 20.973442,	Top-1 err = 89.324841,	Top-5 err = 50.063694,	val_time = 15.517563
TRAIN Iter 10: lr = 0.000997,	loss = 0.013876,	Top-1 err = 80.000000,	Top-5 err = 30.000000,	train_time = 2.156772
TEST Iter 10: loss = 23.955328,	Top-1 err = 85.834395,	Top-5 err = 42.828025,	val_time = 15.803333
TRAIN Iter 20: lr = 0.000989,	loss = 0.016366,	Top-1 err = 30.000000,	Top-5 err = 0.000000,	train_time = 2.123968
TEST Iter 20: loss = 52.565349,	Top-1 err = 86.573248,	Top-5 err = 42.573248,	val_time = 15.553114
TRAIN Iter 30: lr = 0.000976,	loss = 0.007441,	Top-1 err = 80.000000,	Top-5 err = 20.000000,	train_time = 2.081437
TEST Iter 30: loss = 26.268488,	Top-1 err = 84.993631,	Top-5 err = 40.662420,	val_time = 15.569057
TRAIN Iter 40: lr = 0.000957,	loss = 0.006401,	Top-1 err = 40.000000,	Top-5 err = 10.000000,	train_time = 2.114356
TEST Iter 40: loss = 24.438295,	Top-1 err = 82.802548,	Top-5 err = 41.656051,	val_time = 15.589698
TRAIN Iter 50: lr = 0.000933,	loss = 0.007997,	Top-1 err = 30.000000,	Top-5 err = 0.000000,	train_time = 2.113671
TEST Iter 50: loss = 12.404006,	Top-1 err = 78.420382,	Top-5 err = 38.420382,	val_time = 15.594713
TRAIN Iter 60: lr = 0.000905,	loss = 0.007644,	Top-1 err = 50.000000,	Top-5 err = 0.000000,	train_time = 2.089786
TEST Iter 60: loss = 9.776548,	Top-1 err = 75.668790,	Top-5 err = 31.159236,	val_time = 15.627191
TRAIN Iter 70: lr = 0.000872,	loss = 0.006245,	Top-1 err = 80.000000,	Top-5 err = 10.000000,	train_time = 2.139614
TEST Iter 70: loss = 10.831563,	Top-1 err = 78.496815,	Top-5 err = 33.401274,	val_time = 15.476022
TRAIN Iter 80: lr = 0.000835,	loss = 0.008199,	Top-1 err = 50.000000,	Top-5 err = 10.000000,	train_time = 2.165260
TEST Iter 80: loss = 12.717519,	Top-1 err = 80.840764,	Top-5 err = 40.662420,	val_time = 15.779027
TRAIN Iter 90: lr = 0.000794,	loss = 0.004995,	Top-1 err = 20.000000,	Top-5 err = 0.000000,	train_time = 2.144247
TEST Iter 90: loss = 10.856770,	Top-1 err = 78.496815,	Top-5 err = 36.789809,	val_time = 15.781297
TRAIN Iter 100: lr = 0.000750,	loss = 0.004551,	Top-1 err = 90.000000,	Top-5 err = 10.000000,	train_time = 2.138529
TEST Iter 100: loss = 10.845437,	Top-1 err = 75.363057,	Top-5 err = 32.560510,	val_time = 15.665942
TRAIN Iter 110: lr = 0.000703,	loss = 0.006580,	Top-1 err = 10.000000,	Top-5 err = 0.000000,	train_time = 2.158864
TEST Iter 110: loss = 11.699841,	Top-1 err = 75.006369,	Top-5 err = 32.764331,	val_time = 15.510303
TRAIN Iter 120: lr = 0.000655,	loss = 0.004186,	Top-1 err = 10.000000,	Top-5 err = 0.000000,	train_time = 2.113263
TEST Iter 120: loss = 10.075331,	Top-1 err = 73.732484,	Top-5 err = 30.140127,	val_time = 15.421428
TRAIN Iter 130: lr = 0.000604,	loss = 0.003575,	Top-1 err = 80.000000,	Top-5 err = 0.000000,	train_time = 2.103951
TEST Iter 130: loss = 9.701496,	Top-1 err = 73.095541,	Top-5 err = 30.445860,	val_time = 15.690354
TRAIN Iter 140: lr = 0.000552,	loss = 0.004402,	Top-1 err = 90.000000,	Top-5 err = 30.000000,	train_time = 2.130241
TEST Iter 140: loss = 10.561955,	Top-1 err = 75.592357,	Top-5 err = 34.598726,	val_time = 15.732406
TRAIN Iter 150: lr = 0.000500,	loss = 0.005068,	Top-1 err = 90.000000,	Top-5 err = 20.000000,	train_time = 2.217298
TEST Iter 150: loss = 8.386672,	Top-1 err = 73.121019,	Top-5 err = 28.636943,	val_time = 15.480433
TRAIN Iter 160: lr = 0.000448,	loss = 0.003025,	Top-1 err = 10.000000,	Top-5 err = 0.000000,	train_time = 2.113918
TEST Iter 160: loss = 13.398933,	Top-1 err = 76.917197,	Top-5 err = 31.439490,	val_time = 15.512216
TRAIN Iter 170: lr = 0.000396,	loss = 0.003941,	Top-1 err = 0.000000,	Top-5 err = 0.000000,	train_time = 2.074544
TEST Iter 170: loss = 8.201683,	Top-1 err = 71.566879,	Top-5 err = 27.821656,	val_time = 15.494477
TRAIN Iter 180: lr = 0.000345,	loss = 0.003865,	Top-1 err = 0.000000,	Top-5 err = 0.000000,	train_time = 2.114394
TEST Iter 180: loss = 8.925873,	Top-1 err = 72.713376,	Top-5 err = 29.197452,	val_time = 15.613204
TRAIN Iter 190: lr = 0.000297,	loss = 0.004469,	Top-1 err = 80.000000,	Top-5 err = 10.000000,	train_time = 2.068891
TEST Iter 190: loss = 6.607008,	Top-1 err = 71.261146,	Top-5 err = 25.554140,	val_time = 15.389170
TRAIN Iter 200: lr = 0.000250,	loss = 0.004063,	Top-1 err = 70.000000,	Top-5 err = 20.000000,	train_time = 2.144454
TEST Iter 200: loss = 7.232484,	Top-1 err = 73.783439,	Top-5 err = 28.025478,	val_time = 15.998710
TRAIN Iter 210: lr = 0.000206,	loss = 0.004784,	Top-1 err = 10.000000,	Top-5 err = 0.000000,	train_time = 2.084103
TEST Iter 210: loss = 7.417967,	Top-1 err = 71.490446,	Top-5 err = 26.675159,	val_time = 15.523950
TRAIN Iter 220: lr = 0.000165,	loss = 0.005280,	Top-1 err = 30.000000,	Top-5 err = 0.000000,	train_time = 2.103503
TEST Iter 220: loss = 7.377278,	Top-1 err = 69.681529,	Top-5 err = 24.891720,	val_time = 15.390791
TRAIN Iter 230: lr = 0.000128,	loss = 0.005194,	Top-1 err = 30.000000,	Top-5 err = 0.000000,	train_time = 2.109617
TEST Iter 230: loss = 7.528645,	Top-1 err = 67.821656,	Top-5 err = 23.159236,	val_time = 15.398259
TRAIN Iter 240: lr = 0.000095,	loss = 0.003523,	Top-1 err = 10.000000,	Top-5 err = 0.000000,	train_time = 2.128228
TEST Iter 240: loss = 6.878042,	Top-1 err = 66.828025,	Top-5 err = 23.439490,	val_time = 15.539917
TRAIN Iter 250: lr = 0.000067,	loss = 0.004957,	Top-1 err = 60.000000,	Top-5 err = 10.000000,	train_time = 2.186092
TEST Iter 250: loss = 6.620369,	Top-1 err = 66.292994,	Top-5 err = 23.261146,	val_time = 15.780383
TRAIN Iter 260: lr = 0.000043,	loss = 0.001716,	Top-1 err = 0.000000,	Top-5 err = 0.000000,	train_time = 2.141929
TEST Iter 260: loss = 6.716693,	Top-1 err = 65.936306,	Top-5 err = 22.955414,	val_time = 15.603705
TRAIN Iter 270: lr = 0.000024,	loss = 0.002966,	Top-1 err = 90.000000,	Top-5 err = 20.000000,	train_time = 2.094802
TEST Iter 270: loss = 6.564266,	Top-1 err = 66.165605,	Top-5 err = 22.522293,	val_time = 15.449419
TRAIN Iter 280: lr = 0.000011,	loss = 0.004703,	Top-1 err = 10.000000,	Top-5 err = 0.000000,	train_time = 2.136317
TEST Iter 280: loss = 6.636662,	Top-1 err = 66.649682,	Top-5 err = 22.853503,	val_time = 15.452679
TRAIN Iter 290: lr = 0.000003,	loss = 0.004796,	Top-1 err = 30.000000,	Top-5 err = 0.000000,	train_time = 2.122827
TEST Iter 290: loss = 6.781538,	Top-1 err = 66.471338,	Top-5 err = 23.031847,	val_time = 15.881126
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  train/Top1 ▂▂▄▂▅▆▂▅▂▆▇▇▁▆▇▇▇▃▇▇▇██▇█▇▇▇█▇▄▂▅▂█▄█▅▃▅
wandb:  train/Top5 ▁▂▇▄██▂▅████▅█████████████████▇██▇████▇█
wandb: train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  train/loss ▅▅█▆▅▆▅▄▂▂▃▃▂▃▂▃▃▃▃▂▂▂▂▂▁▂▂▂▂▂▂▃▁▂▂▁▁▂▂▂
wandb:    train/lr ███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:   val/epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███
wandb:    val/loss ▃▄█▄▄▂▁▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    val/top1 ▁▂▂▂▃▄▅▄▄▄▅▅▆▆▅▆▅▆▆▆▆▆▇▇███████
wandb:    val/top5 ▁▃▃▃▃▄▆▅▃▄▅▅▆▆▅▆▆▇▆▇▇▇▇████████
wandb: 
wandb: Run summary:
wandb:  train/Top1 60.0
wandb:  train/Top5 100.0
wandb: train/epoch 299
wandb:  train/loss 0.00348
wandb:    train/lr 0.0
wandb:   val/epoch 299
wandb:    val/loss 7.04261
wandb:    val/top1 33.07006
wandb:    val/top5 76.94268
wandb: 
wandb: 🚀 View run eager-sky-488 at: https://wandb.ai/hl57/final_rn18_fkd/runs/o7zlv2ye
wandb: ️⚡ View job at https://wandb.ai/hl57/final_rn18_fkd/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjk3MzkyNjU3/version_details/v47
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231023_134624-o7zlv2ye/logs
TEST Iter 299: loss = 7.042605,	Top-1 err = 66.929936,	Top-5 err = 23.057325,	val_time = 15.543888
