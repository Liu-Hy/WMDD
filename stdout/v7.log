/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
r_bn:  0.01
lr:  0.25
ipc_id =  0
get_images call
------------iteration 0----------
total loss 25.061511993408203
main criterion 3.022326707839966
weighted_aux_loss 22.0391845703125
loss_r_bn_feature 2203.91845703125
------------iteration 100----------
total loss 4.156110763549805
main criterion 0.17661361396312714
weighted_aux_loss 3.979496955871582
loss_r_bn_feature 397.94970703125
------------iteration 200----------
total loss 4.784183979034424
main criterion 0.01132019329816103
weighted_aux_loss 4.772863864898682
loss_r_bn_feature 477.2864074707031
------------iteration 300----------
total loss 7.324163436889648
main criterion 0.6440155506134033
weighted_aux_loss 6.680147647857666
loss_r_bn_feature 668.0147705078125
------------iteration 400----------
total loss 3.346290111541748
main criterion 0.017104430124163628
weighted_aux_loss 3.329185724258423
loss_r_bn_feature 332.9185791015625
------------iteration 500----------
total loss 2.44050931930542
main criterion 0.0030094594694674015
weighted_aux_loss 2.437499761581421
loss_r_bn_feature 243.74998474121094
------------iteration 600----------
total loss 3.1648852825164795
main criterion 0.009412373416125774
weighted_aux_loss 3.155472993850708
loss_r_bn_feature 315.54730224609375
------------iteration 700----------
total loss 2.651658058166504
main criterion 0.004644227214157581
weighted_aux_loss 2.6470139026641846
loss_r_bn_feature 264.7013854980469
------------iteration 800----------
total loss 1.935197114944458
main criterion 0.006956843193620443
weighted_aux_loss 1.9282402992248535
loss_r_bn_feature 192.82403564453125
------------iteration 900----------
total loss 2.7971835136413574
main criterion 0.018103253096342087
weighted_aux_loss 2.7790801525115967
loss_r_bn_feature 277.90802001953125
------------iteration 1000----------
total loss 2.0291595458984375
main criterion 0.005335099063813686
weighted_aux_loss 2.023824453353882
loss_r_bn_feature 202.3824462890625
------------iteration 1100----------
total loss 2.0914297103881836
main criterion 0.0008704094216227531
weighted_aux_loss 2.090559244155884
loss_r_bn_feature 209.05593872070312
------------iteration 1200----------
total loss 2.3488011360168457
main criterion 0.0008221587049774826
weighted_aux_loss 2.3479790687561035
loss_r_bn_feature 234.79791259765625
------------iteration 1300----------
total loss 1.0849875211715698
main criterion 0.000898416736163199
weighted_aux_loss 1.0840891599655151
loss_r_bn_feature 108.40892028808594
------------iteration 1400----------
total loss 1.3431792259216309
main criterion 0.00440610246732831
weighted_aux_loss 1.3387731313705444
loss_r_bn_feature 133.8773193359375
------------iteration 1500----------
total loss 2.2245967388153076
main criterion 0.005958707071840763
weighted_aux_loss 2.2186379432678223
loss_r_bn_feature 221.86380004882812
------------iteration 1600----------
total loss 0.9136379361152649
main criterion 0.0009053439134731889
weighted_aux_loss 0.9127326011657715
loss_r_bn_feature 91.27326202392578
------------iteration 1700----------
total loss 0.8237451910972595
main criterion 0.0012694757897406816
weighted_aux_loss 0.8224757313728333
loss_r_bn_feature 82.24757385253906
------------iteration 1800----------
total loss 1.353994369506836
main criterion 0.0011545817833393812
weighted_aux_loss 1.3528398275375366
loss_r_bn_feature 135.2839813232422
------------iteration 1900----------
total loss 0.5639524459838867
main criterion 0.00143436377402395
weighted_aux_loss 0.5625180602073669
loss_r_bn_feature 56.25180435180664
=> using pytorch pre-trained model 'resnet18'
process data from ../recover/syn_data/imagenette/v7
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 1/300 [00:01<07:23,  1.48s/it]  1%|          | 2/300 [00:01<03:55,  1.27it/s]  1%|          | 3/300 [00:02<02:49,  1.75it/s]  1%|▏         | 4/300 [00:02<02:18,  2.14it/s]  2%|▏         | 5/300 [00:02<02:01,  2.44it/s]  2%|▏         | 6/300 [00:03<01:50,  2.67it/s]  2%|▏         | 7/300 [00:03<01:41,  2.88it/s]  3%|▎         | 8/300 [00:03<01:36,  3.03it/s]  3%|▎         | 9/300 [00:03<01:33,  3.11it/s]  3%|▎         | 10/300 [00:04<01:30,  3.19it/s]  4%|▎         | 11/300 [00:04<01:29,  3.23it/s]  4%|▍         | 12/300 [00:04<01:28,  3.26it/s]  4%|▍         | 13/300 [00:05<01:27,  3.29it/s]  5%|▍         | 14/300 [00:05<01:26,  3.32it/s]  5%|▌         | 15/300 [00:05<01:24,  3.36it/s]  5%|▌         | 16/300 [00:05<01:23,  3.40it/s]  6%|▌         | 17/300 [00:06<01:23,  3.41it/s]  6%|▌         | 18/300 [00:06<01:22,  3.41it/s]  6%|▋         | 19/300 [00:06<01:22,  3.41it/s]  7%|▋         | 20/300 [00:07<01:21,  3.43it/s]  7%|▋         | 21/300 [00:07<01:21,  3.43it/s]  7%|▋         | 22/300 [00:07<01:21,  3.41it/s]  8%|▊         | 23/300 [00:08<01:21,  3.41it/s]  8%|▊         | 24/300 [00:08<01:21,  3.41it/s]  8%|▊         | 25/300 [00:08<01:20,  3.40it/s]  9%|▊         | 26/300 [00:08<01:20,  3.40it/s]  9%|▉         | 27/300 [00:09<01:21,  3.37it/s]  9%|▉         | 28/300 [00:09<01:20,  3.36it/s] 10%|▉         | 29/300 [00:09<01:20,  3.37it/s] 10%|█         | 30/300 [00:10<01:19,  3.39it/s] 10%|█         | 31/300 [00:10<01:18,  3.41it/s] 11%|█         | 32/300 [00:10<01:18,  3.42it/s] 11%|█         | 33/300 [00:10<01:18,  3.39it/s] 11%|█▏        | 34/300 [00:11<01:18,  3.38it/s] 12%|█▏        | 35/300 [00:11<01:18,  3.37it/s] 12%|█▏        | 36/300 [00:11<01:19,  3.33it/s] 12%|█▏        | 37/300 [00:12<01:18,  3.34it/s] 13%|█▎        | 38/300 [00:12<01:18,  3.34it/s] 13%|█▎        | 39/300 [00:12<01:18,  3.33it/s] 13%|█▎        | 40/300 [00:13<01:17,  3.34it/s] 14%|█▎        | 41/300 [00:13<01:17,  3.35it/s] 14%|█▍        | 42/300 [00:13<01:17,  3.35it/s] 14%|█▍        | 43/300 [00:13<01:16,  3.35it/s] 15%|█▍        | 44/300 [00:14<01:15,  3.38it/s] 15%|█▌        | 45/300 [00:14<01:15,  3.37it/s] 15%|█▌        | 46/300 [00:14<01:15,  3.38it/s] 16%|█▌        | 47/300 [00:15<01:14,  3.37it/s] 16%|█▌        | 48/300 [00:15<01:14,  3.37it/s] 16%|█▋        | 49/300 [00:15<01:14,  3.37it/s] 17%|█▋        | 50/300 [00:16<01:14,  3.36it/s] 17%|█▋        | 51/300 [00:16<01:13,  3.38it/s] 17%|█▋        | 52/300 [00:16<01:13,  3.38it/s] 18%|█▊        | 53/300 [00:16<01:13,  3.36it/s] 18%|█▊        | 54/300 [00:17<01:13,  3.35it/s] 18%|█▊        | 55/300 [00:17<01:12,  3.36it/s] 19%|█▊        | 56/300 [00:17<01:12,  3.35it/s] 19%|█▉        | 57/300 [00:18<01:12,  3.35it/s] 19%|█▉        | 58/300 [00:18<01:11,  3.38it/s] 20%|█▉        | 59/300 [00:18<01:11,  3.38it/s] 20%|██        | 60/300 [00:19<01:11,  3.37it/s] 20%|██        | 61/300 [00:19<01:10,  3.37it/s] 21%|██        | 62/300 [00:19<01:10,  3.36it/s] 21%|██        | 63/300 [00:19<01:10,  3.36it/s] 21%|██▏       | 64/300 [00:20<01:10,  3.37it/s] 22%|██▏       | 65/300 [00:20<01:09,  3.37it/s] 22%|██▏       | 66/300 [00:20<01:08,  3.41it/s] 22%|██▏       | 67/300 [00:21<01:07,  3.43it/s] 23%|██▎       | 68/300 [00:21<01:07,  3.45it/s] 23%|██▎       | 69/300 [00:21<01:06,  3.48it/s] 23%|██▎       | 70/300 [00:21<01:05,  3.49it/s] 24%|██▎       | 71/300 [00:22<01:05,  3.49it/s] 24%|██▍       | 72/300 [00:22<01:05,  3.47it/s] 24%|██▍       | 73/300 [00:22<01:04,  3.50it/s] 25%|██▍       | 74/300 [00:23<01:04,  3.50it/s] 25%|██▌       | 75/300 [00:23<01:04,  3.50it/s] 25%|██▌       | 76/300 [00:23<01:03,  3.51it/s] 26%|██▌       | 77/300 [00:23<01:03,  3.51it/s] 26%|██▌       | 78/300 [00:24<01:03,  3.50it/s] 26%|██▋       | 79/300 [00:24<01:03,  3.50it/s] 27%|██▋       | 80/300 [00:24<01:02,  3.50it/s] 27%|██▋       | 81/300 [00:25<01:02,  3.52it/s] 27%|██▋       | 82/300 [00:25<01:01,  3.52it/s] 28%|██▊       | 83/300 [00:25<01:02,  3.50it/s] 28%|██▊       | 84/300 [00:25<01:02,  3.46it/s] 28%|██▊       | 85/300 [00:26<01:02,  3.43it/s] 29%|██▊       | 86/300 [00:26<01:03,  3.39it/s] 29%|██▉       | 87/300 [00:26<01:04,  3.29it/s] 29%|██▉       | 88/300 [00:27<01:04,  3.28it/s] 30%|██▉       | 89/300 [00:27<01:04,  3.29it/s] 30%|███       | 90/300 [00:27<01:04,  3.27it/s] 30%|███       | 91/300 [00:28<01:03,  3.29it/s] 31%|███       | 92/300 [00:28<01:03,  3.30it/s] 31%|███       | 93/300 [00:28<01:02,  3.33it/s] 31%|███▏      | 94/300 [00:28<01:02,  3.29it/s] 32%|███▏      | 95/300 [00:29<01:03,  3.25it/s] 32%|███▏      | 96/300 [00:29<01:02,  3.27it/s] 32%|███▏      | 97/300 [00:29<01:01,  3.29it/s] 33%|███▎      | 98/300 [00:30<01:01,  3.29it/s] 33%|███▎      | 99/300 [00:30<01:00,  3.30it/s] 33%|███▎      | 100/300 [00:30<01:00,  3.33it/s] 34%|███▎      | 101/300 [00:31<00:59,  3.34it/s] 34%|███▍      | 102/300 [00:31<00:58,  3.37it/s] 34%|███▍      | 103/300 [00:31<00:57,  3.41it/s] 35%|███▍      | 104/300 [00:31<00:57,  3.44it/s] 35%|███▌      | 105/300 [00:32<00:56,  3.44it/s] 35%|███▌      | 106/300 [00:32<00:57,  3.38it/s] 36%|███▌      | 107/300 [00:32<00:58,  3.33it/s] 36%|███▌      | 108/300 [00:33<00:57,  3.34it/s] 36%|███▋      | 109/300 [00:33<00:56,  3.37it/s] 37%|███▋      | 110/300 [00:33<00:56,  3.36it/s] 37%|███▋      | 111/300 [00:34<00:56,  3.37it/s] 37%|███▋      | 112/300 [00:34<00:55,  3.36it/s] 38%|███▊      | 113/300 [00:34<00:55,  3.36it/s] 38%|███▊      | 114/300 [00:34<00:54,  3.39it/s] 38%|███▊      | 115/300 [00:35<00:54,  3.42it/s] 39%|███▊      | 116/300 [00:35<00:53,  3.45it/s] 39%|███▉      | 117/300 [00:35<00:53,  3.43it/s] 39%|███▉      | 118/300 [00:36<00:52,  3.47it/s] 40%|███▉      | 119/300 [00:36<00:52,  3.48it/s] 40%|████      | 120/300 [00:36<00:51,  3.49it/s] 40%|████      | 121/300 [00:36<00:51,  3.50it/s] 41%|████      | 122/300 [00:37<00:50,  3.51it/s] 41%|████      | 123/300 [00:37<00:50,  3.48it/s] 41%|████▏     | 124/300 [00:37<00:50,  3.47it/s] 42%|████▏     | 125/300 [00:38<00:51,  3.43it/s] 42%|████▏     | 126/300 [00:38<00:50,  3.42it/s] 42%|████▏     | 127/300 [00:38<00:50,  3.42it/s] 43%|████▎     | 128/300 [00:38<00:50,  3.38it/s] 43%|████▎     | 129/300 [00:39<00:50,  3.40it/s] 43%|████▎     | 130/300 [00:39<00:49,  3.42it/s] 44%|████▎     | 131/300 [00:39<00:49,  3.43it/s] 44%|████▍     | 132/300 [00:40<00:48,  3.46it/s] 44%|████▍     | 133/300 [00:40<00:48,  3.46it/s] 45%|████▍     | 134/300 [00:40<00:47,  3.48it/s] 45%|████▌     | 135/300 [00:41<00:47,  3.45it/s] 45%|████▌     | 136/300 [00:41<00:47,  3.47it/s] 46%|████▌     | 137/300 [00:41<00:47,  3.45it/s] 46%|████▌     | 138/300 [00:41<00:46,  3.49it/s] 46%|████▋     | 139/300 [00:42<00:46,  3.47it/s] 47%|████▋     | 140/300 [00:42<00:46,  3.48it/s] 47%|████▋     | 141/300 [00:42<00:45,  3.48it/s] 47%|████▋     | 142/300 [00:43<00:45,  3.48it/s] 48%|████▊     | 143/300 [00:43<00:44,  3.49it/s] 48%|████▊     | 144/300 [00:43<00:44,  3.49it/s] 48%|████▊     | 145/300 [00:43<00:43,  3.53it/s] 49%|████▊     | 146/300 [00:44<00:43,  3.51it/s] 49%|████▉     | 147/300 [00:44<00:43,  3.51it/s] 49%|████▉     | 148/300 [00:44<00:43,  3.53it/s] 50%|████▉     | 149/300 [00:44<00:42,  3.54it/s] 50%|█████     | 150/300 [00:45<00:42,  3.53it/s] 50%|█████     | 151/300 [00:45<00:42,  3.52it/s] 51%|█████     | 152/300 [00:45<00:43,  3.44it/s] 51%|█████     | 153/300 [00:46<00:42,  3.44it/s] 51%|█████▏    | 154/300 [00:46<00:42,  3.43it/s] 52%|█████▏    | 155/300 [00:46<00:42,  3.39it/s] 52%|█████▏    | 156/300 [00:47<00:42,  3.41it/s] 52%|█████▏    | 157/300 [00:47<00:41,  3.44it/s] 53%|█████▎    | 158/300 [00:47<00:41,  3.43it/s] 53%|█████▎    | 159/300 [00:47<00:41,  3.42it/s] 53%|█████▎    | 160/300 [00:48<00:41,  3.40it/s] 54%|█████▎    | 161/300 [00:48<00:40,  3.40it/s] 54%|█████▍    | 162/300 [00:48<00:40,  3.39it/s] 54%|█████▍    | 163/300 [00:49<00:40,  3.39it/s] 55%|█████▍    | 164/300 [00:49<00:40,  3.37it/s] 55%|█████▌    | 165/300 [00:49<00:39,  3.39it/s] 55%|█████▌    | 166/300 [00:49<00:39,  3.40it/s] 56%|█████▌    | 167/300 [00:50<00:39,  3.37it/s] 56%|█████▌    | 168/300 [00:50<00:39,  3.38it/s] 56%|█████▋    | 169/300 [00:50<00:38,  3.38it/s] 57%|█████▋    | 170/300 [00:51<00:38,  3.40it/s] 57%|█████▋    | 171/300 [00:51<00:37,  3.40it/s] 57%|█████▋    | 172/300 [00:51<00:37,  3.41it/s] 58%|█████▊    | 173/300 [00:52<00:37,  3.39it/s] 58%|█████▊    | 174/300 [00:52<00:36,  3.41it/s] 58%|█████▊    | 175/300 [00:52<00:36,  3.39it/s] 59%|█████▊    | 176/300 [00:52<00:36,  3.37it/s] 59%|█████▉    | 177/300 [00:53<00:36,  3.39it/s] 59%|█████▉    | 178/300 [00:53<00:36,  3.36it/s] 60%|█████▉    | 179/300 [00:53<00:35,  3.38it/s] 60%|██████    | 180/300 [00:54<00:35,  3.40it/s] 60%|██████    | 181/300 [00:54<00:34,  3.42it/s] 61%|██████    | 182/300 [00:54<00:34,  3.37it/s] 61%|██████    | 183/300 [00:55<00:34,  3.39it/s] 61%|██████▏   | 184/300 [00:55<00:34,  3.40it/s] 62%|██████▏   | 185/300 [00:55<00:33,  3.41it/s] 62%|██████▏   | 186/300 [00:55<00:33,  3.41it/s] 62%|██████▏   | 187/300 [00:56<00:33,  3.41it/s] 63%|██████▎   | 188/300 [00:56<00:32,  3.42it/s] 63%|██████▎   | 189/300 [00:56<00:32,  3.42it/s] 63%|██████▎   | 190/300 [00:57<00:32,  3.42it/s] 64%|██████▎   | 191/300 [00:57<00:32,  3.41it/s] 64%|██████▍   | 192/300 [00:57<00:32,  3.36it/s] 64%|██████▍   | 193/300 [00:57<00:31,  3.35it/s] 65%|██████▍   | 194/300 [00:58<00:31,  3.36it/s] 65%|██████▌   | 195/300 [00:58<00:31,  3.38it/s] 65%|██████▌   | 196/300 [00:58<00:30,  3.37it/s] 66%|██████▌   | 197/300 [00:59<00:30,  3.39it/s] 66%|██████▌   | 198/300 [00:59<00:30,  3.37it/s] 66%|██████▋   | 199/300 [00:59<00:29,  3.38it/s] 67%|██████▋   | 200/300 [01:00<00:29,  3.39it/s] 67%|██████▋   | 201/300 [01:00<00:29,  3.37it/s] 67%|██████▋   | 202/300 [01:00<00:29,  3.35it/s] 68%|██████▊   | 203/300 [01:00<00:28,  3.37it/s] 68%|██████▊   | 204/300 [01:01<00:28,  3.39it/s] 68%|██████▊   | 205/300 [01:01<00:28,  3.39it/s] 69%|██████▊   | 206/300 [01:01<00:27,  3.40it/s] 69%|██████▉   | 207/300 [01:02<00:27,  3.40it/s] 69%|██████▉   | 208/300 [01:02<00:26,  3.42it/s] 70%|██████▉   | 209/300 [01:02<00:26,  3.41it/s] 70%|███████   | 210/300 [01:02<00:26,  3.41it/s] 70%|███████   | 211/300 [01:03<00:26,  3.41it/s] 71%|███████   | 212/300 [01:03<00:25,  3.41it/s] 71%|███████   | 213/300 [01:03<00:25,  3.43it/s] 71%|███████▏  | 214/300 [01:04<00:25,  3.43it/s] 72%|███████▏  | 215/300 [01:04<00:24,  3.41it/s] 72%|███████▏  | 216/300 [01:04<00:24,  3.43it/s] 72%|███████▏  | 217/300 [01:05<00:24,  3.39it/s] 73%|███████▎  | 218/300 [01:05<00:24,  3.41it/s] 73%|███████▎  | 219/300 [01:05<00:23,  3.41it/s] 73%|███████▎  | 220/300 [01:05<00:23,  3.43it/s] 74%|███████▎  | 221/300 [01:06<00:22,  3.44it/s] 74%|███████▍  | 222/300 [01:06<00:22,  3.41it/s] 74%|███████▍  | 223/300 [01:06<00:22,  3.41it/s] 75%|███████▍  | 224/300 [01:07<00:22,  3.38it/s] 75%|███████▌  | 225/300 [01:07<00:22,  3.41it/s] 75%|███████▌  | 226/300 [01:07<00:21,  3.42it/s] 76%|███████▌  | 227/300 [01:07<00:21,  3.40it/s] 76%|███████▌  | 228/300 [01:08<00:21,  3.36it/s] 76%|███████▋  | 229/300 [01:08<00:21,  3.37it/s] 77%|███████▋  | 230/300 [01:08<00:20,  3.39it/s] 77%|███████▋  | 231/300 [01:09<00:20,  3.40it/s] 77%|███████▋  | 232/300 [01:09<00:19,  3.43it/s] 78%|███████▊  | 233/300 [01:09<00:19,  3.42it/s] 78%|███████▊  | 234/300 [01:10<00:19,  3.43it/s] 78%|███████▊  | 235/300 [01:10<00:19,  3.41it/s] 79%|███████▊  | 236/300 [01:10<00:18,  3.42it/s] 79%|███████▉  | 237/300 [01:10<00:18,  3.44it/s] 79%|███████▉  | 238/300 [01:11<00:18,  3.44it/s] 80%|███████▉  | 239/300 [01:11<00:17,  3.43it/s] 80%|████████  | 240/300 [01:11<00:17,  3.42it/s] 80%|████████  | 241/300 [01:12<00:17,  3.42it/s] 81%|████████  | 242/300 [01:12<00:16,  3.43it/s] 81%|████████  | 243/300 [01:12<00:16,  3.43it/s] 81%|████████▏ | 244/300 [01:12<00:16,  3.42it/s] 82%|████████▏ | 245/300 [01:13<00:16,  3.42it/s] 82%|████████▏ | 246/300 [01:13<00:15,  3.42it/s] 82%|████████▏ | 247/300 [01:13<00:15,  3.40it/s] 83%|████████▎ | 248/300 [01:14<00:15,  3.40it/s] 83%|████████▎ | 249/300 [01:14<00:15,  3.39it/s] 83%|████████▎ | 250/300 [01:14<00:14,  3.41it/s] 84%|████████▎ | 251/300 [01:14<00:14,  3.42it/s] 84%|████████▍ | 252/300 [01:15<00:14,  3.41it/s] 84%|████████▍ | 253/300 [01:15<00:13,  3.40it/s] 85%|████████▍ | 254/300 [01:15<00:13,  3.40it/s] 85%|████████▌ | 255/300 [01:16<00:13,  3.40it/s] 85%|████████▌ | 256/300 [01:16<00:12,  3.40it/s] 86%|████████▌ | 257/300 [01:16<00:12,  3.40it/s] 86%|████████▌ | 258/300 [01:17<00:12,  3.41it/s] 86%|████████▋ | 259/300 [01:17<00:12,  3.41it/s] 87%|████████▋ | 260/300 [01:17<00:11,  3.39it/s] 87%|████████▋ | 261/300 [01:17<00:11,  3.38it/s] 87%|████████▋ | 262/300 [01:18<00:11,  3.36it/s] 88%|████████▊ | 263/300 [01:18<00:11,  3.31it/s] 88%|████████▊ | 264/300 [01:18<00:10,  3.29it/s] 88%|████████▊ | 265/300 [01:19<00:10,  3.32it/s] 89%|████████▊ | 266/300 [01:19<00:10,  3.34it/s] 89%|████████▉ | 267/300 [01:19<00:09,  3.36it/s] 89%|████████▉ | 268/300 [01:20<00:09,  3.38it/s] 90%|████████▉ | 269/300 [01:20<00:09,  3.40it/s] 90%|█████████ | 270/300 [01:20<00:08,  3.45it/s] 90%|█████████ | 271/300 [01:20<00:08,  3.48it/s] 91%|█████████ | 272/300 [01:21<00:08,  3.44it/s] 91%|█████████ | 273/300 [01:21<00:07,  3.45it/s] 91%|█████████▏| 274/300 [01:21<00:07,  3.48it/s] 92%|█████████▏| 275/300 [01:22<00:07,  3.48it/s] 92%|█████████▏| 276/300 [01:22<00:06,  3.49it/s] 92%|█████████▏| 277/300 [01:22<00:06,  3.49it/s] 93%|█████████▎| 278/300 [01:22<00:06,  3.49it/s] 93%|█████████▎| 279/300 [01:23<00:06,  3.46it/s] 93%|█████████▎| 280/300 [01:23<00:05,  3.40it/s] 94%|█████████▎| 281/300 [01:23<00:05,  3.36it/s] 94%|█████████▍| 282/300 [01:24<00:05,  3.41it/s] 94%|█████████▍| 283/300 [01:24<00:04,  3.42it/s] 95%|█████████▍| 284/300 [01:24<00:04,  3.43it/s] 95%|█████████▌| 285/300 [01:24<00:04,  3.41it/s] 95%|█████████▌| 286/300 [01:25<00:04,  3.41it/s] 96%|█████████▌| 287/300 [01:25<00:03,  3.41it/s] 96%|█████████▌| 288/300 [01:25<00:03,  3.40it/s] 96%|█████████▋| 289/300 [01:26<00:03,  3.43it/s] 97%|█████████▋| 290/300 [01:26<00:02,  3.33it/s] 97%|█████████▋| 291/300 [01:26<00:02,  3.32it/s] 97%|█████████▋| 292/300 [01:27<00:02,  3.35it/s] 98%|█████████▊| 293/300 [01:27<00:02,  3.36it/s] 98%|█████████▊| 294/300 [01:27<00:01,  3.38it/s] 98%|█████████▊| 295/300 [01:27<00:01,  3.40it/s] 99%|█████████▊| 296/300 [01:28<00:01,  3.35it/s] 99%|█████████▉| 297/300 [01:28<00:00,  3.37it/s] 99%|█████████▉| 298/300 [01:28<00:00,  3.40it/s]100%|█████████▉| 299/300 [01:29<00:00,  3.40it/s]100%|██████████| 300/300 [01:29<00:00,  3.40it/s]100%|██████████| 300/300 [01:29<00:00,  3.36it/s]
======= FKD: dataset info ======
path: ../relabel/FKD_cutmix_fp16/imagenette/v7/
num img: 10
batch size: 10
max epoch: 300
================================
load data successfully
=> loading student model 'resnet18'
TRAIN Iter 0: lr = 0.001000,	loss = 0.017668,	Top-1 acc = 10.000000,	Top-5 acc = 60.000000,	train_time = 3.542402
TEST Iter 0: loss = 7.319919,	Top-1 acc = 10.038217,	Top-5 acc = 48.687898,	val_time = 25.549410
TRAIN Iter 10: lr = 0.000997,	loss = 0.013399,	Top-1 acc = 60.000000,	Top-5 acc = 100.000000,	train_time = 2.370651
TEST Iter 10: loss = 28.175737,	Top-1 acc = 16.484076,	Top-5 acc = 50.878981,	val_time = 16.815195
TRAIN Iter 20: lr = 0.000989,	loss = 0.006440,	Top-1 acc = 40.000000,	Top-5 acc = 80.000000,	train_time = 2.465852
TEST Iter 20: loss = 35.058778,	Top-1 acc = 11.337580,	Top-5 acc = 51.617834,	val_time = 16.748985
TRAIN Iter 30: lr = 0.000976,	loss = 0.007210,	Top-1 acc = 10.000000,	Top-5 acc = 80.000000,	train_time = 2.376139
TEST Iter 30: loss = 8.079860,	Top-1 acc = 15.872611,	Top-5 acc = 59.108280,	val_time = 16.813235
TRAIN Iter 40: lr = 0.000957,	loss = 0.011821,	Top-1 acc = 50.000000,	Top-5 acc = 100.000000,	train_time = 2.420551
TEST Iter 40: loss = 5.884706,	Top-1 acc = 15.184713,	Top-5 acc = 57.070064,	val_time = 16.650979
TRAIN Iter 50: lr = 0.000933,	loss = 0.007185,	Top-1 acc = 20.000000,	Top-5 acc = 90.000000,	train_time = 2.439971
TEST Iter 50: loss = 6.687247,	Top-1 acc = 17.401274,	Top-5 acc = 62.751592,	val_time = 16.866923
TRAIN Iter 60: lr = 0.000905,	loss = 0.004402,	Top-1 acc = 100.000000,	Top-5 acc = 100.000000,	train_time = 2.402980
TEST Iter 60: loss = 5.396109,	Top-1 acc = 17.019108,	Top-5 acc = 59.464968,	val_time = 16.629120
TRAIN Iter 70: lr = 0.000872,	loss = 0.004363,	Top-1 acc = 100.000000,	Top-5 acc = 100.000000,	train_time = 2.558612
TEST Iter 70: loss = 6.279450,	Top-1 acc = 17.452229,	Top-5 acc = 60.662420,	val_time = 16.779063
TRAIN Iter 80: lr = 0.000835,	loss = 0.003646,	Top-1 acc = 20.000000,	Top-5 acc = 80.000000,	train_time = 2.425138
TEST Iter 80: loss = 8.036224,	Top-1 acc = 17.452229,	Top-5 acc = 60.382166,	val_time = 17.128122
TRAIN Iter 90: lr = 0.000794,	loss = 0.006306,	Top-1 acc = 80.000000,	Top-5 acc = 100.000000,	train_time = 2.551968
TEST Iter 90: loss = 5.977138,	Top-1 acc = 16.891720,	Top-5 acc = 59.031847,	val_time = 16.624730
TRAIN Iter 100: lr = 0.000750,	loss = 0.004224,	Top-1 acc = 100.000000,	Top-5 acc = 100.000000,	train_time = 2.448149
TEST Iter 100: loss = 6.974114,	Top-1 acc = 12.229299,	Top-5 acc = 58.394904,	val_time = 16.786702
TRAIN Iter 110: lr = 0.000703,	loss = 0.007611,	Top-1 acc = 60.000000,	Top-5 acc = 100.000000,	train_time = 2.408756
TEST Iter 110: loss = 8.373753,	Top-1 acc = 15.668790,	Top-5 acc = 60.000000,	val_time = 16.709061
TRAIN Iter 120: lr = 0.000655,	loss = 0.004058,	Top-1 acc = 90.000000,	Top-5 acc = 100.000000,	train_time = 2.447381
TEST Iter 120: loss = 5.233138,	Top-1 acc = 16.433121,	Top-5 acc = 59.108280,	val_time = 16.704147
TRAIN Iter 130: lr = 0.000604,	loss = 0.007131,	Top-1 acc = 100.000000,	Top-5 acc = 100.000000,	train_time = 2.379173
TEST Iter 130: loss = 4.866514,	Top-1 acc = 18.242038,	Top-5 acc = 61.681529,	val_time = 16.721386
TRAIN Iter 140: lr = 0.000552,	loss = 0.004363,	Top-1 acc = 100.000000,	Top-5 acc = 100.000000,	train_time = 2.326707
TEST Iter 140: loss = 5.222343,	Top-1 acc = 15.872611,	Top-5 acc = 60.738854,	val_time = 16.720219
TRAIN Iter 150: lr = 0.000500,	loss = 0.005334,	Top-1 acc = 30.000000,	Top-5 acc = 90.000000,	train_time = 2.388252
TEST Iter 150: loss = 5.267393,	Top-1 acc = 19.439490,	Top-5 acc = 66.063694,	val_time = 16.737916
TRAIN Iter 160: lr = 0.000448,	loss = 0.002912,	Top-1 acc = 100.000000,	Top-5 acc = 100.000000,	train_time = 2.436395
TEST Iter 160: loss = 6.193848,	Top-1 acc = 18.955414,	Top-5 acc = 67.974522,	val_time = 16.635608
TRAIN Iter 170: lr = 0.000396,	loss = 0.004144,	Top-1 acc = 50.000000,	Top-5 acc = 100.000000,	train_time = 2.417167
TEST Iter 170: loss = 4.766103,	Top-1 acc = 17.783439,	Top-5 acc = 65.987261,	val_time = 16.752986
TRAIN Iter 180: lr = 0.000345,	loss = 0.003235,	Top-1 acc = 100.000000,	Top-5 acc = 100.000000,	train_time = 2.405097
TEST Iter 180: loss = 4.506214,	Top-1 acc = 19.974522,	Top-5 acc = 64.535032,	val_time = 17.093536
TRAIN Iter 190: lr = 0.000297,	loss = 0.004740,	Top-1 acc = 100.000000,	Top-5 acc = 100.000000,	train_time = 2.458780
TEST Iter 190: loss = 4.867040,	Top-1 acc = 20.127389,	Top-5 acc = 66.242038,	val_time = 17.018919
TRAIN Iter 200: lr = 0.000250,	loss = 0.003791,	Top-1 acc = 50.000000,	Top-5 acc = 100.000000,	train_time = 2.372787
TEST Iter 200: loss = 4.395630,	Top-1 acc = 21.222930,	Top-5 acc = 67.235669,	val_time = 16.783060
TRAIN Iter 210: lr = 0.000206,	loss = 0.005310,	Top-1 acc = 90.000000,	Top-5 acc = 100.000000,	train_time = 2.411124
TEST Iter 210: loss = 4.208554,	Top-1 acc = 22.496815,	Top-5 acc = 67.668790,	val_time = 16.928176
TRAIN Iter 220: lr = 0.000165,	loss = 0.003645,	Top-1 acc = 70.000000,	Top-5 acc = 100.000000,	train_time = 2.437846
TEST Iter 220: loss = 4.943322,	Top-1 acc = 20.840764,	Top-5 acc = 64.789809,	val_time = 17.142450
TRAIN Iter 230: lr = 0.000128,	loss = 0.004181,	Top-1 acc = 100.000000,	Top-5 acc = 100.000000,	train_time = 2.431319
TEST Iter 230: loss = 4.339223,	Top-1 acc = 21.019108,	Top-5 acc = 67.337580,	val_time = 16.859088
TRAIN Iter 240: lr = 0.000095,	loss = 0.004174,	Top-1 acc = 60.000000,	Top-5 acc = 100.000000,	train_time = 2.440151
TEST Iter 240: loss = 4.644488,	Top-1 acc = 20.560510,	Top-5 acc = 68.178344,	val_time = 16.896412
TRAIN Iter 250: lr = 0.000067,	loss = 0.005338,	Top-1 acc = 30.000000,	Top-5 acc = 90.000000,	train_time = 2.412843
TEST Iter 250: loss = 4.605233,	Top-1 acc = 21.044586,	Top-5 acc = 68.127389,	val_time = 16.931229
TRAIN Iter 260: lr = 0.000043,	loss = 0.002692,	Top-1 acc = 100.000000,	Top-5 acc = 100.000000,	train_time = 2.381626
TEST Iter 260: loss = 4.240765,	Top-1 acc = 21.936306,	Top-5 acc = 68.509554,	val_time = 16.994016
TRAIN Iter 270: lr = 0.000024,	loss = 0.003644,	Top-1 acc = 90.000000,	Top-5 acc = 100.000000,	train_time = 2.380737
TEST Iter 270: loss = 4.224330,	Top-1 acc = 21.605096,	Top-5 acc = 67.184713,	val_time = 16.684027
TRAIN Iter 280: lr = 0.000011,	loss = 0.003830,	Top-1 acc = 0.000000,	Top-5 acc = 90.000000,	train_time = 2.408986
TEST Iter 280: loss = 4.288279,	Top-1 acc = 21.299363,	Top-5 acc = 67.439490,	val_time = 16.543730
TRAIN Iter 290: lr = 0.000003,	loss = 0.003644,	Top-1 acc = 10.000000,	Top-5 acc = 60.000000,	train_time = 2.419722
TEST Iter 290: loss = 4.286794,	Top-1 acc = 21.299363,	Top-5 acc = 67.261146,	val_time = 16.590991
TEST Iter 299: loss = 4.296906,	Top-1 acc = 21.324841,	Top-5 acc = 67.566879,	val_time = 16.680810
