/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
r_bn:  0.1
lr:  0.25
step 1
step 1.1
step 1.2
step 1.3
step 1.1
step 1.2
step 1.3
step 1.1
step 1.2
step 1.3
step 1.1
step 1.2
step 1.3
step 1.1
step 1.2
step 1.3
step 1.1
step 1.2
step 1.3
step 1.1
step 1.2
step 1.3
step 1.1
step 1.2
step 1.3
step 1.1
step 1.2
step 1.3
step 1.1
step 1.2
step 1.3
bc shape torch.Size([10, 10, 512])
step 2
step 2.1
step 2.2
get_images call
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
------------iteration 0----------
total loss 331.2380987826067
main criterion 92.66090456873951
weighted_aux_loss 238.5771942138672
loss_r_bn_feature 2385.77197265625
------------iteration 100----------
total loss 131.89872660089821
main criterion 61.44175638605448
weighted_aux_loss 70.45697021484375
loss_r_bn_feature 704.5697021484375
------------iteration 200----------
total loss 88.62680051857086
main criterion 38.34553907447907
weighted_aux_loss 50.2812614440918
loss_r_bn_feature 502.8126220703125
------------iteration 300----------
total loss 76.48844325954047
main criterion 34.67418086940375
weighted_aux_loss 41.81426239013672
loss_r_bn_feature 418.1426086425781
------------iteration 400----------
total loss 105.1376203959413
main criterion 53.214650577826056
weighted_aux_loss 51.922969818115234
loss_r_bn_feature 519.2296752929688
------------iteration 500----------
total loss 66.6477915370339
main criterion 30.736590059983122
weighted_aux_loss 35.91120147705078
loss_r_bn_feature 359.11199951171875
------------iteration 600----------
total loss 59.59060023678809
main criterion 27.830455049410162
weighted_aux_loss 31.76014518737793
loss_r_bn_feature 317.6014404296875
------------iteration 700----------
total loss 71.30659664132669
main criterion 34.6052683637388
weighted_aux_loss 36.70132827758789
loss_r_bn_feature 367.0132751464844
------------iteration 800----------
total loss 59.4648892554261
main criterion 27.664870944879222
weighted_aux_loss 31.800018310546875
loss_r_bn_feature 318.00018310546875
------------iteration 900----------
total loss 115.24488592195704
main criterion 55.638093472005856
weighted_aux_loss 59.60679244995117
loss_r_bn_feature 596.0679321289062
------------iteration 1000----------
total loss 67.6912844556775
main criterion 33.70157650890016
weighted_aux_loss 33.989707946777344
loss_r_bn_feature 339.8970642089844
------------iteration 1100----------
total loss 45.08558481889847
main criterion 22.752021967946316
weighted_aux_loss 22.33356285095215
loss_r_bn_feature 223.3356170654297
------------iteration 1200----------
total loss 41.251997341876155
main criterion 20.700096478228694
weighted_aux_loss 20.55190086364746
loss_r_bn_feature 205.51901245117188
------------iteration 1300----------
total loss 52.567687269162995
main criterion 28.12677883715616
weighted_aux_loss 24.440908432006836
loss_r_bn_feature 244.40907287597656
------------iteration 1400----------
total loss 36.797815743711
main criterion 20.511623803403378
weighted_aux_loss 16.286191940307617
loss_r_bn_feature 162.86192321777344
------------iteration 1500----------
total loss 32.07563414520578
main criterion 17.96244540161447
weighted_aux_loss 14.113188743591309
loss_r_bn_feature 141.1318817138672
------------iteration 1600----------
total loss 52.873822461228755
main criterion 26.633116971116454
weighted_aux_loss 26.240705490112305
loss_r_bn_feature 262.40704345703125
------------iteration 1700----------
total loss 33.4084727484358
main criterion 19.652704926170177
weighted_aux_loss 13.755767822265625
loss_r_bn_feature 137.55767822265625
------------iteration 1800----------
total loss 97.26730272395147
main criterion 46.873721333570614
weighted_aux_loss 50.39358139038086
loss_r_bn_feature 503.9358215332031
------------iteration 1900----------
total loss 24.440262709677356
main criterion 14.42739668947472
weighted_aux_loss 10.012866020202637
loss_r_bn_feature 100.128662109375
=> using pytorch pre-trained model 'resnet18'
process data from ../recover/syn_data/imagenette/279
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 1/300 [00:01<09:30,  1.91s/it]  1%|          | 2/300 [00:02<05:42,  1.15s/it]  1%|          | 3/300 [00:03<04:28,  1.11it/s]  1%|▏         | 4/300 [00:03<03:54,  1.26it/s]  2%|▏         | 5/300 [00:04<03:33,  1.38it/s]  2%|▏         | 6/300 [00:04<03:22,  1.45it/s]  2%|▏         | 7/300 [00:05<03:15,  1.50it/s]  3%|▎         | 8/300 [00:06<03:10,  1.53it/s]  3%|▎         | 9/300 [00:06<03:07,  1.55it/s]  3%|▎         | 10/300 [00:07<03:04,  1.57it/s]  4%|▎         | 11/300 [00:08<03:02,  1.58it/s]  4%|▍         | 12/300 [00:08<03:01,  1.59it/s]  4%|▍         | 13/300 [00:09<03:00,  1.59it/s]  5%|▍         | 14/300 [00:09<03:00,  1.59it/s]  5%|▌         | 15/300 [00:10<02:57,  1.60it/s]  5%|▌         | 16/300 [00:11<02:56,  1.61it/s]  6%|▌         | 17/300 [00:11<02:56,  1.61it/s]  6%|▌         | 18/300 [00:12<02:54,  1.61it/s]  6%|▋         | 19/300 [00:13<02:53,  1.62it/s]  7%|▋         | 20/300 [00:13<02:52,  1.62it/s]  7%|▋         | 21/300 [00:14<02:51,  1.62it/s]  7%|▋         | 22/300 [00:14<02:51,  1.62it/s]  8%|▊         | 23/300 [00:15<02:52,  1.61it/s]  8%|▊         | 24/300 [00:16<02:52,  1.60it/s]  8%|▊         | 25/300 [00:16<02:51,  1.60it/s]  9%|▊         | 26/300 [00:17<02:51,  1.60it/s]  9%|▉         | 27/300 [00:18<02:50,  1.60it/s]  9%|▉         | 28/300 [00:18<02:49,  1.60it/s] 10%|▉         | 29/300 [00:19<02:48,  1.60it/s] 10%|█         | 30/300 [00:19<02:48,  1.60it/s] 10%|█         | 31/300 [00:20<02:48,  1.60it/s] 11%|█         | 32/300 [00:21<02:46,  1.61it/s] 11%|█         | 33/300 [00:21<02:46,  1.61it/s] 11%|█▏        | 34/300 [00:22<02:45,  1.61it/s] 12%|█▏        | 35/300 [00:23<02:44,  1.62it/s] 12%|█▏        | 36/300 [00:23<02:43,  1.61it/s] 12%|█▏        | 37/300 [00:24<02:42,  1.62it/s] 13%|█▎        | 38/300 [00:24<02:43,  1.60it/s] 13%|█▎        | 39/300 [00:25<02:42,  1.61it/s] 13%|█▎        | 40/300 [00:26<02:40,  1.62it/s] 14%|█▎        | 41/300 [00:26<02:42,  1.59it/s] 14%|█▍        | 42/300 [00:27<02:41,  1.60it/s] 14%|█▍        | 43/300 [00:28<02:40,  1.60it/s] 15%|█▍        | 44/300 [00:28<02:39,  1.61it/s] 15%|█▌        | 45/300 [00:29<02:38,  1.61it/s] 15%|█▌        | 46/300 [00:29<02:37,  1.61it/s] 16%|█▌        | 47/300 [00:30<02:36,  1.61it/s] 16%|█▌        | 48/300 [00:31<02:37,  1.60it/s] 16%|█▋        | 49/300 [00:31<02:39,  1.58it/s] 17%|█▋        | 50/300 [00:32<02:37,  1.58it/s] 17%|█▋        | 51/300 [00:33<02:36,  1.59it/s] 17%|█▋        | 52/300 [00:33<02:35,  1.60it/s] 18%|█▊        | 53/300 [00:34<02:34,  1.60it/s] 18%|█▊        | 54/300 [00:34<02:33,  1.60it/s] 18%|█▊        | 55/300 [00:35<02:33,  1.60it/s] 19%|█▊        | 56/300 [00:36<02:34,  1.58it/s] 19%|█▉        | 57/300 [00:36<02:33,  1.59it/s] 19%|█▉        | 58/300 [00:37<02:32,  1.59it/s] 20%|█▉        | 59/300 [00:38<02:29,  1.61it/s] 20%|██        | 60/300 [00:38<02:30,  1.60it/s] 20%|██        | 61/300 [00:39<02:29,  1.60it/s] 21%|██        | 62/300 [00:39<02:28,  1.60it/s] 21%|██        | 63/300 [00:40<02:28,  1.60it/s] 21%|██▏       | 64/300 [00:41<02:25,  1.62it/s] 22%|██▏       | 65/300 [00:41<02:23,  1.64it/s] 22%|██▏       | 66/300 [00:42<02:22,  1.64it/s] 22%|██▏       | 67/300 [00:42<02:23,  1.63it/s] 23%|██▎       | 68/300 [00:43<02:21,  1.64it/s] 23%|██▎       | 69/300 [00:44<02:19,  1.66it/s] 23%|██▎       | 70/300 [00:44<02:18,  1.66it/s] 24%|██▎       | 71/300 [00:45<02:17,  1.66it/s] 24%|██▍       | 72/300 [00:45<02:18,  1.65it/s] 24%|██▍       | 73/300 [00:46<02:17,  1.65it/s] 25%|██▍       | 74/300 [00:47<02:18,  1.63it/s] 25%|██▌       | 75/300 [00:47<02:20,  1.60it/s] 25%|██▌       | 76/300 [00:48<02:20,  1.59it/s] 26%|██▌       | 77/300 [00:49<02:19,  1.60it/s] 26%|██▌       | 78/300 [00:49<02:18,  1.60it/s] 26%|██▋       | 79/300 [00:50<02:18,  1.59it/s] 27%|██▋       | 80/300 [00:50<02:18,  1.59it/s] 27%|██▋       | 81/300 [00:51<02:17,  1.60it/s] 27%|██▋       | 82/300 [00:52<02:16,  1.60it/s] 28%|██▊       | 83/300 [00:52<02:16,  1.59it/s] 28%|██▊       | 84/300 [00:53<02:15,  1.59it/s] 28%|██▊       | 85/300 [00:54<02:14,  1.59it/s] 29%|██▊       | 86/300 [00:54<02:15,  1.58it/s] 29%|██▉       | 87/300 [00:55<02:15,  1.58it/s] 29%|██▉       | 88/300 [00:56<02:13,  1.59it/s] 30%|██▉       | 89/300 [00:56<02:11,  1.60it/s] 30%|███       | 90/300 [00:57<02:09,  1.62it/s] 30%|███       | 91/300 [00:57<02:10,  1.60it/s] 31%|███       | 92/300 [00:58<02:09,  1.60it/s] 31%|███       | 93/300 [00:59<02:07,  1.62it/s] 31%|███▏      | 94/300 [00:59<02:07,  1.62it/s] 32%|███▏      | 95/300 [01:00<02:06,  1.62it/s] 32%|███▏      | 96/300 [01:00<02:05,  1.62it/s] 32%|███▏      | 97/300 [01:01<02:05,  1.61it/s] 33%|███▎      | 98/300 [01:02<02:05,  1.61it/s] 33%|███▎      | 99/300 [01:02<02:04,  1.61it/s] 33%|███▎      | 100/300 [01:03<02:03,  1.62it/s] 34%|███▎      | 101/300 [01:04<02:02,  1.62it/s] 34%|███▍      | 102/300 [01:04<02:01,  1.63it/s] 34%|███▍      | 103/300 [01:05<02:00,  1.63it/s] 35%|███▍      | 104/300 [01:05<02:01,  1.62it/s] 35%|███▌      | 105/300 [01:06<02:01,  1.61it/s] 35%|███▌      | 106/300 [01:07<02:00,  1.61it/s] 36%|███▌      | 107/300 [01:07<01:59,  1.62it/s] 36%|███▌      | 108/300 [01:08<01:59,  1.61it/s] 36%|███▋      | 109/300 [01:09<01:58,  1.61it/s] 37%|███▋      | 110/300 [01:09<01:58,  1.61it/s] 37%|███▋      | 111/300 [01:10<01:57,  1.62it/s] 37%|███▋      | 112/300 [01:10<01:56,  1.61it/s] 38%|███▊      | 113/300 [01:11<01:54,  1.63it/s] 38%|███▊      | 114/300 [01:12<01:54,  1.63it/s] 38%|███▊      | 115/300 [01:12<01:54,  1.61it/s] 39%|███▊      | 116/300 [01:13<01:55,  1.60it/s] 39%|███▉      | 117/300 [01:13<01:54,  1.60it/s] 39%|███▉      | 118/300 [01:14<01:53,  1.60it/s] 40%|███▉      | 119/300 [01:15<01:52,  1.60it/s] 40%|████      | 120/300 [01:15<01:51,  1.61it/s] 40%|████      | 121/300 [01:16<01:51,  1.61it/s] 41%|████      | 122/300 [01:17<01:50,  1.62it/s] 41%|████      | 123/300 [01:17<01:49,  1.61it/s] 41%|████▏     | 124/300 [01:18<01:49,  1.60it/s] 42%|████▏     | 125/300 [01:18<01:47,  1.63it/s] 42%|████▏     | 126/300 [01:19<01:46,  1.64it/s] 42%|████▏     | 127/300 [01:20<01:45,  1.64it/s] 43%|████▎     | 128/300 [01:20<01:44,  1.64it/s] 43%|████▎     | 129/300 [01:21<01:43,  1.64it/s] 43%|████▎     | 130/300 [01:21<01:43,  1.64it/s] 44%|████▎     | 131/300 [01:22<01:42,  1.65it/s] 44%|████▍     | 132/300 [01:23<01:41,  1.66it/s] 44%|████▍     | 133/300 [01:23<01:41,  1.65it/s] 45%|████▍     | 134/300 [01:24<01:40,  1.66it/s] 45%|████▌     | 135/300 [01:24<01:39,  1.66it/s] 45%|████▌     | 136/300 [01:25<01:38,  1.67it/s] 46%|████▌     | 137/300 [01:26<01:38,  1.66it/s] 46%|████▌     | 138/300 [01:26<01:38,  1.64it/s] 46%|████▋     | 139/300 [01:27<01:38,  1.63it/s] 47%|████▋     | 140/300 [01:28<01:38,  1.62it/s] 47%|████▋     | 141/300 [01:28<01:38,  1.62it/s] 47%|████▋     | 142/300 [01:29<01:38,  1.61it/s] 48%|████▊     | 143/300 [01:29<01:37,  1.61it/s] 48%|████▊     | 144/300 [01:30<01:36,  1.61it/s] 48%|████▊     | 145/300 [01:31<01:36,  1.61it/s] 49%|████▊     | 146/300 [01:31<01:35,  1.60it/s] 49%|████▉     | 147/300 [01:32<01:34,  1.61it/s] 49%|████▉     | 148/300 [01:33<01:34,  1.60it/s] 50%|████▉     | 149/300 [01:33<01:34,  1.60it/s] 50%|█████     | 150/300 [01:34<01:33,  1.60it/s] 50%|█████     | 151/300 [01:34<01:34,  1.58it/s] 51%|█████     | 152/300 [01:35<01:33,  1.59it/s] 51%|█████     | 153/300 [01:36<01:32,  1.60it/s] 51%|█████▏    | 154/300 [01:36<01:31,  1.60it/s] 52%|█████▏    | 155/300 [01:37<01:30,  1.60it/s] 52%|█████▏    | 156/300 [01:38<01:30,  1.60it/s] 52%|█████▏    | 157/300 [01:38<01:29,  1.59it/s] 53%|█████▎    | 158/300 [01:39<01:28,  1.60it/s] 53%|█████▎    | 159/300 [01:39<01:27,  1.60it/s] 53%|█████▎    | 160/300 [01:40<01:26,  1.61it/s] 54%|█████▎    | 161/300 [01:41<01:26,  1.61it/s] 54%|█████▍    | 162/300 [01:41<01:25,  1.61it/s] 54%|█████▍    | 163/300 [01:42<01:24,  1.61it/s] 55%|█████▍    | 164/300 [01:43<01:24,  1.61it/s] 55%|█████▌    | 165/300 [01:43<01:24,  1.61it/s] 55%|█████▌    | 166/300 [01:44<01:22,  1.62it/s] 56%|█████▌    | 167/300 [01:44<01:22,  1.62it/s] 56%|█████▌    | 168/300 [01:45<01:22,  1.61it/s] 56%|█████▋    | 169/300 [01:46<01:20,  1.62it/s] 57%|█████▋    | 170/300 [01:46<01:20,  1.62it/s] 57%|█████▋    | 171/300 [01:47<01:19,  1.61it/s] 57%|█████▋    | 172/300 [01:47<01:19,  1.61it/s] 58%|█████▊    | 173/300 [01:48<01:18,  1.61it/s] 58%|█████▊    | 174/300 [01:49<01:18,  1.60it/s] 58%|█████▊    | 175/300 [01:49<01:17,  1.60it/s] 59%|█████▊    | 176/300 [01:50<01:17,  1.61it/s] 59%|█████▉    | 177/300 [01:51<01:16,  1.61it/s] 59%|█████▉    | 178/300 [01:51<01:15,  1.61it/s] 60%|█████▉    | 179/300 [01:52<01:15,  1.61it/s] 60%|██████    | 180/300 [01:52<01:14,  1.61it/s] 60%|██████    | 181/300 [01:53<01:13,  1.61it/s] 61%|██████    | 182/300 [01:54<01:13,  1.61it/s] 61%|██████    | 183/300 [01:54<01:12,  1.62it/s] 61%|██████▏   | 184/300 [01:55<01:11,  1.61it/s] 62%|██████▏   | 185/300 [01:56<01:11,  1.62it/s] 62%|██████▏   | 186/300 [01:56<01:10,  1.62it/s] 62%|██████▏   | 187/300 [01:57<01:09,  1.62it/s] 63%|██████▎   | 188/300 [01:57<01:08,  1.63it/s] 63%|██████▎   | 189/300 [01:58<01:08,  1.62it/s] 63%|██████▎   | 190/300 [01:59<01:08,  1.62it/s] 64%|██████▎   | 191/300 [01:59<01:08,  1.60it/s] 64%|██████▍   | 192/300 [02:00<01:07,  1.61it/s] 64%|██████▍   | 193/300 [02:01<01:06,  1.60it/s] 65%|██████▍   | 194/300 [02:01<01:06,  1.60it/s] 65%|██████▌   | 195/300 [02:02<01:05,  1.61it/s] 65%|██████▌   | 196/300 [02:02<01:05,  1.60it/s] 66%|██████▌   | 197/300 [02:03<01:04,  1.59it/s] 66%|██████▌   | 198/300 [02:04<01:03,  1.61it/s] 66%|██████▋   | 199/300 [02:04<01:02,  1.63it/s] 67%|██████▋   | 200/300 [02:05<01:01,  1.64it/s] 67%|██████▋   | 201/300 [02:05<00:59,  1.65it/s] 67%|██████▋   | 202/300 [02:06<00:59,  1.66it/s] 68%|██████▊   | 203/300 [02:07<00:58,  1.65it/s] 68%|██████▊   | 204/300 [02:07<00:59,  1.62it/s] 68%|██████▊   | 205/300 [02:08<00:58,  1.62it/s] 69%|██████▊   | 206/300 [02:08<00:57,  1.62it/s] 69%|██████▉   | 207/300 [02:09<00:57,  1.61it/s] 69%|██████▉   | 208/300 [02:10<00:56,  1.62it/s] 70%|██████▉   | 209/300 [02:10<00:56,  1.62it/s] 70%|███████   | 210/300 [02:11<00:55,  1.62it/s] 70%|███████   | 211/300 [02:12<00:54,  1.62it/s] 71%|███████   | 212/300 [02:12<00:54,  1.61it/s] 71%|███████   | 213/300 [02:13<00:53,  1.61it/s] 71%|███████▏  | 214/300 [02:13<00:52,  1.62it/s] 72%|███████▏  | 215/300 [02:14<00:52,  1.62it/s] 72%|███████▏  | 216/300 [02:15<00:51,  1.63it/s] 72%|███████▏  | 217/300 [02:15<00:51,  1.63it/s] 73%|███████▎  | 218/300 [02:16<00:50,  1.63it/s] 73%|███████▎  | 219/300 [02:17<00:49,  1.63it/s] 73%|███████▎  | 220/300 [02:17<00:49,  1.63it/s] 74%|███████▎  | 221/300 [02:18<00:48,  1.63it/s] 74%|███████▍  | 222/300 [02:18<00:48,  1.61it/s] 74%|███████▍  | 223/300 [02:19<00:47,  1.61it/s] 75%|███████▍  | 224/300 [02:20<00:47,  1.60it/s] 75%|███████▌  | 225/300 [02:20<00:46,  1.61it/s] 75%|███████▌  | 226/300 [02:21<00:46,  1.61it/s] 76%|███████▌  | 227/300 [02:21<00:45,  1.59it/s] 76%|███████▌  | 228/300 [02:22<00:45,  1.60it/s] 76%|███████▋  | 229/300 [02:23<00:44,  1.60it/s] 77%|███████▋  | 230/300 [02:23<00:43,  1.61it/s] 77%|███████▋  | 231/300 [02:24<00:42,  1.62it/s] 77%|███████▋  | 232/300 [02:25<00:42,  1.62it/s] 78%|███████▊  | 233/300 [02:25<00:41,  1.62it/s] 78%|███████▊  | 234/300 [02:26<00:40,  1.62it/s] 78%|███████▊  | 235/300 [02:26<00:40,  1.61it/s] 79%|███████▊  | 236/300 [02:27<00:40,  1.59it/s] 79%|███████▉  | 237/300 [02:28<00:39,  1.59it/s] 79%|███████▉  | 238/300 [02:28<00:38,  1.60it/s] 80%|███████▉  | 239/300 [02:29<00:38,  1.60it/s] 80%|████████  | 240/300 [02:30<00:37,  1.60it/s] 80%|████████  | 241/300 [02:30<00:36,  1.60it/s] 81%|████████  | 242/300 [02:31<00:36,  1.60it/s] 81%|████████  | 243/300 [02:31<00:35,  1.60it/s] 81%|████████▏ | 244/300 [02:32<00:35,  1.60it/s] 82%|████████▏ | 245/300 [02:33<00:34,  1.60it/s] 82%|████████▏ | 246/300 [02:33<00:33,  1.61it/s] 82%|████████▏ | 247/300 [02:34<00:32,  1.62it/s] 83%|████████▎ | 248/300 [02:35<00:32,  1.62it/s] 83%|████████▎ | 249/300 [02:35<00:31,  1.61it/s] 83%|████████▎ | 250/300 [02:36<00:30,  1.61it/s] 84%|████████▎ | 251/300 [02:36<00:30,  1.61it/s] 84%|████████▍ | 252/300 [02:37<00:29,  1.61it/s] 84%|████████▍ | 253/300 [02:38<00:29,  1.61it/s] 85%|████████▍ | 254/300 [02:38<00:28,  1.62it/s] 85%|████████▌ | 255/300 [02:39<00:27,  1.62it/s] 85%|████████▌ | 256/300 [02:39<00:27,  1.63it/s] 86%|████████▌ | 257/300 [02:40<00:26,  1.62it/s] 86%|████████▌ | 258/300 [02:41<00:26,  1.61it/s] 86%|████████▋ | 259/300 [02:41<00:25,  1.62it/s] 87%|████████▋ | 260/300 [02:42<00:25,  1.59it/s] 87%|████████▋ | 261/300 [02:43<00:24,  1.60it/s] 87%|████████▋ | 262/300 [02:43<00:23,  1.60it/s] 88%|████████▊ | 263/300 [02:44<00:23,  1.61it/s] 88%|████████▊ | 264/300 [02:44<00:22,  1.61it/s] 88%|████████▊ | 265/300 [02:45<00:21,  1.61it/s] 89%|████████▊ | 266/300 [02:46<00:21,  1.61it/s] 89%|████████▉ | 267/300 [02:46<00:20,  1.60it/s] 89%|████████▉ | 268/300 [02:47<00:20,  1.60it/s] 90%|████████▉ | 269/300 [02:48<00:19,  1.61it/s] 90%|█████████ | 270/300 [02:48<00:18,  1.62it/s] 90%|█████████ | 271/300 [02:49<00:18,  1.61it/s] 91%|█████████ | 272/300 [02:49<00:17,  1.61it/s] 91%|█████████ | 273/300 [02:50<00:16,  1.61it/s] 91%|█████████▏| 274/300 [02:51<00:16,  1.62it/s] 92%|█████████▏| 275/300 [02:51<00:15,  1.62it/s] 92%|█████████▏| 276/300 [02:52<00:14,  1.61it/s] 92%|█████████▏| 277/300 [02:53<00:14,  1.61it/s] 93%|█████████▎| 278/300 [02:53<00:13,  1.61it/s] 93%|█████████▎| 279/300 [02:54<00:12,  1.62it/s] 93%|█████████▎| 280/300 [02:54<00:12,  1.61it/s] 94%|█████████▎| 281/300 [02:55<00:11,  1.61it/s] 94%|█████████▍| 282/300 [02:56<00:11,  1.63it/s] 94%|█████████▍| 283/300 [02:56<00:10,  1.63it/s] 95%|█████████▍| 284/300 [02:57<00:09,  1.63it/s] 95%|█████████▌| 285/300 [02:57<00:09,  1.62it/s] 95%|█████████▌| 286/300 [02:58<00:08,  1.62it/s] 96%|█████████▌| 287/300 [02:59<00:08,  1.61it/s] 96%|█████████▌| 288/300 [02:59<00:07,  1.61it/s] 96%|█████████▋| 289/300 [03:00<00:06,  1.61it/s] 97%|█████████▋| 290/300 [03:01<00:06,  1.61it/s] 97%|█████████▋| 291/300 [03:01<00:05,  1.61it/s] 97%|█████████▋| 292/300 [03:02<00:04,  1.61it/s] 98%|█████████▊| 293/300 [03:02<00:04,  1.61it/s] 98%|█████████▊| 294/300 [03:03<00:03,  1.62it/s] 98%|█████████▊| 295/300 [03:04<00:03,  1.62it/s] 99%|█████████▊| 296/300 [03:04<00:02,  1.61it/s] 99%|█████████▉| 297/300 [03:05<00:01,  1.62it/s] 99%|█████████▉| 298/300 [03:06<00:01,  1.61it/s]100%|█████████▉| 299/300 [03:06<00:00,  1.62it/s]100%|██████████| 300/300 [03:07<00:00,  1.61it/s]100%|██████████| 300/300 [03:07<00:00,  1.60it/s]
W&B disabled.
W&B online. Running your script from this directory will now sync to the cloud.
wandb: Currently logged in as: hl57. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /media/techt/One Touch/DD/SRe2L/train/wandb/run-20231022_110348-x6ajw7ij
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-wind-452
wandb: ⭐️ View project at https://wandb.ai/hl57/final_rn18_fkd
wandb: 🚀 View run at https://wandb.ai/hl57/final_rn18_fkd/runs/x6ajw7ij
======= FKD: dataset info ======
path: ../relabel/FKD_cutmix_fp16/imagenette/279/
num img: 100
batch size: 100
max epoch: 300
================================
load data successfully
=> loading student model 'resnet18'
TRAIN Iter 0: lr = 0.001000,	loss = 0.020272,	Top-1 err = 90.000000,	Top-5 err = 51.000000,	train_time = 3.224046
TEST Iter 0: loss = 14.364712,	Top-1 err = 89.324841,	Top-5 err = 50.445860,	val_time = 12.823807
TRAIN Iter 10: lr = 0.000997,	loss = 0.020537,	Top-1 err = 65.000000,	Top-5 err = 16.000000,	train_time = 2.220439
TEST Iter 10: loss = 58.008228,	Top-1 err = 87.133758,	Top-5 err = 40.127389,	val_time = 12.922115
TRAIN Iter 20: lr = 0.000989,	loss = 0.013463,	Top-1 err = 43.000000,	Top-5 err = 5.000000,	train_time = 2.221148
TEST Iter 20: loss = 7.164111,	Top-1 err = 77.961783,	Top-5 err = 38.802548,	val_time = 13.051318
TRAIN Iter 30: lr = 0.000976,	loss = 0.007950,	Top-1 err = 45.000000,	Top-5 err = 9.000000,	train_time = 2.194941
TEST Iter 30: loss = 7.224982,	Top-1 err = 76.178344,	Top-5 err = 34.802548,	val_time = 12.905048
TRAIN Iter 40: lr = 0.000957,	loss = 0.007372,	Top-1 err = 82.000000,	Top-5 err = 30.000000,	train_time = 2.360095
TEST Iter 40: loss = 4.172729,	Top-1 err = 68.178344,	Top-5 err = 24.000000,	val_time = 12.962172
TRAIN Iter 50: lr = 0.000933,	loss = 0.008241,	Top-1 err = 19.000000,	Top-5 err = 5.000000,	train_time = 2.186809
TEST Iter 50: loss = 4.579941,	Top-1 err = 60.713376,	Top-5 err = 18.471338,	val_time = 13.013348
TRAIN Iter 60: lr = 0.000905,	loss = 0.005853,	Top-1 err = 71.000000,	Top-5 err = 20.000000,	train_time = 2.272987
TEST Iter 60: loss = 5.403590,	Top-1 err = 66.165605,	Top-5 err = 19.439490,	val_time = 12.931001
TRAIN Iter 70: lr = 0.000872,	loss = 0.005174,	Top-1 err = 29.000000,	Top-5 err = 1.000000,	train_time = 2.223739
TEST Iter 70: loss = 3.754747,	Top-1 err = 63.592357,	Top-5 err = 17.426752,	val_time = 12.824958
TRAIN Iter 80: lr = 0.000835,	loss = 0.005802,	Top-1 err = 82.000000,	Top-5 err = 30.000000,	train_time = 2.250167
TEST Iter 80: loss = 3.799040,	Top-1 err = 59.566879,	Top-5 err = 16.254777,	val_time = 13.018516
TRAIN Iter 90: lr = 0.000794,	loss = 0.003970,	Top-1 err = 13.000000,	Top-5 err = 0.000000,	train_time = 2.228558
TEST Iter 90: loss = 4.420033,	Top-1 err = 62.140127,	Top-5 err = 16.280255,	val_time = 12.942294
TRAIN Iter 100: lr = 0.000750,	loss = 0.004223,	Top-1 err = 90.000000,	Top-5 err = 37.000000,	train_time = 2.222905
TEST Iter 100: loss = 3.092805,	Top-1 err = 54.777070,	Top-5 err = 13.452229,	val_time = 12.924373
TRAIN Iter 110: lr = 0.000703,	loss = 0.003657,	Top-1 err = 78.000000,	Top-5 err = 24.000000,	train_time = 2.220186
TEST Iter 110: loss = 2.904392,	Top-1 err = 54.089172,	Top-5 err = 15.312102,	val_time = 12.784579
TRAIN Iter 120: lr = 0.000655,	loss = 0.004263,	Top-1 err = 25.000000,	Top-5 err = 0.000000,	train_time = 2.234690
TEST Iter 120: loss = 3.787078,	Top-1 err = 58.828025,	Top-5 err = 16.662420,	val_time = 12.945517
TRAIN Iter 130: lr = 0.000604,	loss = 0.003368,	Top-1 err = 6.000000,	Top-5 err = 2.000000,	train_time = 2.262632
TEST Iter 130: loss = 2.687776,	Top-1 err = 49.732484,	Top-5 err = 10.853503,	val_time = 12.992579
TRAIN Iter 140: lr = 0.000552,	loss = 0.003366,	Top-1 err = 5.000000,	Top-5 err = 0.000000,	train_time = 2.200272
TEST Iter 140: loss = 3.172959,	Top-1 err = 53.859873,	Top-5 err = 12.280255,	val_time = 13.283911
TRAIN Iter 150: lr = 0.000500,	loss = 0.003239,	Top-1 err = 27.000000,	Top-5 err = 1.000000,	train_time = 2.235815
TEST Iter 150: loss = 3.033150,	Top-1 err = 52.025478,	Top-5 err = 13.375796,	val_time = 12.885046
TRAIN Iter 160: lr = 0.000448,	loss = 0.003547,	Top-1 err = 58.000000,	Top-5 err = 7.000000,	train_time = 2.196223
TEST Iter 160: loss = 2.225537,	Top-1 err = 45.732484,	Top-5 err = 8.891720,	val_time = 12.833030
TRAIN Iter 170: lr = 0.000396,	loss = 0.003689,	Top-1 err = 49.000000,	Top-5 err = 5.000000,	train_time = 2.252646
TEST Iter 170: loss = 2.813304,	Top-1 err = 49.681529,	Top-5 err = 10.802548,	val_time = 12.803649
TRAIN Iter 180: lr = 0.000345,	loss = 0.003003,	Top-1 err = 19.000000,	Top-5 err = 0.000000,	train_time = 2.258114
TEST Iter 180: loss = 2.671962,	Top-1 err = 46.929936,	Top-5 err = 9.477707,	val_time = 12.848450
TRAIN Iter 190: lr = 0.000297,	loss = 0.002545,	Top-1 err = 6.000000,	Top-5 err = 0.000000,	train_time = 2.224614
TEST Iter 190: loss = 2.312284,	Top-1 err = 44.509554,	Top-5 err = 8.917197,	val_time = 12.914089
TRAIN Iter 200: lr = 0.000250,	loss = 0.003086,	Top-1 err = 63.000000,	Top-5 err = 5.000000,	train_time = 2.272569
TEST Iter 200: loss = 1.917813,	Top-1 err = 42.751592,	Top-5 err = 7.847134,	val_time = 12.889768
TRAIN Iter 210: lr = 0.000206,	loss = 0.002844,	Top-1 err = 34.000000,	Top-5 err = 1.000000,	train_time = 2.220872
TEST Iter 210: loss = 1.867527,	Top-1 err = 41.528662,	Top-5 err = 7.184713,	val_time = 12.888654
TRAIN Iter 220: lr = 0.000165,	loss = 0.002631,	Top-1 err = 36.000000,	Top-5 err = 1.000000,	train_time = 2.235743
TEST Iter 220: loss = 1.926637,	Top-1 err = 42.751592,	Top-5 err = 8.305732,	val_time = 12.837689
TRAIN Iter 230: lr = 0.000128,	loss = 0.002582,	Top-1 err = 18.000000,	Top-5 err = 1.000000,	train_time = 2.256767
TEST Iter 230: loss = 2.076221,	Top-1 err = 42.828025,	Top-5 err = 8.636943,	val_time = 12.817673
TRAIN Iter 240: lr = 0.000095,	loss = 0.002565,	Top-1 err = 12.000000,	Top-5 err = 0.000000,	train_time = 2.203907
TEST Iter 240: loss = 1.864188,	Top-1 err = 39.821656,	Top-5 err = 7.312102,	val_time = 12.839773
TRAIN Iter 250: lr = 0.000067,	loss = 0.002580,	Top-1 err = 29.000000,	Top-5 err = 1.000000,	train_time = 2.244462
TEST Iter 250: loss = 1.865390,	Top-1 err = 39.898089,	Top-5 err = 7.363057,	val_time = 12.778612
TRAIN Iter 260: lr = 0.000043,	loss = 0.002122,	Top-1 err = 8.000000,	Top-5 err = 0.000000,	train_time = 2.249382
TEST Iter 260: loss = 1.862281,	Top-1 err = 39.643312,	Top-5 err = 7.312102,	val_time = 12.747034
TRAIN Iter 270: lr = 0.000024,	loss = 0.002269,	Top-1 err = 9.000000,	Top-5 err = 0.000000,	train_time = 2.238667
TEST Iter 270: loss = 1.821356,	Top-1 err = 39.261146,	Top-5 err = 7.057325,	val_time = 12.839313
TRAIN Iter 280: lr = 0.000011,	loss = 0.002747,	Top-1 err = 45.000000,	Top-5 err = 2.000000,	train_time = 2.279510
TEST Iter 280: loss = 1.830730,	Top-1 err = 39.159236,	Top-5 err = 7.159236,	val_time = 12.774358
TRAIN Iter 290: lr = 0.000003,	loss = 0.002651,	Top-1 err = 37.000000,	Top-5 err = 1.000000,	train_time = 2.256833
TEST Iter 290: loss = 1.850146,	Top-1 err = 39.159236,	Top-5 err = 7.235669,	val_time = 12.804332
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  train/Top1 ▁▁▄▅▂▆▆▇▃▄▅▃▆▇█▆█▇▂▅▁▃▄▂▇▅▆█▅▆▇▅▇▆▇█▆█▂▆
wandb:  train/Top5 ▁▁▇▇▅███▅▇▇▆▇██▇▇█▆▇▄▆▇▇████▇██▇███▇██▆▇
wandb: train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  train/loss ▇█▇▆▃▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    train/lr ███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:   val/epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███
wandb:    val/loss ▃█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    val/top1 ▁▁▃▃▄▅▄▅▅▅▆▆▅▇▆▆▇▇▇▇▇█▇▇███████
wandb:    val/top5 ▁▃▃▄▅▆▆▆▇▇▇▇▆▇▇▇█▇█████████████
wandb: 
wandb: Run summary:
wandb:  train/Top1 76.0
wandb:  train/Top5 96.0
wandb: train/epoch 299
wandb:  train/loss 0.00266
wandb:    train/lr 0.0
wandb:   val/epoch 299
wandb:    val/loss 1.84064
wandb:    val/top1 60.76433
wandb:    val/top5 92.81529
wandb: 
wandb: 🚀 View run skilled-wind-452 at: https://wandb.ai/hl57/final_rn18_fkd/runs/x6ajw7ij
wandb: ️⚡ View job at https://wandb.ai/hl57/final_rn18_fkd/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjk3MzkyNjU3/version_details/v46
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231022_110348-x6ajw7ij/logs
TEST Iter 299: loss = 1.840641,	Top-1 err = 39.235669,	Top-5 err = 7.184713,	val_time = 12.797226
