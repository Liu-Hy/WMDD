/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
r_bn:  0.01
lr:  0.25
bc shape torch.Size([10, 10, 512])
get_images call
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
------------iteration 0----------
total loss 116.67292206402276
main criterion 92.96409599895928
weighted_aux_loss 23.708826065063477
loss_r_bn_feature 2370.882568359375
------------iteration 100----------
total loss 62.08482407530686
main criterion 42.609858026112526
weighted_aux_loss 19.474966049194336
loss_r_bn_feature 1947.49658203125
------------iteration 200----------
total loss 53.10245995509905
main criterion 35.27424149501604
weighted_aux_loss 17.828218460083008
loss_r_bn_feature 1782.8218994140625
------------iteration 300----------
total loss 45.26046040720728
main criterion 29.52710011667994
weighted_aux_loss 15.733360290527344
loss_r_bn_feature 1573.3360595703125
------------iteration 400----------
total loss 47.93562162816346
main criterion 31.84774816930116
weighted_aux_loss 16.087873458862305
loss_r_bn_feature 1608.787353515625
------------iteration 500----------
total loss 54.9612113479062
main criterion 41.77172961267671
weighted_aux_loss 13.189481735229492
loss_r_bn_feature 1318.9482421875
------------iteration 600----------
total loss 42.52963487578026
main criterion 29.070919436937487
weighted_aux_loss 13.458715438842773
loss_r_bn_feature 1345.87158203125
------------iteration 700----------
total loss 44.68747160234493
main criterion 33.27226564683956
weighted_aux_loss 11.415205955505371
loss_r_bn_feature 1141.5206298828125
------------iteration 800----------
total loss 38.38980210814618
main criterion 26.444411406852232
weighted_aux_loss 11.945390701293945
loss_r_bn_feature 1194.5390625
------------iteration 900----------
total loss 37.848161662333595
main criterion 26.388910258525005
weighted_aux_loss 11.459251403808594
loss_r_bn_feature 1145.9251708984375
------------iteration 1000----------
total loss 36.62522967224561
main criterion 26.414351300053223
weighted_aux_loss 10.210878372192383
loss_r_bn_feature 1021.087890625
------------iteration 1100----------
total loss 31.801175932606608
main criterion 23.02783570738688
weighted_aux_loss 8.773340225219727
loss_r_bn_feature 877.3340454101562
------------iteration 1200----------
total loss 33.41680811333225
main criterion 25.290707573171115
weighted_aux_loss 8.126100540161133
loss_r_bn_feature 812.610107421875
------------iteration 1300----------
total loss 27.657532063040872
main criterion 19.49618467381968
weighted_aux_loss 8.161347389221191
loss_r_bn_feature 816.134765625
------------iteration 1400----------
total loss 24.54850784386305
main criterion 17.81567159737257
weighted_aux_loss 6.7328362464904785
loss_r_bn_feature 673.2836303710938
------------iteration 1500----------
total loss 23.096644073255035
main criterion 16.542827754743072
weighted_aux_loss 6.553816318511963
loss_r_bn_feature 655.3816528320312
------------iteration 1600----------
total loss 24.238440475908725
main criterion 19.596031628099887
weighted_aux_loss 4.642408847808838
loss_r_bn_feature 464.2408752441406
------------iteration 1700----------
total loss 23.335979881591115
main criterion 18.12326044113091
weighted_aux_loss 5.212719440460205
loss_r_bn_feature 521.27197265625
------------iteration 1800----------
total loss 38.7221091754689
main criterion 32.90576491429947
weighted_aux_loss 5.816344261169434
loss_r_bn_feature 581.6344604492188
------------iteration 1900----------
total loss 23.959809514850306
main criterion 19.802804204791713
weighted_aux_loss 4.157005310058594
loss_r_bn_feature 415.7005310058594
=> using pytorch pre-trained model 'resnet18'
process data from ../recover/syn_data/imagenette/246
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 1/300 [00:01<09:41,  1.94s/it]  1%|          | 2/300 [00:02<05:49,  1.17s/it]  1%|          | 3/300 [00:03<04:35,  1.08it/s]  1%|▏         | 4/300 [00:03<03:58,  1.24it/s]  2%|▏         | 5/300 [00:04<03:36,  1.36it/s]  2%|▏         | 6/300 [00:05<03:22,  1.45it/s]  2%|▏         | 7/300 [00:05<03:14,  1.51it/s]  3%|▎         | 8/300 [00:06<03:07,  1.56it/s]  3%|▎         | 9/300 [00:06<03:02,  1.59it/s]  3%|▎         | 10/300 [00:07<03:01,  1.60it/s]  4%|▎         | 11/300 [00:08<03:00,  1.60it/s]  4%|▍         | 12/300 [00:08<02:59,  1.60it/s]  4%|▍         | 13/300 [00:09<02:58,  1.61it/s]  5%|▍         | 14/300 [00:09<02:57,  1.61it/s]  5%|▌         | 15/300 [00:10<02:56,  1.62it/s]  5%|▌         | 16/300 [00:11<02:55,  1.62it/s]  6%|▌         | 17/300 [00:11<02:53,  1.63it/s]  6%|▌         | 18/300 [00:12<02:53,  1.63it/s]  6%|▋         | 19/300 [00:12<02:51,  1.64it/s]  7%|▋         | 20/300 [00:13<02:50,  1.65it/s]  7%|▋         | 21/300 [00:14<02:50,  1.64it/s]  7%|▋         | 22/300 [00:14<02:50,  1.63it/s]  8%|▊         | 23/300 [00:15<02:49,  1.63it/s]  8%|▊         | 24/300 [00:16<02:48,  1.64it/s]  8%|▊         | 25/300 [00:16<02:50,  1.62it/s]  9%|▊         | 26/300 [00:17<02:48,  1.62it/s]  9%|▉         | 27/300 [00:17<02:49,  1.61it/s]  9%|▉         | 28/300 [00:18<02:47,  1.62it/s] 10%|▉         | 29/300 [00:19<02:45,  1.64it/s] 10%|█         | 30/300 [00:19<02:44,  1.64it/s] 10%|█         | 31/300 [00:20<02:46,  1.61it/s] 11%|█         | 32/300 [00:20<02:44,  1.63it/s] 11%|█         | 33/300 [00:21<02:43,  1.64it/s] 11%|█▏        | 34/300 [00:22<02:41,  1.64it/s] 12%|█▏        | 35/300 [00:22<02:41,  1.64it/s] 12%|█▏        | 36/300 [00:23<02:41,  1.63it/s] 12%|█▏        | 37/300 [00:24<02:40,  1.64it/s] 13%|█▎        | 38/300 [00:24<02:40,  1.63it/s] 13%|█▎        | 39/300 [00:25<02:40,  1.63it/s] 13%|█▎        | 40/300 [00:25<02:40,  1.62it/s] 14%|█▎        | 41/300 [00:26<02:38,  1.63it/s] 14%|█▍        | 42/300 [00:27<02:37,  1.64it/s] 14%|█▍        | 43/300 [00:27<02:35,  1.65it/s] 15%|█▍        | 44/300 [00:28<02:36,  1.64it/s] 15%|█▌        | 45/300 [00:28<02:35,  1.64it/s] 15%|█▌        | 46/300 [00:29<02:34,  1.65it/s] 16%|█▌        | 47/300 [00:30<02:34,  1.64it/s] 16%|█▌        | 48/300 [00:30<02:34,  1.63it/s] 16%|█▋        | 49/300 [00:31<02:34,  1.62it/s] 17%|█▋        | 50/300 [00:31<02:33,  1.63it/s] 17%|█▋        | 51/300 [00:32<02:32,  1.63it/s] 17%|█▋        | 52/300 [00:33<02:32,  1.63it/s] 18%|█▊        | 53/300 [00:33<02:31,  1.63it/s] 18%|█▊        | 54/300 [00:34<02:30,  1.64it/s] 18%|█▊        | 55/300 [00:35<02:29,  1.64it/s] 19%|█▊        | 56/300 [00:35<02:29,  1.63it/s] 19%|█▉        | 57/300 [00:36<02:28,  1.64it/s] 19%|█▉        | 58/300 [00:36<02:27,  1.64it/s] 20%|█▉        | 59/300 [00:37<02:28,  1.62it/s] 20%|██        | 60/300 [00:38<02:28,  1.62it/s] 20%|██        | 61/300 [00:38<02:26,  1.63it/s] 21%|██        | 62/300 [00:39<02:27,  1.61it/s] 21%|██        | 63/300 [00:39<02:26,  1.61it/s] 21%|██▏       | 64/300 [00:40<02:25,  1.62it/s] 22%|██▏       | 65/300 [00:41<02:23,  1.63it/s] 22%|██▏       | 66/300 [00:41<02:23,  1.64it/s] 22%|██▏       | 67/300 [00:42<02:21,  1.64it/s] 23%|██▎       | 68/300 [00:43<02:20,  1.65it/s] 23%|██▎       | 69/300 [00:43<02:19,  1.66it/s] 23%|██▎       | 70/300 [00:44<02:18,  1.66it/s] 24%|██▎       | 71/300 [00:44<02:18,  1.66it/s] 24%|██▍       | 72/300 [00:45<02:17,  1.66it/s] 24%|██▍       | 73/300 [00:46<02:18,  1.64it/s] 25%|██▍       | 74/300 [00:46<02:18,  1.64it/s] 25%|██▌       | 75/300 [00:47<02:17,  1.63it/s] 25%|██▌       | 76/300 [00:47<02:16,  1.64it/s] 26%|██▌       | 77/300 [00:48<02:14,  1.66it/s] 26%|██▌       | 78/300 [00:49<02:13,  1.66it/s] 26%|██▋       | 79/300 [00:49<02:12,  1.67it/s] 27%|██▋       | 80/300 [00:50<02:11,  1.67it/s] 27%|██▋       | 81/300 [00:50<02:13,  1.65it/s] 27%|██▋       | 82/300 [00:51<02:12,  1.65it/s] 28%|██▊       | 83/300 [00:52<02:12,  1.63it/s] 28%|██▊       | 84/300 [00:52<02:12,  1.63it/s] 28%|██▊       | 85/300 [00:53<02:12,  1.62it/s] 29%|██▊       | 86/300 [00:53<02:11,  1.63it/s] 29%|██▉       | 87/300 [00:54<02:10,  1.64it/s] 29%|██▉       | 88/300 [00:55<02:08,  1.65it/s] 30%|██▉       | 89/300 [00:55<02:07,  1.65it/s] 30%|███       | 90/300 [00:56<02:07,  1.65it/s] 30%|███       | 91/300 [00:56<02:05,  1.66it/s] 31%|███       | 92/300 [00:57<02:04,  1.67it/s] 31%|███       | 93/300 [00:58<02:03,  1.67it/s] 31%|███▏      | 94/300 [00:58<02:03,  1.67it/s] 32%|███▏      | 95/300 [00:59<02:05,  1.63it/s] 32%|███▏      | 96/300 [00:59<02:04,  1.64it/s] 32%|███▏      | 97/300 [01:00<02:02,  1.66it/s] 33%|███▎      | 98/300 [01:01<02:01,  1.66it/s] 33%|███▎      | 99/300 [01:01<02:00,  1.67it/s] 33%|███▎      | 100/300 [01:02<02:00,  1.67it/s] 34%|███▎      | 101/300 [01:02<01:59,  1.66it/s] 34%|███▍      | 102/300 [01:03<01:59,  1.65it/s] 34%|███▍      | 103/300 [01:04<01:59,  1.65it/s] 35%|███▍      | 104/300 [01:04<01:58,  1.65it/s] 35%|███▌      | 105/300 [01:05<01:57,  1.66it/s] 35%|███▌      | 106/300 [01:06<01:57,  1.65it/s] 36%|███▌      | 107/300 [01:06<01:56,  1.65it/s] 36%|███▌      | 108/300 [01:07<01:57,  1.63it/s] 36%|███▋      | 109/300 [01:07<01:55,  1.65it/s] 37%|███▋      | 110/300 [01:08<01:55,  1.65it/s] 37%|███▋      | 111/300 [01:09<01:53,  1.66it/s] 37%|███▋      | 112/300 [01:09<01:54,  1.64it/s] 38%|███▊      | 113/300 [01:10<01:54,  1.64it/s] 38%|███▊      | 114/300 [01:10<01:53,  1.64it/s] 38%|███▊      | 115/300 [01:11<01:52,  1.64it/s] 39%|███▊      | 116/300 [01:12<01:50,  1.66it/s] 39%|███▉      | 117/300 [01:12<01:50,  1.66it/s] 39%|███▉      | 118/300 [01:13<01:50,  1.65it/s] 40%|███▉      | 119/300 [01:13<01:50,  1.64it/s] 40%|████      | 120/300 [01:14<01:48,  1.66it/s] 40%|████      | 121/300 [01:15<01:47,  1.66it/s] 41%|████      | 122/300 [01:15<01:47,  1.66it/s] 41%|████      | 123/300 [01:16<01:46,  1.66it/s] 41%|████▏     | 124/300 [01:16<01:44,  1.68it/s] 42%|████▏     | 125/300 [01:17<01:44,  1.67it/s] 42%|████▏     | 126/300 [01:18<01:43,  1.69it/s] 42%|████▏     | 127/300 [01:18<01:44,  1.65it/s] 43%|████▎     | 128/300 [01:19<01:43,  1.66it/s] 43%|████▎     | 129/300 [01:19<01:42,  1.67it/s] 43%|████▎     | 130/300 [01:20<01:42,  1.66it/s] 44%|████▎     | 131/300 [01:21<01:41,  1.67it/s] 44%|████▍     | 132/300 [01:21<01:39,  1.68it/s] 44%|████▍     | 133/300 [01:22<01:39,  1.68it/s] 45%|████▍     | 134/300 [01:22<01:38,  1.69it/s] 45%|████▌     | 135/300 [01:23<01:36,  1.70it/s] 45%|████▌     | 136/300 [01:24<01:37,  1.69it/s] 46%|████▌     | 137/300 [01:24<01:36,  1.70it/s] 46%|████▌     | 138/300 [01:25<01:35,  1.69it/s] 46%|████▋     | 139/300 [01:25<01:35,  1.69it/s] 47%|████▋     | 140/300 [01:26<01:34,  1.69it/s] 47%|████▋     | 141/300 [01:26<01:33,  1.70it/s] 47%|████▋     | 142/300 [01:27<01:32,  1.70it/s] 48%|████▊     | 143/300 [01:28<01:31,  1.71it/s] 48%|████▊     | 144/300 [01:28<01:31,  1.70it/s] 48%|████▊     | 145/300 [01:29<01:31,  1.70it/s] 49%|████▊     | 146/300 [01:29<01:30,  1.69it/s] 49%|████▉     | 147/300 [01:30<01:30,  1.70it/s] 49%|████▉     | 148/300 [01:31<01:28,  1.71it/s] 50%|████▉     | 149/300 [01:31<01:28,  1.72it/s] 50%|█████     | 150/300 [01:32<01:28,  1.70it/s] 50%|█████     | 151/300 [01:32<01:27,  1.71it/s] 51%|█████     | 152/300 [01:33<01:26,  1.70it/s] 51%|█████     | 153/300 [01:34<01:26,  1.69it/s] 51%|█████▏    | 154/300 [01:34<01:26,  1.69it/s] 52%|█████▏    | 155/300 [01:35<01:25,  1.70it/s] 52%|█████▏    | 156/300 [01:35<01:25,  1.69it/s] 52%|█████▏    | 157/300 [01:36<01:24,  1.69it/s] 53%|█████▎    | 158/300 [01:36<01:23,  1.69it/s] 53%|█████▎    | 159/300 [01:37<01:23,  1.69it/s] 53%|█████▎    | 160/300 [01:38<01:22,  1.70it/s] 54%|█████▎    | 161/300 [01:38<01:22,  1.69it/s] 54%|█████▍    | 162/300 [01:39<01:21,  1.69it/s] 54%|█████▍    | 163/300 [01:39<01:20,  1.70it/s] 55%|█████▍    | 164/300 [01:40<01:20,  1.68it/s] 55%|█████▌    | 165/300 [01:41<01:19,  1.70it/s] 55%|█████▌    | 166/300 [01:41<01:18,  1.70it/s] 56%|█████▌    | 167/300 [01:42<01:18,  1.69it/s] 56%|█████▌    | 168/300 [01:42<01:17,  1.70it/s] 56%|█████▋    | 169/300 [01:43<01:17,  1.69it/s] 57%|█████▋    | 170/300 [01:44<01:17,  1.69it/s] 57%|█████▋    | 171/300 [01:44<01:16,  1.68it/s] 57%|█████▋    | 172/300 [01:45<01:16,  1.68it/s] 58%|█████▊    | 173/300 [01:45<01:15,  1.69it/s] 58%|█████▊    | 174/300 [01:46<01:14,  1.69it/s] 58%|█████▊    | 175/300 [01:47<01:14,  1.69it/s] 59%|█████▊    | 176/300 [01:47<01:13,  1.69it/s] 59%|█████▉    | 177/300 [01:48<01:12,  1.69it/s] 59%|█████▉    | 178/300 [01:48<01:12,  1.69it/s] 60%|█████▉    | 179/300 [01:49<01:11,  1.69it/s] 60%|██████    | 180/300 [01:49<01:10,  1.69it/s] 60%|██████    | 181/300 [01:50<01:10,  1.70it/s] 61%|██████    | 182/300 [01:51<01:10,  1.66it/s] 61%|██████    | 183/300 [01:51<01:09,  1.68it/s] 61%|██████▏   | 184/300 [01:52<01:08,  1.68it/s] 62%|██████▏   | 185/300 [01:52<01:08,  1.67it/s] 62%|██████▏   | 186/300 [01:53<01:08,  1.66it/s] 62%|██████▏   | 187/300 [01:54<01:08,  1.65it/s] 63%|██████▎   | 188/300 [01:54<01:07,  1.67it/s] 63%|██████▎   | 189/300 [01:55<01:06,  1.68it/s] 63%|██████▎   | 190/300 [01:55<01:05,  1.68it/s] 64%|██████▎   | 191/300 [01:56<01:04,  1.69it/s] 64%|██████▍   | 192/300 [01:57<01:04,  1.69it/s] 64%|██████▍   | 193/300 [01:57<01:02,  1.70it/s] 65%|██████▍   | 194/300 [01:58<01:02,  1.70it/s] 65%|██████▌   | 195/300 [01:58<01:01,  1.70it/s] 65%|██████▌   | 196/300 [01:59<01:01,  1.70it/s] 66%|██████▌   | 197/300 [02:00<01:00,  1.70it/s] 66%|██████▌   | 198/300 [02:00<01:00,  1.69it/s] 66%|██████▋   | 199/300 [02:01<00:59,  1.70it/s] 67%|██████▋   | 200/300 [02:01<00:58,  1.70it/s] 67%|██████▋   | 201/300 [02:02<00:58,  1.70it/s] 67%|██████▋   | 202/300 [02:03<00:57,  1.71it/s] 68%|██████▊   | 203/300 [02:03<00:56,  1.70it/s] 68%|██████▊   | 204/300 [02:04<00:56,  1.70it/s] 68%|██████▊   | 205/300 [02:04<00:55,  1.70it/s] 69%|██████▊   | 206/300 [02:05<00:55,  1.70it/s] 69%|██████▉   | 207/300 [02:05<00:54,  1.70it/s] 69%|██████▉   | 208/300 [02:06<00:54,  1.70it/s] 70%|██████▉   | 209/300 [02:07<00:53,  1.70it/s] 70%|███████   | 210/300 [02:07<00:53,  1.69it/s] 70%|███████   | 211/300 [02:08<00:52,  1.69it/s] 71%|███████   | 212/300 [02:08<00:51,  1.70it/s] 71%|███████   | 213/300 [02:09<00:51,  1.70it/s] 71%|███████▏  | 214/300 [02:10<00:50,  1.70it/s] 72%|███████▏  | 215/300 [02:10<00:49,  1.70it/s] 72%|███████▏  | 216/300 [02:11<00:49,  1.70it/s] 72%|███████▏  | 217/300 [02:11<00:48,  1.70it/s] 73%|███████▎  | 218/300 [02:12<00:48,  1.69it/s] 73%|███████▎  | 219/300 [02:13<00:47,  1.70it/s] 73%|███████▎  | 220/300 [02:13<00:46,  1.71it/s] 74%|███████▎  | 221/300 [02:14<00:46,  1.71it/s] 74%|███████▍  | 222/300 [02:14<00:45,  1.71it/s] 74%|███████▍  | 223/300 [02:15<00:45,  1.70it/s] 75%|███████▍  | 224/300 [02:15<00:44,  1.70it/s] 75%|███████▌  | 225/300 [02:16<00:44,  1.69it/s] 75%|███████▌  | 226/300 [02:17<00:43,  1.70it/s] 76%|███████▌  | 227/300 [02:17<00:43,  1.69it/s] 76%|███████▌  | 228/300 [02:18<00:42,  1.70it/s] 76%|███████▋  | 229/300 [02:18<00:41,  1.70it/s] 77%|███████▋  | 230/300 [02:19<00:41,  1.70it/s] 77%|███████▋  | 231/300 [02:20<00:40,  1.71it/s] 77%|███████▋  | 232/300 [02:20<00:39,  1.70it/s] 78%|███████▊  | 233/300 [02:21<00:39,  1.69it/s] 78%|███████▊  | 234/300 [02:21<00:38,  1.70it/s] 78%|███████▊  | 235/300 [02:22<00:38,  1.68it/s] 79%|███████▊  | 236/300 [02:23<00:38,  1.68it/s] 79%|███████▉  | 237/300 [02:23<00:37,  1.70it/s] 79%|███████▉  | 238/300 [02:24<00:36,  1.70it/s] 80%|███████▉  | 239/300 [02:24<00:35,  1.71it/s] 80%|████████  | 240/300 [02:25<00:35,  1.69it/s] 80%|████████  | 241/300 [02:26<00:34,  1.70it/s] 81%|████████  | 242/300 [02:26<00:34,  1.70it/s] 81%|████████  | 243/300 [02:27<00:33,  1.69it/s] 81%|████████▏ | 244/300 [02:27<00:32,  1.70it/s] 82%|████████▏ | 245/300 [02:28<00:32,  1.71it/s] 82%|████████▏ | 246/300 [02:28<00:31,  1.70it/s] 82%|████████▏ | 247/300 [02:29<00:31,  1.71it/s] 83%|████████▎ | 248/300 [02:30<00:30,  1.71it/s] 83%|████████▎ | 249/300 [02:30<00:30,  1.69it/s] 83%|████████▎ | 250/300 [02:31<00:29,  1.70it/s] 84%|████████▎ | 251/300 [02:31<00:28,  1.70it/s] 84%|████████▍ | 252/300 [02:32<00:28,  1.71it/s] 84%|████████▍ | 253/300 [02:33<00:27,  1.72it/s] 85%|████████▍ | 254/300 [02:33<00:26,  1.72it/s] 85%|████████▌ | 255/300 [02:34<00:26,  1.71it/s] 85%|████████▌ | 256/300 [02:34<00:25,  1.72it/s] 86%|████████▌ | 257/300 [02:35<00:24,  1.73it/s] 86%|████████▌ | 258/300 [02:35<00:24,  1.73it/s] 86%|████████▋ | 259/300 [02:36<00:23,  1.73it/s] 87%|████████▋ | 260/300 [02:37<00:23,  1.73it/s] 87%|████████▋ | 261/300 [02:37<00:22,  1.71it/s] 87%|████████▋ | 262/300 [02:38<00:22,  1.71it/s] 88%|████████▊ | 263/300 [02:38<00:21,  1.72it/s] 88%|████████▊ | 264/300 [02:39<00:20,  1.72it/s] 88%|████████▊ | 265/300 [02:40<00:20,  1.71it/s] 89%|████████▊ | 266/300 [02:40<00:19,  1.71it/s] 89%|████████▉ | 267/300 [02:41<00:19,  1.69it/s] 89%|████████▉ | 268/300 [02:41<00:19,  1.68it/s] 90%|████████▉ | 269/300 [02:42<00:18,  1.68it/s] 90%|█████████ | 270/300 [02:43<00:18,  1.66it/s] 90%|█████████ | 271/300 [02:43<00:17,  1.63it/s] 91%|█████████ | 272/300 [02:44<00:17,  1.63it/s] 91%|█████████ | 273/300 [02:44<00:16,  1.63it/s] 91%|█████████▏| 274/300 [02:45<00:15,  1.64it/s] 92%|█████████▏| 275/300 [02:46<00:15,  1.64it/s] 92%|█████████▏| 276/300 [02:46<00:14,  1.64it/s] 92%|█████████▏| 277/300 [02:47<00:14,  1.64it/s] 93%|█████████▎| 278/300 [02:47<00:13,  1.64it/s] 93%|█████████▎| 279/300 [02:48<00:12,  1.64it/s] 93%|█████████▎| 280/300 [02:49<00:12,  1.64it/s] 94%|█████████▎| 281/300 [02:49<00:11,  1.65it/s] 94%|█████████▍| 282/300 [02:50<00:10,  1.65it/s] 94%|█████████▍| 283/300 [02:50<00:10,  1.64it/s] 95%|█████████▍| 284/300 [02:51<00:09,  1.64it/s] 95%|█████████▌| 285/300 [02:52<00:09,  1.65it/s] 95%|█████████▌| 286/300 [02:52<00:08,  1.65it/s] 96%|█████████▌| 287/300 [02:53<00:07,  1.65it/s] 96%|█████████▌| 288/300 [02:54<00:07,  1.65it/s] 96%|█████████▋| 289/300 [02:54<00:06,  1.64it/s] 97%|█████████▋| 290/300 [02:55<00:06,  1.64it/s] 97%|█████████▋| 291/300 [02:55<00:05,  1.64it/s] 97%|█████████▋| 292/300 [02:56<00:04,  1.64it/s] 98%|█████████▊| 293/300 [02:57<00:04,  1.62it/s] 98%|█████████▊| 294/300 [02:57<00:03,  1.61it/s] 98%|█████████▊| 295/300 [02:58<00:03,  1.62it/s] 99%|█████████▊| 296/300 [02:58<00:02,  1.63it/s] 99%|█████████▉| 297/300 [02:59<00:01,  1.64it/s] 99%|█████████▉| 298/300 [03:00<00:01,  1.66it/s]100%|█████████▉| 299/300 [03:00<00:00,  1.67it/s]100%|██████████| 300/300 [03:01<00:00,  1.67it/s]100%|██████████| 300/300 [03:01<00:00,  1.65it/s]
W&B disabled.
W&B online. Running your script from this directory will now sync to the cloud.
wandb: Currently logged in as: hl57. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /media/techt/One Touch/DD/SRe2L/train/wandb/run-20231019_150720-tacwtq6m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-night-413
wandb: ⭐️ View project at https://wandb.ai/hl57/final_rn18_fkd
wandb: 🚀 View run at https://wandb.ai/hl57/final_rn18_fkd/runs/tacwtq6m
======= FKD: dataset info ======
path: ../relabel/FKD_cutmix_fp16/imagenette/246/
num img: 100
batch size: 100
max epoch: 300
================================
load data successfully
=> loading student model 'resnet18'

Epoch: 0
TRAIN Iter 0: lr = 0.001000,	loss = 0.000204,	Top-1 err = 90.000000,	Top-5 err = 46.000000,	train_time = 3.216309
TEST Iter 0: loss = 5.157526,	Top-1 err = 90.089172,	Top-5 err = 49.885350,	val_time = 12.796850

Epoch: 1

Epoch: 2

Epoch: 3

Epoch: 4

Epoch: 5

Epoch: 6

Epoch: 7

Epoch: 8

Epoch: 9

Epoch: 10
TRAIN Iter 10: lr = 0.000997,	loss = 0.000112,	Top-1 err = 67.000000,	Top-5 err = 19.000000,	train_time = 2.197683
TEST Iter 10: loss = 29.106841,	Top-1 err = 89.503185,	Top-5 err = 49.783439,	val_time = 12.591076

Epoch: 11

Epoch: 12

Epoch: 13

Epoch: 14

Epoch: 15

Epoch: 16

Epoch: 17

Epoch: 18

Epoch: 19

Epoch: 20
TRAIN Iter 20: lr = 0.000989,	loss = 0.000095,	Top-1 err = 70.000000,	Top-5 err = 25.000000,	train_time = 2.240323
TEST Iter 20: loss = 31.318003,	Top-1 err = 88.738854,	Top-5 err = 41.350318,	val_time = 12.815849

Epoch: 21

Epoch: 22

Epoch: 23

Epoch: 24

Epoch: 25

Epoch: 26

Epoch: 27

Epoch: 28

Epoch: 29

Epoch: 30
TRAIN Iter 30: lr = 0.000976,	loss = 0.000067,	Top-1 err = 66.000000,	Top-5 err = 11.000000,	train_time = 2.203591
TEST Iter 30: loss = 5.136340,	Top-1 err = 70.547771,	Top-5 err = 29.961783,	val_time = 12.603588

Epoch: 31

Epoch: 32

Epoch: 33

Epoch: 34

Epoch: 35

Epoch: 36

Epoch: 37

Epoch: 38

Epoch: 39

Epoch: 40
TRAIN Iter 40: lr = 0.000957,	loss = 0.000049,	Top-1 err = 89.000000,	Top-5 err = 25.000000,	train_time = 2.282132
TEST Iter 40: loss = 6.879888,	Top-1 err = 67.541401,	Top-5 err = 24.458599,	val_time = 12.656943

Epoch: 41

Epoch: 42

Epoch: 43

Epoch: 44

Epoch: 45

Epoch: 46

Epoch: 47

Epoch: 48

Epoch: 49

Epoch: 50
TRAIN Iter 50: lr = 0.000933,	loss = 0.000053,	Top-1 err = 46.000000,	Top-5 err = 5.000000,	train_time = 2.181324
TEST Iter 50: loss = 5.426591,	Top-1 err = 70.445860,	Top-5 err = 25.452229,	val_time = 12.536329

Epoch: 51

Epoch: 52

Epoch: 53

Epoch: 54

Epoch: 55

Epoch: 56

Epoch: 57

Epoch: 58

Epoch: 59

Epoch: 60
TRAIN Iter 60: lr = 0.000905,	loss = 0.000047,	Top-1 err = 62.000000,	Top-5 err = 9.000000,	train_time = 2.206721
TEST Iter 60: loss = 3.790357,	Top-1 err = 63.057325,	Top-5 err = 19.210191,	val_time = 12.792033

Epoch: 61

Epoch: 62

Epoch: 63

Epoch: 64

Epoch: 65

Epoch: 66

Epoch: 67

Epoch: 68

Epoch: 69

Epoch: 70
TRAIN Iter 70: lr = 0.000872,	loss = 0.000047,	Top-1 err = 78.000000,	Top-5 err = 15.000000,	train_time = 2.210953
TEST Iter 70: loss = 4.736139,	Top-1 err = 64.356688,	Top-5 err = 20.866242,	val_time = 12.793646

Epoch: 71

Epoch: 72

Epoch: 73

Epoch: 74

Epoch: 75

Epoch: 76

Epoch: 77

Epoch: 78

Epoch: 79

Epoch: 80
TRAIN Iter 80: lr = 0.000835,	loss = 0.000032,	Top-1 err = 73.000000,	Top-5 err = 19.000000,	train_time = 2.219573
TEST Iter 80: loss = 4.016444,	Top-1 err = 61.656051,	Top-5 err = 19.006369,	val_time = 12.607222

Epoch: 81

Epoch: 82

Epoch: 83

Epoch: 84

Epoch: 85

Epoch: 86

Epoch: 87

Epoch: 88

Epoch: 89

Epoch: 90
TRAIN Iter 90: lr = 0.000794,	loss = 0.000036,	Top-1 err = 5.000000,	Top-5 err = 0.000000,	train_time = 2.286762
TEST Iter 90: loss = 4.292288,	Top-1 err = 61.707006,	Top-5 err = 16.662420,	val_time = 12.759778

Epoch: 91

Epoch: 92

Epoch: 93

Epoch: 94

Epoch: 95

Epoch: 96

Epoch: 97

Epoch: 98

Epoch: 99

Epoch: 100
TRAIN Iter 100: lr = 0.000750,	loss = 0.000035,	Top-1 err = 26.000000,	Top-5 err = 0.000000,	train_time = 2.206548
TEST Iter 100: loss = 3.455502,	Top-1 err = 59.643312,	Top-5 err = 16.738854,	val_time = 12.688564

Epoch: 101

Epoch: 102

Epoch: 103

Epoch: 104

Epoch: 105

Epoch: 106

Epoch: 107

Epoch: 108

Epoch: 109

Epoch: 110
TRAIN Iter 110: lr = 0.000703,	loss = 0.000029,	Top-1 err = 7.000000,	Top-5 err = 0.000000,	train_time = 2.175088
TEST Iter 110: loss = 4.891184,	Top-1 err = 61.375796,	Top-5 err = 16.000000,	val_time = 12.742713

Epoch: 111

Epoch: 112

Epoch: 113

Epoch: 114

Epoch: 115

Epoch: 116

Epoch: 117

Epoch: 118

Epoch: 119

Epoch: 120
TRAIN Iter 120: lr = 0.000655,	loss = 0.000033,	Top-1 err = 68.000000,	Top-5 err = 10.000000,	train_time = 2.210135
TEST Iter 120: loss = 4.005020,	Top-1 err = 57.681529,	Top-5 err = 14.853503,	val_time = 12.755575

Epoch: 121

Epoch: 122

Epoch: 123

Epoch: 124

Epoch: 125

Epoch: 126

Epoch: 127

Epoch: 128

Epoch: 129

Epoch: 130
TRAIN Iter 130: lr = 0.000604,	loss = 0.000036,	Top-1 err = 33.000000,	Top-5 err = 1.000000,	train_time = 2.215337
TEST Iter 130: loss = 3.491305,	Top-1 err = 61.401274,	Top-5 err = 17.171975,	val_time = 12.630312

Epoch: 131

Epoch: 132

Epoch: 133

Epoch: 134

Epoch: 135

Epoch: 136

Epoch: 137

Epoch: 138

Epoch: 139

Epoch: 140
TRAIN Iter 140: lr = 0.000552,	loss = 0.000029,	Top-1 err = 6.000000,	Top-5 err = 1.000000,	train_time = 2.351872
TEST Iter 140: loss = 3.409910,	Top-1 err = 56.050955,	Top-5 err = 14.853503,	val_time = 12.800680

Epoch: 141

Epoch: 142

Epoch: 143

Epoch: 144

Epoch: 145

Epoch: 146

Epoch: 147

Epoch: 148

Epoch: 149

Epoch: 150
TRAIN Iter 150: lr = 0.000500,	loss = 0.000031,	Top-1 err = 79.000000,	Top-5 err = 9.000000,	train_time = 2.285017
TEST Iter 150: loss = 3.226593,	Top-1 err = 55.796178,	Top-5 err = 13.554140,	val_time = 12.962004

Epoch: 151

Epoch: 152

Epoch: 153

Epoch: 154

Epoch: 155

Epoch: 156

Epoch: 157

Epoch: 158

Epoch: 159

Epoch: 160
TRAIN Iter 160: lr = 0.000448,	loss = 0.000031,	Top-1 err = 10.000000,	Top-5 err = 1.000000,	train_time = 2.218343
TEST Iter 160: loss = 3.713308,	Top-1 err = 57.248408,	Top-5 err = 13.528662,	val_time = 13.082220

Epoch: 161

Epoch: 162

Epoch: 163

Epoch: 164

Epoch: 165

Epoch: 166

Epoch: 167

Epoch: 168

Epoch: 169

Epoch: 170
TRAIN Iter 170: lr = 0.000396,	loss = 0.000029,	Top-1 err = 11.000000,	Top-5 err = 0.000000,	train_time = 2.314447
TEST Iter 170: loss = 4.244017,	Top-1 err = 56.025478,	Top-5 err = 13.783439,	val_time = 12.999938

Epoch: 171

Epoch: 172

Epoch: 173

Epoch: 174

Epoch: 175

Epoch: 176

Epoch: 177

Epoch: 178

Epoch: 179

Epoch: 180
TRAIN Iter 180: lr = 0.000345,	loss = 0.000021,	Top-1 err = 5.000000,	Top-5 err = 0.000000,	train_time = 2.306687
TEST Iter 180: loss = 3.330627,	Top-1 err = 55.643312,	Top-5 err = 15.923567,	val_time = 12.914382

Epoch: 181

Epoch: 182

Epoch: 183

Epoch: 184

Epoch: 185

Epoch: 186

Epoch: 187

Epoch: 188

Epoch: 189

Epoch: 190
TRAIN Iter 190: lr = 0.000297,	loss = 0.000026,	Top-1 err = 11.000000,	Top-5 err = 1.000000,	train_time = 2.288900
TEST Iter 190: loss = 3.148965,	Top-1 err = 53.452229,	Top-5 err = 12.738854,	val_time = 12.799486

Epoch: 191

Epoch: 192

Epoch: 193

Epoch: 194

Epoch: 195

Epoch: 196

Epoch: 197

Epoch: 198

Epoch: 199

Epoch: 200
TRAIN Iter 200: lr = 0.000250,	loss = 0.000025,	Top-1 err = 72.000000,	Top-5 err = 7.000000,	train_time = 2.296985
TEST Iter 200: loss = 3.119894,	Top-1 err = 51.261146,	Top-5 err = 12.254777,	val_time = 13.208487

Epoch: 201

Epoch: 202

Epoch: 203

Epoch: 204

Epoch: 205

Epoch: 206

Epoch: 207

Epoch: 208

Epoch: 209

Epoch: 210
TRAIN Iter 210: lr = 0.000206,	loss = 0.000023,	Top-1 err = 11.000000,	Top-5 err = 1.000000,	train_time = 2.226856
TEST Iter 210: loss = 2.485323,	Top-1 err = 51.108280,	Top-5 err = 12.356688,	val_time = 13.194767

Epoch: 211

Epoch: 212

Epoch: 213

Epoch: 214

Epoch: 215

Epoch: 216

Epoch: 217

Epoch: 218

Epoch: 219

Epoch: 220
TRAIN Iter 220: lr = 0.000165,	loss = 0.000023,	Top-1 err = 55.000000,	Top-5 err = 5.000000,	train_time = 2.228911
TEST Iter 220: loss = 3.045080,	Top-1 err = 52.764331,	Top-5 err = 12.968153,	val_time = 12.890632

Epoch: 221

Epoch: 222

Epoch: 223

Epoch: 224

Epoch: 225

Epoch: 226

Epoch: 227

Epoch: 228

Epoch: 229

Epoch: 230
TRAIN Iter 230: lr = 0.000128,	loss = 0.000023,	Top-1 err = 60.000000,	Top-5 err = 4.000000,	train_time = 2.301036
TEST Iter 230: loss = 2.873528,	Top-1 err = 51.312102,	Top-5 err = 11.949045,	val_time = 12.895182

Epoch: 231

Epoch: 232

Epoch: 233

Epoch: 234

Epoch: 235

Epoch: 236

Epoch: 237

Epoch: 238

Epoch: 239

Epoch: 240
TRAIN Iter 240: lr = 0.000095,	loss = 0.000021,	Top-1 err = 9.000000,	Top-5 err = 2.000000,	train_time = 2.240030
TEST Iter 240: loss = 2.390736,	Top-1 err = 47.923567,	Top-5 err = 11.847134,	val_time = 12.732289

Epoch: 241

Epoch: 242

Epoch: 243

Epoch: 244

Epoch: 245

Epoch: 246

Epoch: 247

Epoch: 248

Epoch: 249

Epoch: 250
TRAIN Iter 250: lr = 0.000067,	loss = 0.000024,	Top-1 err = 35.000000,	Top-5 err = 2.000000,	train_time = 2.232604
TEST Iter 250: loss = 2.611659,	Top-1 err = 48.560510,	Top-5 err = 11.566879,	val_time = 12.780918

Epoch: 251

Epoch: 252

Epoch: 253

Epoch: 254

Epoch: 255

Epoch: 256

Epoch: 257

Epoch: 258

Epoch: 259

Epoch: 260
TRAIN Iter 260: lr = 0.000043,	loss = 0.000019,	Top-1 err = 7.000000,	Top-5 err = 1.000000,	train_time = 2.222463
TEST Iter 260: loss = 2.653266,	Top-1 err = 49.605096,	Top-5 err = 11.414013,	val_time = 12.584059

Epoch: 261

Epoch: 262

Epoch: 263

Epoch: 264

Epoch: 265

Epoch: 266

Epoch: 267

Epoch: 268

Epoch: 269

Epoch: 270
TRAIN Iter 270: lr = 0.000024,	loss = 0.000023,	Top-1 err = 8.000000,	Top-5 err = 0.000000,	train_time = 2.225507
TEST Iter 270: loss = 2.618663,	Top-1 err = 49.757962,	Top-5 err = 11.566879,	val_time = 12.775971

Epoch: 271

Epoch: 272

Epoch: 273

Epoch: 274

Epoch: 275

Epoch: 276

Epoch: 277

Epoch: 278

Epoch: 279

Epoch: 280
TRAIN Iter 280: lr = 0.000011,	loss = 0.000024,	Top-1 err = 32.000000,	Top-5 err = 1.000000,	train_time = 2.298190
TEST Iter 280: loss = 2.613638,	Top-1 err = 49.426752,	Top-5 err = 11.337580,	val_time = 13.239737

Epoch: 281

Epoch: 282

Epoch: 283

Epoch: 284

Epoch: 285

Epoch: 286

Epoch: 287

Epoch: 288

Epoch: 289

Epoch: 290
TRAIN Iter 290: lr = 0.000003,	loss = 0.000026,	Top-1 err = 13.000000,	Top-5 err = 1.000000,	train_time = 2.373929
TEST Iter 290: loss = 2.596964,	Top-1 err = 48.764331,	Top-5 err = 11.133758,	val_time = 13.080150

Epoch: 291

Epoch: 292

Epoch: 293

Epoch: 294

Epoch: 295

Epoch: 296

Epoch: 297

Epoch: 298

Epoch: 299
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  train/Top1 ▁▁▁▄▄▂▆▅▂▇▂▃▃▇▇▁▇█▁▇▇▆█▇█▇▆█▇▄▂▇▂▇▆▅█▅▇█
wandb:  train/Top5 ▁▂▃▆▇▅█▇▅█▆▆▇██▅██▆███████▇███▅█▃███████
wandb: train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  train/loss █▅▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    train/lr ███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:   val/epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███
wandb:    val/loss ▂▇█▂▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    val/top1 ▁▁▁▄▅▄▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇███████
wandb:    val/top5 ▁▁▃▅▆▅▇▆▇▇▇▇▇▇▇███▇████████████
wandb: 
wandb: Run summary:
wandb:  train/Top1 99.0
wandb:  train/Top5 100.0
wandb: train/epoch 299
wandb:  train/loss 2e-05
wandb:    train/lr 0.0
wandb:   val/epoch 299
wandb:    val/loss 2.56269
wandb:    val/top1 51.66879
wandb:    val/top5 88.78981
wandb: 
wandb: 🚀 View run unique-night-413 at: https://wandb.ai/hl57/final_rn18_fkd/runs/tacwtq6m
wandb: ️⚡ View job at https://wandb.ai/hl57/final_rn18_fkd/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjk3MzkyNjU3/version_details/v39
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231019_150720-tacwtq6m/logs
TEST Iter 299: loss = 2.562690,	Top-1 err = 48.331210,	Top-5 err = 11.210191,	val_time = 13.073061
