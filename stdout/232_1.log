W&B disabled.
W&B online. Running your script from this directory will now sync to the cloud.
wandb: Currently logged in as: hl57. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /media/techt/One Touch/DD/SRe2L/train/wandb/run-20231006_215351-9895kgkx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-hill-401
wandb: â­ï¸ View project at https://wandb.ai/hl57/final_rn18_fkd
wandb: ðŸš€ View run at https://wandb.ai/hl57/final_rn18_fkd/runs/9895kgkx
======= FKD: dataset info ======
path: ../relabel/FKD_cutmix_fp16/tiny-imagenet/232/
num img: 2000
batch size: 100
max epoch: 300
================================
load data successfully
=> loading student model 'resnet18'

Epoch: 0
TRAIN Iter 0: lr = 0.000500,	loss = 0.007862,	Top-1 err = 99.000000,	Top-5 err = 95.900000,	train_time = 17.491123
TEST Iter 0: loss = 7.430218,	Top-1 err = 99.300000,	Top-5 err = 96.020000,	val_time = 19.158419

Epoch: 1

Epoch: 2

Epoch: 3

Epoch: 4

Epoch: 5

Epoch: 6

Epoch: 7

Epoch: 8

Epoch: 9

Epoch: 10
TRAIN Iter 10: lr = 0.000499,	loss = 0.005896,	Top-1 err = 96.500000,	Top-5 err = 87.050000,	train_time = 15.123425
TEST Iter 10: loss = 5.970275,	Top-1 err = 97.420000,	Top-5 err = 88.750000,	val_time = 17.987736

Epoch: 11

Epoch: 12

Epoch: 13

Epoch: 14

Epoch: 15

Epoch: 16

Epoch: 17

Epoch: 18

Epoch: 19

Epoch: 20
TRAIN Iter 20: lr = 0.000495,	loss = 0.005662,	Top-1 err = 92.900000,	Top-5 err = 75.050000,	train_time = 15.207506
TEST Iter 20: loss = 4.856820,	Top-1 err = 93.860000,	Top-5 err = 78.710000,	val_time = 18.176294

Epoch: 21

Epoch: 22

Epoch: 23

Epoch: 24

Epoch: 25

Epoch: 26

Epoch: 27

Epoch: 28

Epoch: 29

Epoch: 30
TRAIN Iter 30: lr = 0.000488,	loss = 0.004812,	Top-1 err = 90.350000,	Top-5 err = 74.550000,	train_time = 15.353334
TEST Iter 30: loss = 5.070149,	Top-1 err = 93.610000,	Top-5 err = 78.680000,	val_time = 18.354882

Epoch: 31

Epoch: 32

Epoch: 33

Epoch: 34

Epoch: 35

Epoch: 36

Epoch: 37

Epoch: 38

Epoch: 39

Epoch: 40
TRAIN Iter 40: lr = 0.000478,	loss = 0.004496,	Top-1 err = 89.150000,	Top-5 err = 67.950000,	train_time = 15.826316
TEST Iter 40: loss = 5.156052,	Top-1 err = 93.180000,	Top-5 err = 76.970000,	val_time = 19.083708

Epoch: 41

Epoch: 42

Epoch: 43

Epoch: 44

Epoch: 45

Epoch: 46

Epoch: 47

Epoch: 48

Epoch: 49

Epoch: 50
TRAIN Iter 50: lr = 0.000467,	loss = 0.004344,	Top-1 err = 84.500000,	Top-5 err = 60.000000,	train_time = 15.112315
TEST Iter 50: loss = 5.129704,	Top-1 err = 91.360000,	Top-5 err = 74.820000,	val_time = 18.246588

Epoch: 51

Epoch: 52

Epoch: 53

Epoch: 54

Epoch: 55

Epoch: 56

Epoch: 57

Epoch: 58

Epoch: 59

Epoch: 60
TRAIN Iter 60: lr = 0.000452,	loss = 0.004043,	Top-1 err = 83.250000,	Top-5 err = 59.650000,	train_time = 15.480820
TEST Iter 60: loss = 4.951142,	Top-1 err = 89.450000,	Top-5 err = 71.260000,	val_time = 18.055228

Epoch: 61

Epoch: 62

Epoch: 63

Epoch: 64

Epoch: 65

Epoch: 66

Epoch: 67

Epoch: 68

Epoch: 69

Epoch: 70
TRAIN Iter 70: lr = 0.000436,	loss = 0.003911,	Top-1 err = 76.100000,	Top-5 err = 50.200000,	train_time = 15.018769
TEST Iter 70: loss = 4.124324,	Top-1 err = 85.700000,	Top-5 err = 63.970000,	val_time = 18.222337

Epoch: 71

Epoch: 72

Epoch: 73

Epoch: 74

Epoch: 75

Epoch: 76

Epoch: 77

Epoch: 78

Epoch: 79

Epoch: 80
TRAIN Iter 80: lr = 0.000417,	loss = 0.003655,	Top-1 err = 77.100000,	Top-5 err = 51.600000,	train_time = 15.500332
TEST Iter 80: loss = 4.532522,	Top-1 err = 88.080000,	Top-5 err = 68.090000,	val_time = 17.946912

Epoch: 81

Epoch: 82

Epoch: 83

Epoch: 84

Epoch: 85

Epoch: 86

Epoch: 87

Epoch: 88

Epoch: 89

Epoch: 90
TRAIN Iter 90: lr = 0.000397,	loss = 0.003319,	Top-1 err = 82.100000,	Top-5 err = 59.800000,	train_time = 15.084361
TEST Iter 90: loss = 4.566375,	Top-1 err = 85.200000,	Top-5 err = 61.850000,	val_time = 18.561386

Epoch: 91

Epoch: 92

Epoch: 93

Epoch: 94

Epoch: 95

Epoch: 96

Epoch: 97

Epoch: 98

Epoch: 99

Epoch: 100
TRAIN Iter 100: lr = 0.000375,	loss = 0.003256,	Top-1 err = 67.350000,	Top-5 err = 39.850000,	train_time = 15.345482
TEST Iter 100: loss = 4.109123,	Top-1 err = 81.620000,	Top-5 err = 56.990000,	val_time = 18.471330

Epoch: 101

Epoch: 102

Epoch: 103

Epoch: 104

Epoch: 105

Epoch: 106

Epoch: 107

Epoch: 108

Epoch: 109

Epoch: 110
TRAIN Iter 110: lr = 0.000352,	loss = 0.003153,	Top-1 err = 76.150000,	Top-5 err = 55.000000,	train_time = 17.746002
TEST Iter 110: loss = 3.891907,	Top-1 err = 80.910000,	Top-5 err = 55.360000,	val_time = 18.290100

Epoch: 111

Epoch: 112

Epoch: 113

Epoch: 114

Epoch: 115

Epoch: 116

Epoch: 117

Epoch: 118

Epoch: 119

Epoch: 120
TRAIN Iter 120: lr = 0.000327,	loss = 0.003074,	Top-1 err = 74.600000,	Top-5 err = 53.200000,	train_time = 15.294009
TEST Iter 120: loss = 3.839052,	Top-1 err = 79.520000,	Top-5 err = 53.810000,	val_time = 18.443567

Epoch: 121

Epoch: 122

Epoch: 123

Epoch: 124

Epoch: 125

Epoch: 126

Epoch: 127

Epoch: 128

Epoch: 129

Epoch: 130
TRAIN Iter 130: lr = 0.000302,	loss = 0.002880,	Top-1 err = 66.200000,	Top-5 err = 43.550000,	train_time = 15.089706
TEST Iter 130: loss = 3.895348,	Top-1 err = 79.190000,	Top-5 err = 53.650000,	val_time = 17.970152

Epoch: 131

Epoch: 132

Epoch: 133

Epoch: 134

Epoch: 135

Epoch: 136

Epoch: 137

Epoch: 138

Epoch: 139

Epoch: 140
TRAIN Iter 140: lr = 0.000276,	loss = 0.002759,	Top-1 err = 64.650000,	Top-5 err = 41.050000,	train_time = 15.429455
TEST Iter 140: loss = 3.797211,	Top-1 err = 76.610000,	Top-5 err = 50.650000,	val_time = 18.470815

Epoch: 141

Epoch: 142

Epoch: 143

Epoch: 144

Epoch: 145

Epoch: 146

Epoch: 147

Epoch: 148

Epoch: 149

Epoch: 150
TRAIN Iter 150: lr = 0.000250,	loss = 0.002768,	Top-1 err = 63.750000,	Top-5 err = 41.150000,	train_time = 15.181016
TEST Iter 150: loss = 3.617763,	Top-1 err = 74.840000,	Top-5 err = 48.020000,	val_time = 18.114333

Epoch: 151

Epoch: 152

Epoch: 153

Epoch: 154

Epoch: 155

Epoch: 156

Epoch: 157

Epoch: 158

Epoch: 159

Epoch: 160
TRAIN Iter 160: lr = 0.000224,	loss = 0.002592,	Top-1 err = 62.000000,	Top-5 err = 39.950000,	train_time = 15.375041
TEST Iter 160: loss = 3.392663,	Top-1 err = 73.230000,	Top-5 err = 44.830000,	val_time = 18.163988

Epoch: 161

Epoch: 162

Epoch: 163

Epoch: 164

Epoch: 165

Epoch: 166

Epoch: 167

Epoch: 168

Epoch: 169

Epoch: 170
TRAIN Iter 170: lr = 0.000198,	loss = 0.002586,	Top-1 err = 67.650000,	Top-5 err = 48.300000,	train_time = 15.078399
TEST Iter 170: loss = 3.632586,	Top-1 err = 73.680000,	Top-5 err = 45.790000,	val_time = 17.870536

Epoch: 171

Epoch: 172

Epoch: 173

Epoch: 174

Epoch: 175

Epoch: 176

Epoch: 177

Epoch: 178

Epoch: 179

Epoch: 180
TRAIN Iter 180: lr = 0.000173,	loss = 0.002561,	Top-1 err = 57.000000,	Top-5 err = 34.500000,	train_time = 15.253405
TEST Iter 180: loss = 3.540920,	Top-1 err = 72.430000,	Top-5 err = 45.260000,	val_time = 18.136591

Epoch: 181

Epoch: 182

Epoch: 183

Epoch: 184

Epoch: 185

Epoch: 186

Epoch: 187

Epoch: 188

Epoch: 189

Epoch: 190
TRAIN Iter 190: lr = 0.000148,	loss = 0.002429,	Top-1 err = 55.950000,	Top-5 err = 36.450000,	train_time = 15.470831
TEST Iter 190: loss = 3.093256,	Top-1 err = 68.650000,	Top-5 err = 39.910000,	val_time = 18.141578

Epoch: 191

Epoch: 192

Epoch: 193

Epoch: 194

Epoch: 195

Epoch: 196

Epoch: 197

Epoch: 198

Epoch: 199

Epoch: 200
TRAIN Iter 200: lr = 0.000125,	loss = 0.002396,	Top-1 err = 59.850000,	Top-5 err = 39.700000,	train_time = 15.084394
TEST Iter 200: loss = 3.172792,	Top-1 err = 69.480000,	Top-5 err = 40.970000,	val_time = 18.011199

Epoch: 201

Epoch: 202

Epoch: 203

Epoch: 204

Epoch: 205

Epoch: 206

Epoch: 207

Epoch: 208

Epoch: 209

Epoch: 210
TRAIN Iter 210: lr = 0.000103,	loss = 0.002333,	Top-1 err = 47.900000,	Top-5 err = 27.550000,	train_time = 15.083117
wandb: Waiting for W&B process to finish... (failed 255). Press Control-C to abort syncing.
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/multiprocessing/spawn.py", line 125, in _main
    prepare(preparation_data)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/multiprocessing/spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/runpy.py", line 265, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/media/techt/One Touch/DD/SRe2L/train/train_FKD.py", line 11, in <module>
    import torch
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/__init__.py", line 229, in <module>
    from torch._C import *  # noqa: F403
KeyboardInterrupt
Traceback (most recent call last):
  File "train_FKD.py", line 390, in <module>
    main()
  File "train_FKD.py", line 199, in main
    top1 = validate(model, args, epoch)
  File "train_FKD.py", line 333, in validate
    for data, target in args.val_loader:
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 441, in __iter__
    return self._get_iterator()
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 388, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1042, in __init__
    w.start()
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/multiprocessing/context.py", line 284, in _Popen
    return Popen(process_obj)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/multiprocessing/popen_spawn_posix.py", line 32, in __init__
    super().__init__(process_obj)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/multiprocessing/popen_spawn_posix.py", line 62, in _launch
    f.write(fp.getbuffer())
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py", line 175, in _teardown
    result = self._service.join()
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/wandb/sdk/service/service.py", line 258, in join
    ret = self._internal_proc.wait()
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/subprocess.py", line 1083, in wait
    return self._wait(timeout=timeout)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/subprocess.py", line 1822, in _wait
    (pid, sts) = self._try_wait(0)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/subprocess.py", line 1780, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
