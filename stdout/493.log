W&B disabled.
W&B online. Running your script from this directory will now sync to the cloud.
wandb: Currently logged in as: hl57. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /media/techt/One Touch/DD/SRe2L/train/wandb/run-20231108_194513-mc7bljff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-elevator-626
wandb: â­ï¸ View project at https://wandb.ai/hl57/final_rn18_fkd
wandb: ğŸš€ View run at https://wandb.ai/hl57/final_rn18_fkd/runs/mc7bljff
======= FKD: dataset info ======
path: ../relabel/FKD_cutmix_fp16/imagenette/484/
num img: 100
batch size: 100
max epoch: 300
================================
load data successfully
=> loading student model 'resnet50'
TRAIN Iter 0: lr = 0.001000,	loss = 0.020447,	Top-1 err = 93.000000,	Top-5 err = 49.000000,	train_time = 4.726531
TEST Iter 0: loss = 45.633537,	Top-1 err = 89.324841,	Top-5 err = 50.063694,	val_time = 14.105190
TRAIN Iter 10: lr = 0.000997,	loss = 0.015315,	Top-1 err = 74.000000,	Top-5 err = 27.000000,	train_time = 2.398813
TEST Iter 10: loss = 3.844553,	Top-1 err = 85.171975,	Top-5 err = 44.687898,	val_time = 13.721899
TRAIN Iter 20: lr = 0.000989,	loss = 0.016113,	Top-1 err = 67.000000,	Top-5 err = 11.000000,	train_time = 2.444960
TEST Iter 20: loss = 6.271683,	Top-1 err = 82.675159,	Top-5 err = 43.388535,	val_time = 13.293678
TRAIN Iter 30: lr = 0.000976,	loss = 0.011906,	Top-1 err = 78.000000,	Top-5 err = 27.000000,	train_time = 2.414719
TEST Iter 30: loss = 5.055170,	Top-1 err = 77.656051,	Top-5 err = 41.095541,	val_time = 13.215003
TRAIN Iter 40: lr = 0.000957,	loss = 0.012727,	Top-1 err = 51.000000,	Top-5 err = 16.000000,	train_time = 2.481896
TEST Iter 40: loss = 5.665558,	Top-1 err = 73.503185,	Top-5 err = 33.503185,	val_time = 13.232928
TRAIN Iter 50: lr = 0.000933,	loss = 0.014011,	Top-1 err = 37.000000,	Top-5 err = 8.000000,	train_time = 2.450302
TEST Iter 50: loss = 4.903038,	Top-1 err = 68.178344,	Top-5 err = 21.452229,	val_time = 13.579190
TRAIN Iter 60: lr = 0.000905,	loss = 0.012141,	Top-1 err = 42.000000,	Top-5 err = 5.000000,	train_time = 2.430827
TEST Iter 60: loss = 4.034319,	Top-1 err = 68.229299,	Top-5 err = 21.707006,	val_time = 13.625917
TRAIN Iter 70: lr = 0.000872,	loss = 0.010747,	Top-1 err = 59.000000,	Top-5 err = 18.000000,	train_time = 2.450866
TEST Iter 70: loss = 4.452375,	Top-1 err = 69.554140,	Top-5 err = 26.012739,	val_time = 13.464588
TRAIN Iter 80: lr = 0.000835,	loss = 0.009390,	Top-1 err = 53.000000,	Top-5 err = 6.000000,	train_time = 2.481048
TEST Iter 80: loss = 5.007982,	Top-1 err = 66.063694,	Top-5 err = 20.509554,	val_time = 13.324110
TRAIN Iter 90: lr = 0.000794,	loss = 0.010727,	Top-1 err = 24.000000,	Top-5 err = 4.000000,	train_time = 2.448922
TEST Iter 90: loss = 3.730366,	Top-1 err = 60.076433,	Top-5 err = 17.783439,	val_time = 13.371274
TRAIN Iter 100: lr = 0.000750,	loss = 0.007334,	Top-1 err = 64.000000,	Top-5 err = 7.000000,	train_time = 2.496490
TEST Iter 100: loss = 3.360585,	Top-1 err = 58.216561,	Top-5 err = 16.509554,	val_time = 13.296102
TRAIN Iter 110: lr = 0.000703,	loss = 0.007243,	Top-1 err = 30.000000,	Top-5 err = 5.000000,	train_time = 2.408866
TEST Iter 110: loss = 3.510720,	Top-1 err = 56.331210,	Top-5 err = 14.853503,	val_time = 13.281258
TRAIN Iter 120: lr = 0.000655,	loss = 0.006385,	Top-1 err = 32.000000,	Top-5 err = 5.000000,	train_time = 2.491458
TEST Iter 120: loss = 3.040328,	Top-1 err = 54.140127,	Top-5 err = 11.821656,	val_time = 13.413316
TRAIN Iter 130: lr = 0.000604,	loss = 0.006504,	Top-1 err = 17.000000,	Top-5 err = 1.000000,	train_time = 2.423866
TEST Iter 130: loss = 2.600653,	Top-1 err = 53.605096,	Top-5 err = 13.528662,	val_time = 13.691478
TRAIN Iter 140: lr = 0.000552,	loss = 0.006717,	Top-1 err = 49.000000,	Top-5 err = 3.000000,	train_time = 2.557528
TEST Iter 140: loss = 2.361173,	Top-1 err = 48.509554,	Top-5 err = 10.420382,	val_time = 13.661805
TRAIN Iter 150: lr = 0.000500,	loss = 0.005461,	Top-1 err = 65.000000,	Top-5 err = 12.000000,	train_time = 2.613445
TEST Iter 150: loss = 2.375549,	Top-1 err = 50.878981,	Top-5 err = 12.331210,	val_time = 13.538917
TRAIN Iter 160: lr = 0.000448,	loss = 0.005896,	Top-1 err = 34.000000,	Top-5 err = 4.000000,	train_time = 2.471361
TEST Iter 160: loss = 2.389708,	Top-1 err = 46.471338,	Top-5 err = 8.509554,	val_time = 13.662772
TRAIN Iter 170: lr = 0.000396,	loss = 0.004792,	Top-1 err = 23.000000,	Top-5 err = 1.000000,	train_time = 2.467485
TEST Iter 170: loss = 2.124037,	Top-1 err = 45.503185,	Top-5 err = 9.681529,	val_time = 13.422757
TRAIN Iter 180: lr = 0.000345,	loss = 0.004941,	Top-1 err = 13.000000,	Top-5 err = 2.000000,	train_time = 2.466475
TEST Iter 180: loss = 2.484991,	Top-1 err = 47.464968,	Top-5 err = 9.452229,	val_time = 13.585573
TRAIN Iter 190: lr = 0.000297,	loss = 0.003968,	Top-1 err = 27.000000,	Top-5 err = 3.000000,	train_time = 2.590152
TEST Iter 190: loss = 2.219838,	Top-1 err = 47.796178,	Top-5 err = 10.140127,	val_time = 13.989520
TRAIN Iter 200: lr = 0.000250,	loss = 0.004206,	Top-1 err = 18.000000,	Top-5 err = 0.000000,	train_time = 2.603424
TEST Iter 200: loss = 1.950788,	Top-1 err = 45.324841,	Top-5 err = 8.280255,	val_time = 13.549073
TRAIN Iter 210: lr = 0.000206,	loss = 0.004300,	Top-1 err = 29.000000,	Top-5 err = 1.000000,	train_time = 2.424657
TEST Iter 210: loss = 2.129020,	Top-1 err = 44.025478,	Top-5 err = 8.280255,	val_time = 13.482161
TRAIN Iter 220: lr = 0.000165,	loss = 0.004511,	Top-1 err = 26.000000,	Top-5 err = 5.000000,	train_time = 2.409722
TEST Iter 220: loss = 2.129462,	Top-1 err = 45.299363,	Top-5 err = 7.439490,	val_time = 13.518467
TRAIN Iter 230: lr = 0.000128,	loss = 0.004097,	Top-1 err = 23.000000,	Top-5 err = 1.000000,	train_time = 2.445342
TEST Iter 230: loss = 1.997490,	Top-1 err = 43.796178,	Top-5 err = 8.458599,	val_time = 14.106769
TRAIN Iter 240: lr = 0.000095,	loss = 0.003636,	Top-1 err = 15.000000,	Top-5 err = 3.000000,	train_time = 2.449063
TEST Iter 240: loss = 1.945089,	Top-1 err = 41.681529,	Top-5 err = 7.286624,	val_time = 13.770768
TRAIN Iter 250: lr = 0.000067,	loss = 0.003287,	Top-1 err = 18.000000,	Top-5 err = 3.000000,	train_time = 2.504398
TEST Iter 250: loss = 1.917949,	Top-1 err = 41.987261,	Top-5 err = 6.802548,	val_time = 13.385834
TRAIN Iter 260: lr = 0.000043,	loss = 0.004559,	Top-1 err = 52.000000,	Top-5 err = 10.000000,	train_time = 2.485123
TEST Iter 260: loss = 1.899299,	Top-1 err = 42.445860,	Top-5 err = 7.490446,	val_time = 13.875534
TRAIN Iter 270: lr = 0.000024,	loss = 0.003262,	Top-1 err = 31.000000,	Top-5 err = 1.000000,	train_time = 2.620251
TEST Iter 270: loss = 1.879047,	Top-1 err = 42.394904,	Top-5 err = 7.388535,	val_time = 14.191769
TRAIN Iter 280: lr = 0.000011,	loss = 0.003681,	Top-1 err = 29.000000,	Top-5 err = 1.000000,	train_time = 2.486734
TEST Iter 280: loss = 1.889116,	Top-1 err = 42.267516,	Top-5 err = 7.286624,	val_time = 13.803854
TRAIN Iter 290: lr = 0.000003,	loss = 0.003752,	Top-1 err = 26.000000,	Top-5 err = 2.000000,	train_time = 2.480646
TEST Iter 290: loss = 1.897162,	Top-1 err = 42.267516,	Top-5 err = 7.337580,	val_time = 13.616861
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.026 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.026 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  train/Top1 â–â–‚â–‚â–ƒâ–„â–„â–…â–„â–„â–„â–…â–„â–†â–‚â–†â–…â–ƒâ–„â–†â–„â–‚â–‡â–„â–„â–†â–…â–â–ˆâ–â–†â–ˆâ–ƒâ–…â–‡â–â–…â–„â–†â–„â–ˆ
wandb:  train/Top5 â–â–ƒâ–„â–†â–…â–…â–‡â–‡â–‡â–‡â–‡â–†â–‡â–…â–‡â–‡â–…â–‡â–ˆâ–‡â–†â–ˆâ–‡â–ˆâ–ˆâ–‡â–â–ˆâ–…â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ƒâ–‡â–‡â–ˆâ–‡â–ˆ
wandb: train/epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:  train/loss â–ˆâ–†â–†â–†â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–
wandb:    train/lr â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:   val/epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:    val/loss â–ˆâ–â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    val/top1 â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    val/top5 â–â–‚â–‚â–‚â–„â–†â–†â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:  train/Top1 93.0
wandb:  train/Top5 100.0
wandb: train/epoch 299
wandb:  train/loss 0.00329
wandb:    train/lr 0.0
wandb:   val/epoch 299
wandb:    val/loss 1.87749
wandb:    val/top1 58.03822
wandb:    val/top5 92.89172
wandb: 
wandb: ğŸš€ View run warm-elevator-626 at: https://wandb.ai/hl57/final_rn18_fkd/runs/mc7bljff
wandb: ï¸âš¡ View job at https://wandb.ai/hl57/final_rn18_fkd/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjk3MzkyNjU3/version_details/v57
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231108_194513-mc7bljff/logs
TEST Iter 299: loss = 1.877492,	Top-1 err = 41.961783,	Top-5 err = 7.108280,	val_time = 13.906408
