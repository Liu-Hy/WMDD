/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
r_bn:  1.0
lr:  0.1
bc shape torch.Size([200, 10, 512])
ipc_id =  0
get_images call
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
------------iteration 0----------
total loss 551.3054758717392
main criterion 134.0259043385361
weighted_aux_loss 417.2795715332031
loss_r_bn_feature 417.2795715332031
Verifier accuracy:  0.0
------------iteration 100----------
total loss 283.23178634843566
main criterion 77.874440767381
weighted_aux_loss 205.3573455810547
loss_r_bn_feature 205.3573455810547
Verifier accuracy:  0.0
------------iteration 200----------
total loss 211.2254394001968
main criterion 56.5939238972671
weighted_aux_loss 154.6315155029297
loss_r_bn_feature 154.6315155029297
Verifier accuracy:  0.0
------------iteration 300----------
total loss 168.3283007540839
main criterion 48.92600278045109
weighted_aux_loss 119.40229797363281
loss_r_bn_feature 119.40229797363281
Verifier accuracy:  0.0
------------iteration 400----------
total loss 175.16001331806845
main criterion 43.701074719435645
weighted_aux_loss 131.4589385986328
loss_r_bn_feature 131.4589385986328
Verifier accuracy:  0.0
------------iteration 500----------
total loss 144.11519018039934
main criterion 40.853425654032165
weighted_aux_loss 103.26176452636719
loss_r_bn_feature 103.26176452636719
Verifier accuracy:  0.0
------------iteration 600----------
total loss 129.9915127221349
main criterion 57.02014583981069
weighted_aux_loss 72.97136688232422
loss_r_bn_feature 72.97136688232422
Verifier accuracy:  0.0
------------iteration 700----------
total loss 109.43311219514574
main criterion 37.857161572587145
weighted_aux_loss 71.5759506225586
loss_r_bn_feature 71.5759506225586
Verifier accuracy:  0.0
------------iteration 800----------
total loss 115.3311192046971
main criterion 46.90339245909164
weighted_aux_loss 68.42772674560547
loss_r_bn_feature 68.42772674560547
Verifier accuracy:  0.0
------------iteration 900----------
total loss 94.63141100237692
main criterion 37.32691423724021
weighted_aux_loss 57.30449676513672
loss_r_bn_feature 57.30449676513672
Verifier accuracy:  0.0
------------iteration 1000----------
total loss 93.48560686611812
main criterion 46.31672258877437
weighted_aux_loss 47.16888427734375
loss_r_bn_feature 47.16888427734375
Verifier accuracy:  0.0
------------iteration 1100----------
total loss 161.39939040052678
main criterion 72.4673606764057
weighted_aux_loss 88.9320297241211
loss_r_bn_feature 88.9320297241211
Verifier accuracy:  0.0
------------iteration 1200----------
total loss 74.94059534651811
main criterion 32.112073618002476
weighted_aux_loss 42.828521728515625
loss_r_bn_feature 42.828521728515625
Verifier accuracy:  0.0
------------iteration 1300----------
total loss 73.19875437332041
main criterion 28.83055597854502
weighted_aux_loss 44.36819839477539
loss_r_bn_feature 44.36819839477539
Verifier accuracy:  0.0
------------iteration 1400----------
total loss 88.22499940757463
main criterion 45.18013475303361
weighted_aux_loss 43.044864654541016
loss_r_bn_feature 43.044864654541016
Verifier accuracy:  0.0
------------iteration 1500----------
total loss 61.974989443563295
main criterion 31.50543644978888
weighted_aux_loss 30.469552993774414
loss_r_bn_feature 30.469552993774414
Verifier accuracy:  0.0
------------iteration 1600----------
total loss 69.42239594022104
main criterion 35.6591284231312
weighted_aux_loss 33.763267517089844
loss_r_bn_feature 33.763267517089844
Verifier accuracy:  0.0
------------iteration 1700----------
total loss 114.24053987088993
main criterion 55.29462083402469
weighted_aux_loss 58.945919036865234
loss_r_bn_feature 58.945919036865234
Verifier accuracy:  0.0
------------iteration 1800----------
total loss 58.24187390339663
main criterion 36.17681042683413
weighted_aux_loss 22.0650634765625
loss_r_bn_feature 22.0650634765625
Verifier accuracy:  0.0
------------iteration 1900----------
total loss 45.326273257935114
main criterion 24.46032744189507
weighted_aux_loss 20.86594581604004
loss_r_bn_feature 20.86594581604004
Verifier accuracy:  0.0
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
------------iteration 0----------
total loss 549.1283892007788
main criterion 149.5985430093725
weighted_aux_loss 399.52984619140625
loss_r_bn_feature 399.52984619140625
Verifier accuracy:  0.0
------------iteration 100----------
total loss 273.9209295066597
main criterion 44.79692132794877
weighted_aux_loss 229.12400817871094
loss_r_bn_feature 229.12400817871094
Verifier accuracy:  0.0
------------iteration 200----------
total loss 195.79130335835436
main criterion 38.90868922261218
weighted_aux_loss 156.8826141357422
loss_r_bn_feature 156.8826141357422
Verifier accuracy:  0.0
------------iteration 300----------
total loss 167.15274904673217
main criterion 57.05711458628294
weighted_aux_loss 110.09563446044922
loss_r_bn_feature 110.09563446044922
Verifier accuracy:  0.0
------------iteration 400----------
total loss 142.1784909624514
main criterion 39.22396215385766
weighted_aux_loss 102.95452880859375
loss_r_bn_feature 102.95452880859375
Verifier accuracy:  0.0
------------iteration 500----------
total loss 141.12494095668737
main criterion 37.765863503074094
weighted_aux_loss 103.35907745361328
loss_r_bn_feature 103.35907745361328
Verifier accuracy:  0.0
------------iteration 600----------
total loss 123.57925893517637
main criterion 37.75446798058652
weighted_aux_loss 85.82479095458984
loss_r_bn_feature 85.82479095458984
Verifier accuracy:  0.0
------------iteration 700----------
total loss 117.02053140653855
main criterion 39.86701272978074
weighted_aux_loss 77.15351867675781
loss_r_bn_feature 77.15351867675781
Verifier accuracy:  0.0
------------iteration 800----------
total loss 98.45077784673165
main criterion 36.82973750249337
weighted_aux_loss 61.62104034423828
loss_r_bn_feature 61.62104034423828
Verifier accuracy:  0.0
------------iteration 900----------
total loss 92.52908466459232
main criterion 39.111470681438014
weighted_aux_loss 53.4176139831543
loss_r_bn_feature 53.4176139831543
Verifier accuracy:  0.0
------------iteration 1000----------
total loss 90.48155148939935
main criterion 36.216338476704045
weighted_aux_loss 54.26521301269531
loss_r_bn_feature 54.26521301269531
Verifier accuracy:  0.0
------------iteration 1100----------
total loss 82.99685482595771
main criterion 40.141790433867875
weighted_aux_loss 42.855064392089844
loss_r_bn_feature 42.855064392089844
Verifier accuracy:  0.0
------------iteration 1200----------
total loss 100.72979540596631
main criterion 49.83147616158155
weighted_aux_loss 50.898319244384766
loss_r_bn_feature 50.898319244384766
Verifier accuracy:  0.0
------------iteration 1300----------
total loss 70.66742593337305
main criterion 29.972773376000006
weighted_aux_loss 40.69465255737305
loss_r_bn_feature 40.69465255737305
Verifier accuracy:  0.0
------------iteration 1400----------
total loss 88.37822907555235
main criterion 45.05038636315002
weighted_aux_loss 43.327842712402344
loss_r_bn_feature 43.327842712402344
Verifier accuracy:  0.0
------------iteration 1500----------
total loss 54.09257760333985
main criterion 29.00123086261719
weighted_aux_loss 25.091346740722656
loss_r_bn_feature 25.091346740722656
Verifier accuracy:  0.0
------------iteration 1600----------
total loss 53.649727696722
main criterion 26.501406544988605
weighted_aux_loss 27.1483211517334
loss_r_bn_feature 27.1483211517334
Verifier accuracy:  0.0
------------iteration 1700----------
total loss 110.27774909788042
main criterion 54.204979932841354
weighted_aux_loss 56.07276916503906
loss_r_bn_feature 56.07276916503906
Verifier accuracy:  0.0
------------iteration 1800----------
total loss 44.32529761444038
main criterion 24.48115470062202
weighted_aux_loss 19.84414291381836
loss_r_bn_feature 19.84414291381836
Verifier accuracy:  0.0
------------iteration 1900----------
total loss 48.5490635655746
main criterion 28.710373761497447
weighted_aux_loss 19.83868980407715
loss_r_bn_feature 19.83868980407715
Verifier accuracy:  0.0
ipc_id =  1
get_images call
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
------------iteration 0----------
total loss 557.4938618593327
main criterion 131.13586015034835
weighted_aux_loss 426.3580017089844
loss_r_bn_feature 426.3580017089844
Verifier accuracy:  0.0
------------iteration 100----------
total loss 383.4985428962538
main criterion 87.75574504469132
weighted_aux_loss 295.7427978515625
loss_r_bn_feature 295.7427978515625
Verifier accuracy:  0.0
------------iteration 200----------
total loss 210.66405917335146
main criterion 40.645245086437406
weighted_aux_loss 170.01881408691406
loss_r_bn_feature 170.01881408691406
Verifier accuracy:  0.0
------------iteration 300----------
total loss 146.33355667709353
main criterion 48.384696508636495
weighted_aux_loss 97.94886016845703
loss_r_bn_feature 97.94886016845703
Verifier accuracy:  0.0
------------iteration 400----------
total loss 135.21802814753786
main criterion 39.73335560115115
weighted_aux_loss 95.48467254638672
loss_r_bn_feature 95.48467254638672
Verifier accuracy:  0.0
------------iteration 500----------
total loss 113.98448654855821
main criterion 35.225766150609
weighted_aux_loss 78.75872039794922
loss_r_bn_feature 78.75872039794922
Verifier accuracy:  0.0
------------iteration 600----------
total loss 372.1426444560635
main criterion 116.043401292001
weighted_aux_loss 256.0992431640625
loss_r_bn_feature 256.0992431640625
Verifier accuracy:  0.0
------------iteration 700----------
total loss 149.49897186271494
main criterion 59.255693359296956
weighted_aux_loss 90.24327850341797
loss_r_bn_feature 90.24327850341797
Verifier accuracy:  0.0
------------iteration 800----------
total loss 106.62446185287455
main criterion 43.14171572860697
weighted_aux_loss 63.48274612426758
loss_r_bn_feature 63.48274612426758
Verifier accuracy:  0.0
------------iteration 900----------
total loss 84.98068431498892
main criterion 32.948732410692045
weighted_aux_loss 52.031951904296875
loss_r_bn_feature 52.031951904296875
Verifier accuracy:  0.0
------------iteration 1000----------
total loss 86.21205542046482
main criterion 38.690124725884736
weighted_aux_loss 47.52193069458008
loss_r_bn_feature 47.52193069458008
Verifier accuracy:  0.0
------------iteration 1100----------
total loss 133.3872392136853
main criterion 65.2948319871228
weighted_aux_loss 68.0924072265625
loss_r_bn_feature 68.0924072265625
Verifier accuracy:  0.0
------------iteration 1200----------
total loss 73.67503272824212
main criterion 35.27719413571281
weighted_aux_loss 38.3978385925293
loss_r_bn_feature 38.3978385925293
Verifier accuracy:  0.0
------------iteration 1300----------
total loss 61.18692264365778
main criterion 28.090597723003487
weighted_aux_loss 33.0963249206543
loss_r_bn_feature 33.0963249206543
Verifier accuracy:  0.0
------------iteration 1400----------
total loss 66.52110564487654
main criterion 35.48734366672712
weighted_aux_loss 31.033761978149414
loss_r_bn_feature 31.033761978149414
Verifier accuracy:  0.0
------------iteration 1500----------
total loss 97.0705144849952
main criterion 52.34389857923348
weighted_aux_loss 44.72661590576172
loss_r_bn_feature 44.72661590576172
Verifier accuracy:  0.0
------------iteration 1600----------
total loss 87.28572340692654
main criterion 43.085261065617935
weighted_aux_loss 44.200462341308594
loss_r_bn_feature 44.200462341308594
Verifier accuracy:  0.0
------------iteration 1700----------
total loss 65.12215360301894
main criterion 39.65010007518691
weighted_aux_loss 25.47205352783203
loss_r_bn_feature 25.47205352783203
Verifier accuracy:  0.0
------------iteration 1800----------
total loss 75.46065039724954
main criterion 42.214945746370624
weighted_aux_loss 33.245704650878906
loss_r_bn_feature 33.245704650878906
Verifier accuracy:  0.0
------------iteration 1900----------
total loss 44.37432749313939
main criterion 26.13543779892552
weighted_aux_loss 18.238889694213867
loss_r_bn_feature 18.238889694213867
Verifier accuracy:  0.0
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
------------iteration 0----------
total loss 547.8261668982248
main criterion 154.96169546267782
weighted_aux_loss 392.8644714355469
loss_r_bn_feature 392.8644714355469
Verifier accuracy:  0.0
------------iteration 100----------
total loss 264.98368563010814
main criterion 48.9630252297175
weighted_aux_loss 216.02066040039062
loss_r_bn_feature 216.02066040039062
Verifier accuracy:  0.0
------------iteration 200----------
total loss 203.3293921805392
main criterion 48.25425790319546
weighted_aux_loss 155.07513427734375
loss_r_bn_feature 155.07513427734375
Verifier accuracy:  0.0
------------iteration 300----------
total loss 353.2960313443583
main criterion 112.72881637853803
weighted_aux_loss 240.5672149658203
loss_r_bn_feature 240.5672149658203
Verifier accuracy:  0.0
------------iteration 400----------
total loss 142.1157059168321
main criterion 42.85204930062115
weighted_aux_loss 99.26365661621094
loss_r_bn_feature 99.26365661621094
Verifier accuracy:  0.0
------------iteration 500----------
total loss 164.13624499548936
main criterion 44.22691272009873
weighted_aux_loss 119.90933227539062
loss_r_bn_feature 119.90933227539062
Verifier accuracy:  0.0
------------iteration 600----------
total loss 127.17285574622753
main criterion 44.45909537025097
weighted_aux_loss 82.71376037597656
loss_r_bn_feature 82.71376037597656
Verifier accuracy:  0.0
------------iteration 700----------
total loss 123.0522306435037
main criterion 50.444801139109174
weighted_aux_loss 72.60742950439453
loss_r_bn_feature 72.60742950439453
Verifier accuracy:  0.0
------------iteration 800----------
total loss 104.90768649411265
main criterion 42.096365235567724
weighted_aux_loss 62.81132125854492
loss_r_bn_feature 62.81132125854492
Verifier accuracy:  0.0
------------iteration 900----------
total loss 84.24716453417284
main criterion 34.24870948656541
weighted_aux_loss 49.99845504760742
loss_r_bn_feature 49.99845504760742
Verifier accuracy:  0.0
------------iteration 1000----------
total loss 183.6355209254807
main criterion 83.40457915301978
weighted_aux_loss 100.23094177246094
loss_r_bn_feature 100.23094177246094
Verifier accuracy:  0.0
------------iteration 1100----------
total loss 77.570033062144
main criterion 35.20147608582565
weighted_aux_loss 42.36855697631836
loss_r_bn_feature 42.36855697631836
Verifier accuracy:  0.0
------------iteration 1200----------
total loss 70.86796819686592
main criterion 35.11559164046944
weighted_aux_loss 35.752376556396484
loss_r_bn_feature 35.752376556396484
Verifier accuracy:  0.0
------------iteration 1300----------
total loss 63.411904731222236
main criterion 29.421048560567936
weighted_aux_loss 33.9908561706543
loss_r_bn_feature 33.9908561706543
Verifier accuracy:  0.0
------------iteration 1400----------
total loss 65.44860007762168
main criterion 28.529929423324806
weighted_aux_loss 36.918670654296875
loss_r_bn_feature 36.918670654296875
Verifier accuracy:  0.0
------------iteration 1500----------
total loss 72.08643434056256
main criterion 41.113274550523506
weighted_aux_loss 30.973159790039062
loss_r_bn_feature 30.973159790039062
Verifier accuracy:  0.0
------------iteration 1600----------
total loss 62.3051605432906
main criterion 32.89412309822224
weighted_aux_loss 29.41103744506836
loss_r_bn_feature 29.41103744506836
Verifier accuracy:  0.0
------------iteration 1700----------
total loss 65.09837280930807
main criterion 38.846417776959434
weighted_aux_loss 26.251955032348633
loss_r_bn_feature 26.251955032348633
Verifier accuracy:  0.0
------------iteration 1800----------
total loss 68.71467579028737
main criterion 41.01784313342702
weighted_aux_loss 27.69683265686035
loss_r_bn_feature 27.69683265686035
Verifier accuracy:  0.0
------------iteration 1900----------
total loss 54.89367336943917
main criterion 33.05753941252999
weighted_aux_loss 21.83613395690918
loss_r_bn_feature 21.83613395690918
Verifier accuracy:  0.0
ipc_id =  2
get_images call
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
------------iteration 0----------
total loss 572.1117255615418
main criterion 132.84353708497923
weighted_aux_loss 439.2681884765625
loss_r_bn_feature 439.2681884765625
Verifier accuracy:  0.0
------------iteration 100----------
total loss 252.54934673373188
main criterion 63.61849956576312
weighted_aux_loss 188.93084716796875
loss_r_bn_feature 188.93084716796875
Verifier accuracy:  0.0
------------iteration 200----------
total loss 309.5721432211678
main criterion 88.62245144870685
weighted_aux_loss 220.94969177246094
loss_r_bn_feature 220.94969177246094
Verifier accuracy:  0.0
------------iteration 300----------
total loss 166.40406500090256
main criterion 53.65977941740648
weighted_aux_loss 112.7442855834961
loss_r_bn_feature 112.7442855834961
Verifier accuracy:  0.0
------------iteration 400----------
total loss 144.07961852886163
main criterion 41.72231872417414
weighted_aux_loss 102.3572998046875
loss_r_bn_feature 102.3572998046875
Verifier accuracy:  0.0
------------iteration 500----------
total loss 130.69036169849142
main criterion 43.148270328862495
weighted_aux_loss 87.5420913696289
loss_r_bn_feature 87.5420913696289
Verifier accuracy:  0.0
------------iteration 600----------
total loss 129.52995401121953
main criterion 50.358056123035944
weighted_aux_loss 79.1718978881836
loss_r_bn_feature 79.1718978881836
Verifier accuracy:  0.0
------------iteration 700----------
total loss 148.56414861013707
main criterion 57.87792271902377
weighted_aux_loss 90.68622589111328
loss_r_bn_feature 90.68622589111328
Verifier accuracy:  0.0
------------iteration 800----------
total loss 110.7528550165143
main criterion 45.11861581973695
weighted_aux_loss 65.63423919677734
loss_r_bn_feature 65.63423919677734
Verifier accuracy:  0.0
------------iteration 900----------
total loss 101.58317908953873
main criterion 36.26351508807389
weighted_aux_loss 65.31966400146484
loss_r_bn_feature 65.31966400146484
Verifier accuracy:  0.0
------------iteration 1000----------
total loss 132.51715607747488
main criterion 61.62689728841237
weighted_aux_loss 70.8902587890625
loss_r_bn_feature 70.8902587890625
Verifier accuracy:  0.0
------------iteration 1100----------
total loss 98.49614565675125
main criterion 49.997568538831324
weighted_aux_loss 48.49857711791992
loss_r_bn_feature 48.49857711791992
Verifier accuracy:  0.0
------------iteration 1200----------
total loss 77.944447990416
main criterion 34.130071159361314
weighted_aux_loss 43.81437683105469
loss_r_bn_feature 43.81437683105469
Verifier accuracy:  0.0
------------iteration 1300----------
total loss 80.0638261748588
main criterion 41.22460803521036
weighted_aux_loss 38.83921813964844
loss_r_bn_feature 38.83921813964844
Verifier accuracy:  0.0
------------iteration 1400----------
total loss 65.49179596130239
main criterion 28.89523834411489
weighted_aux_loss 36.5965576171875
loss_r_bn_feature 36.5965576171875
Verifier accuracy:  0.0
------------iteration 1500----------
total loss 55.85441765578392
main criterion 26.830774162131576
weighted_aux_loss 29.023643493652344
loss_r_bn_feature 29.023643493652344
Verifier accuracy:  0.0
------------iteration 1600----------
total loss 61.31253836221575
main criterion 37.800899720858325
weighted_aux_loss 23.511638641357422
loss_r_bn_feature 23.511638641357422
Verifier accuracy:  0.0
------------iteration 1700----------
total loss 97.5567068984551
main criterion 50.32904195094533
weighted_aux_loss 47.227664947509766
loss_r_bn_feature 47.227664947509766
Verifier accuracy:  0.0
------------iteration 1800----------
total loss 223.09994517455715
main criterion 76.61396800170557
weighted_aux_loss 146.48597717285156
loss_r_bn_feature 146.48597717285156
Verifier accuracy:  0.0
------------iteration 1900----------
total loss 52.292129629720634
main criterion 30.84629260884661
weighted_aux_loss 21.445837020874023
loss_r_bn_feature 21.445837020874023
Verifier accuracy:  0.0
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
------------iteration 0----------
total loss 570.8761399146657
main criterion 132.33396462169696
weighted_aux_loss 438.54217529296875
loss_r_bn_feature 438.54217529296875
Verifier accuracy:  0.0
------------iteration 100----------
total loss 266.83156210194306
main criterion 47.75152975331025
weighted_aux_loss 219.0800323486328
loss_r_bn_feature 219.0800323486328
Verifier accuracy:  0.0
------------iteration 200----------
total loss 246.4582936398681
main criterion 66.84223529025873
weighted_aux_loss 179.61605834960938
loss_r_bn_feature 179.61605834960938
Verifier accuracy:  0.0
------------iteration 300----------
total loss 184.52239820514654
main criterion 40.244978161201225
weighted_aux_loss 144.2774200439453
loss_r_bn_feature 144.2774200439453
Verifier accuracy:  0.0
------------iteration 400----------
total loss 178.4847359653978
main criterion 72.96815729108138
weighted_aux_loss 105.5165786743164
loss_r_bn_feature 105.5165786743164
Verifier accuracy:  0.0
------------iteration 500----------
total loss 134.81625507010693
main criterion 39.96290729178662
weighted_aux_loss 94.85334777832031
loss_r_bn_feature 94.85334777832031
Verifier accuracy:  0.0
------------iteration 600----------
total loss 115.28979123663125
main criterion 41.22587216924843
weighted_aux_loss 74.06391906738281
loss_r_bn_feature 74.06391906738281
Verifier accuracy:  0.0
------------iteration 700----------
total loss 209.92933035058041
main criterion 93.3711256997015
weighted_aux_loss 116.5582046508789
loss_r_bn_feature 116.5582046508789
Verifier accuracy:  0.0
Traceback (most recent call last):
  File "data_synthesis.py", line 373, in <module>
    
  File "data_synthesis.py", line 295, in main_syn
    for p in model_verifier.parameters():
  File "data_synthesis.py", line 168, in get_images
    
KeyboardInterrupt
