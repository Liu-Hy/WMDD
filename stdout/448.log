r_bn:  10.0
lr:  0.25
Computing sample features for class 0
centroid_image shape: torch.Size([10, 3, 224, 224])
Computing sample features for class 1
centroid_image shape: torch.Size([10, 3, 224, 224])
Computing sample features for class 2
centroid_image shape: torch.Size([10, 3, 224, 224])
Computing sample features for class 3
centroid_image shape: torch.Size([10, 3, 224, 224])
Computing sample features for class 4
centroid_image shape: torch.Size([10, 3, 224, 224])
Computing sample features for class 5
centroid_image shape: torch.Size([10, 3, 224, 224])
Computing sample features for class 6
centroid_image shape: torch.Size([10, 3, 224, 224])
Computing sample features for class 7
centroid_image shape: torch.Size([10, 3, 224, 224])
Computing sample features for class 8
centroid_image shape: torch.Size([10, 3, 224, 224])
Computing sample features for class 9
centroid_image shape: torch.Size([10, 3, 224, 224])
Total centroid_images shape: torch.Size([10, 10, 3, 224, 224])
bc shape torch.Size([10, 10, 512])
Computing BatchNorm statistics for class 0
Computing BatchNorm statistics for class 1
Computing BatchNorm statistics for class 2
Computing BatchNorm statistics for class 3
Computing BatchNorm statistics for class 4
Computing BatchNorm statistics for class 5
Computing BatchNorm statistics for class 6
Computing BatchNorm statistics for class 7
Computing BatchNorm statistics for class 8
Computing BatchNorm statistics for class 9
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
get_images call
class_per_batch  10 batch_size  100 args.ipc  10
------------iteration 0----------
total loss 9725.829713877194
main criterion 99.27502637719442
weighted_aux_loss 9626.5546875
loss_r_bn_feature 962.655517578125
------------iteration 100----------
total loss 3418.9639875783814
main criterion 51.71667312525654
weighted_aux_loss 3367.247314453125
loss_r_bn_feature 336.7247314453125
------------iteration 200----------
total loss 2480.3937085497537
main criterion 43.314118706003605
weighted_aux_loss 2437.07958984375
loss_r_bn_feature 243.70794677734375
------------iteration 300----------
total loss 2128.1263160846233
main criterion 41.84506608462337
weighted_aux_loss 2086.28125
loss_r_bn_feature 208.62811279296875
------------iteration 400----------
total loss 2098.2875904841267
main criterion 39.55004165600154
weighted_aux_loss 2058.737548828125
loss_r_bn_feature 205.87374877929688
------------iteration 500----------
total loss 2245.446152470136
main criterion 40.2532813763862
weighted_aux_loss 2205.19287109375
loss_r_bn_feature 220.519287109375
------------iteration 600----------
total loss 2165.113478936163
main criterion 40.505568779913276
weighted_aux_loss 2124.60791015625
loss_r_bn_feature 212.46078491210938
------------iteration 700----------
total loss 1913.2433899357559
main criterion 38.91965946700579
weighted_aux_loss 1874.32373046875
loss_r_bn_feature 187.432373046875
------------iteration 800----------
total loss 2032.8662609012113
main criterion 52.034962073086376
weighted_aux_loss 1980.831298828125
loss_r_bn_feature 198.0831298828125
------------iteration 900----------
total loss 1598.295526074625
main criterion 40.49352412150004
weighted_aux_loss 1557.802001953125
loss_r_bn_feature 155.7801971435547
------------iteration 1000----------
total loss 1364.7760298546116
main criterion 36.20742633898663
weighted_aux_loss 1328.568603515625
loss_r_bn_feature 132.8568572998047
------------iteration 1100----------
total loss 1564.7890392622846
main criterion 39.60947383259721
weighted_aux_loss 1525.1795654296875
loss_r_bn_feature 152.51795959472656
------------iteration 1200----------
total loss 1910.2547279142043
main criterion 54.20467908607935
weighted_aux_loss 1856.050048828125
loss_r_bn_feature 185.60501098632812
------------iteration 1300----------
total loss 1270.2065542228597
main criterion 39.187389183797144
weighted_aux_loss 1231.0191650390625
loss_r_bn_feature 123.10191345214844
------------iteration 1400----------
total loss 1245.6788432454348
main criterion 41.96338914387231
weighted_aux_loss 1203.7154541015625
loss_r_bn_feature 120.37154388427734
------------iteration 1500----------
total loss 1217.193361097482
main criterion 41.73327808966944
weighted_aux_loss 1175.4600830078125
loss_r_bn_feature 117.54601287841797
------------iteration 1600----------
total loss 779.642234312994
main criterion 32.184287535650206
weighted_aux_loss 747.4579467773438
loss_r_bn_feature 74.74579620361328
------------iteration 1700----------
total loss 852.2114275458358
main criterion 39.44482598333582
weighted_aux_loss 812.7666015625
loss_r_bn_feature 81.27665710449219
------------iteration 1800----------
total loss 533.042407081069
main criterion 30.162951514662716
weighted_aux_loss 502.87945556640625
loss_r_bn_feature 50.28794479370117
------------iteration 1900----------
total loss 672.9258680992821
main criterion 33.23263079459453
weighted_aux_loss 639.6932373046875
loss_r_bn_feature 63.96932601928711
=> using pytorch pre-trained model 'resnet18'
process data from ../recover/syn_data/imagenette/448
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 1/300 [00:01<09:33,  1.92s/it]  1%|          | 2/300 [00:02<05:43,  1.15s/it]  1%|          | 3/300 [00:03<04:24,  1.12it/s]  1%|▏         | 4/300 [00:03<03:50,  1.29it/s]  2%|▏         | 5/300 [00:04<03:34,  1.38it/s]  2%|▏         | 6/300 [00:04<03:22,  1.45it/s]  2%|▏         | 7/300 [00:05<03:13,  1.52it/s]  3%|▎         | 8/300 [00:06<03:10,  1.53it/s]  3%|▎         | 9/300 [00:06<03:05,  1.57it/s]  3%|▎         | 10/300 [00:07<03:03,  1.58it/s]  4%|▎         | 11/300 [00:08<03:00,  1.60it/s]  4%|▍         | 12/300 [00:08<02:55,  1.64it/s]  4%|▍         | 13/300 [00:09<02:56,  1.63it/s]  5%|▍         | 14/300 [00:09<02:55,  1.63it/s]  5%|▌         | 15/300 [00:10<02:56,  1.62it/s]  5%|▌         | 16/300 [00:11<02:55,  1.62it/s]  6%|▌         | 17/300 [00:11<02:55,  1.61it/s]  6%|▌         | 18/300 [00:12<02:54,  1.62it/s]  6%|▋         | 19/300 [00:12<02:51,  1.64it/s]  7%|▋         | 20/300 [00:13<02:48,  1.66it/s]  7%|▋         | 21/300 [00:14<02:48,  1.66it/s]  7%|▋         | 22/300 [00:14<02:49,  1.64it/s]  8%|▊         | 23/300 [00:15<02:47,  1.66it/s]  8%|▊         | 24/300 [00:15<02:45,  1.66it/s]  8%|▊         | 25/300 [00:16<02:45,  1.66it/s]  9%|▊         | 26/300 [00:17<02:45,  1.65it/s]  9%|▉         | 27/300 [00:17<02:43,  1.67it/s]  9%|▉         | 28/300 [00:18<02:44,  1.65it/s] 10%|▉         | 29/300 [00:18<02:46,  1.63it/s] 10%|█         | 30/300 [00:19<02:45,  1.63it/s] 10%|█         | 31/300 [00:20<02:45,  1.63it/s] 11%|█         | 32/300 [00:20<02:46,  1.61it/s] 11%|█         | 33/300 [00:21<02:43,  1.63it/s] 11%|█▏        | 34/300 [00:22<02:42,  1.64it/s] 12%|█▏        | 35/300 [00:22<02:41,  1.64it/s] 12%|█▏        | 36/300 [00:23<02:42,  1.63it/s] 12%|█▏        | 37/300 [00:23<02:43,  1.61it/s] 13%|█▎        | 38/300 [00:24<02:41,  1.62it/s] 13%|█▎        | 39/300 [00:25<02:41,  1.62it/s] 13%|█▎        | 40/300 [00:25<02:42,  1.60it/s] 14%|█▎        | 41/300 [00:26<02:41,  1.60it/s] 14%|█▍        | 42/300 [00:27<02:40,  1.61it/s] 14%|█▍        | 43/300 [00:27<02:37,  1.63it/s] 15%|█▍        | 44/300 [00:28<02:38,  1.62it/s] 15%|█▌        | 45/300 [00:28<02:36,  1.63it/s] 15%|█▌        | 46/300 [00:29<02:37,  1.62it/s] 16%|█▌        | 47/300 [00:30<02:34,  1.64it/s] 16%|█▌        | 48/300 [00:30<02:33,  1.64it/s] 16%|█▋        | 49/300 [00:31<02:32,  1.64it/s] 17%|█▋        | 50/300 [00:31<02:31,  1.66it/s] 17%|█▋        | 51/300 [00:32<02:29,  1.66it/s] 17%|█▋        | 52/300 [00:33<02:27,  1.68it/s] 18%|█▊        | 53/300 [00:33<02:27,  1.67it/s] 18%|█▊        | 54/300 [00:34<02:27,  1.66it/s] 18%|█▊        | 55/300 [00:34<02:26,  1.67it/s] 19%|█▊        | 56/300 [00:35<02:25,  1.68it/s] 19%|█▉        | 57/300 [00:36<02:25,  1.68it/s] 19%|█▉        | 58/300 [00:36<02:23,  1.69it/s] 20%|█▉        | 59/300 [00:37<02:23,  1.68it/s] 20%|██        | 60/300 [00:37<02:23,  1.67it/s] 20%|██        | 61/300 [00:38<02:22,  1.68it/s] 21%|██        | 62/300 [00:39<02:25,  1.64it/s] 21%|██        | 63/300 [00:39<02:34,  1.54it/s] 21%|██▏       | 64/300 [00:40<02:33,  1.53it/s] 22%|██▏       | 65/300 [00:41<02:32,  1.54it/s] 22%|██▏       | 66/300 [00:41<02:28,  1.58it/s] 22%|██▏       | 67/300 [00:42<02:26,  1.59it/s] 23%|██▎       | 68/300 [00:42<02:26,  1.59it/s] 23%|██▎       | 69/300 [00:43<02:25,  1.59it/s] 23%|██▎       | 70/300 [00:44<02:22,  1.61it/s] 24%|██▎       | 71/300 [00:44<02:24,  1.59it/s] 24%|██▍       | 72/300 [00:45<02:23,  1.59it/s] 24%|██▍       | 73/300 [00:46<02:22,  1.59it/s] 25%|██▍       | 74/300 [00:46<02:20,  1.61it/s] 25%|██▌       | 75/300 [00:47<02:20,  1.61it/s] 25%|██▌       | 76/300 [00:47<02:21,  1.59it/s] 26%|██▌       | 77/300 [00:48<02:21,  1.57it/s] 26%|██▌       | 78/300 [00:49<02:21,  1.57it/s] 26%|██▋       | 79/300 [00:49<02:20,  1.57it/s] 27%|██▋       | 80/300 [00:50<02:18,  1.59it/s] 27%|██▋       | 81/300 [00:51<02:19,  1.57it/s] 27%|██▋       | 82/300 [00:51<02:17,  1.59it/s] 28%|██▊       | 83/300 [00:52<02:14,  1.62it/s] 28%|██▊       | 84/300 [00:53<02:15,  1.60it/s] 28%|██▊       | 85/300 [00:53<02:15,  1.58it/s] 29%|██▊       | 86/300 [00:54<02:16,  1.56it/s] 29%|██▉       | 87/300 [00:54<02:13,  1.60it/s] 29%|██▉       | 88/300 [00:55<02:11,  1.61it/s] 30%|██▉       | 89/300 [00:56<02:11,  1.60it/s] 30%|███       | 90/300 [00:56<02:10,  1.60it/s] 30%|███       | 91/300 [00:57<02:09,  1.62it/s] 31%|███       | 92/300 [00:58<02:09,  1.60it/s] 31%|███       | 93/300 [00:58<02:08,  1.62it/s] 31%|███▏      | 94/300 [00:59<02:06,  1.63it/s] 32%|███▏      | 95/300 [00:59<02:05,  1.63it/s] 32%|███▏      | 96/300 [01:00<02:04,  1.64it/s] 32%|███▏      | 97/300 [01:01<02:04,  1.62it/s] 33%|███▎      | 98/300 [01:01<02:01,  1.66it/s] 33%|███▎      | 99/300 [01:02<02:00,  1.67it/s] 33%|███▎      | 100/300 [01:02<02:00,  1.66it/s] 34%|███▎      | 101/300 [01:03<01:59,  1.67it/s] 34%|███▍      | 102/300 [01:04<01:57,  1.69it/s] 34%|███▍      | 103/300 [01:04<01:57,  1.67it/s] 35%|███▍      | 104/300 [01:05<01:57,  1.67it/s] 35%|███▌      | 105/300 [01:05<01:54,  1.70it/s] 35%|███▌      | 106/300 [01:06<01:54,  1.69it/s] 36%|███▌      | 107/300 [01:06<01:54,  1.68it/s] 36%|███▌      | 108/300 [01:07<01:52,  1.70it/s] 36%|███▋      | 109/300 [01:08<01:53,  1.68it/s] 37%|███▋      | 110/300 [01:08<01:53,  1.67it/s] 37%|███▋      | 111/300 [01:09<01:53,  1.67it/s] 37%|███▋      | 112/300 [01:09<01:51,  1.69it/s] 38%|███▊      | 113/300 [01:10<01:52,  1.67it/s] 38%|███▊      | 114/300 [01:11<01:51,  1.66it/s] 38%|███▊      | 115/300 [01:11<01:50,  1.67it/s] 39%|███▊      | 116/300 [01:12<01:50,  1.67it/s] 39%|███▉      | 117/300 [01:12<01:50,  1.66it/s] 39%|███▉      | 118/300 [01:13<01:48,  1.67it/s] 40%|███▉      | 119/300 [01:14<01:47,  1.68it/s] 40%|████      | 120/300 [01:14<01:45,  1.71it/s] 40%|████      | 121/300 [01:15<01:45,  1.70it/s] 41%|████      | 122/300 [01:15<01:44,  1.70it/s] 41%|████      | 123/300 [01:16<01:44,  1.70it/s] 41%|████▏     | 124/300 [01:17<01:44,  1.69it/s] 42%|████▏     | 125/300 [01:17<01:42,  1.70it/s] 42%|████▏     | 126/300 [01:18<01:43,  1.69it/s] 42%|████▏     | 127/300 [01:18<01:42,  1.68it/s] 43%|████▎     | 128/300 [01:19<01:42,  1.67it/s] 43%|████▎     | 129/300 [01:20<01:40,  1.70it/s] 43%|████▎     | 130/300 [01:20<01:41,  1.68it/s] 44%|████▎     | 131/300 [01:21<01:41,  1.67it/s] 44%|████▍     | 132/300 [01:21<01:40,  1.67it/s] 44%|████▍     | 133/300 [01:22<01:40,  1.67it/s] 45%|████▍     | 134/300 [01:23<01:39,  1.66it/s] 45%|████▌     | 135/300 [01:23<01:37,  1.69it/s] 45%|████▌     | 136/300 [01:24<01:37,  1.68it/s] 46%|████▌     | 137/300 [01:24<01:38,  1.66it/s] 46%|████▌     | 138/300 [01:25<01:37,  1.66it/s] 46%|████▋     | 139/300 [01:26<01:36,  1.66it/s] 47%|████▋     | 140/300 [01:26<01:35,  1.67it/s] 47%|████▋     | 141/300 [01:27<01:34,  1.69it/s] 47%|████▋     | 142/300 [01:27<01:33,  1.68it/s] 48%|████▊     | 143/300 [01:28<01:33,  1.67it/s] 48%|████▊     | 144/300 [01:29<01:33,  1.67it/s] 48%|████▊     | 145/300 [01:29<01:32,  1.67it/s] 49%|████▊     | 146/300 [01:30<01:33,  1.66it/s] 49%|████▉     | 147/300 [01:30<01:32,  1.65it/s] 49%|████▉     | 148/300 [01:31<01:31,  1.66it/s] 50%|████▉     | 149/300 [01:32<01:31,  1.66it/s] 50%|█████     | 150/300 [01:32<01:30,  1.66it/s] 50%|█████     | 151/300 [01:33<01:29,  1.66it/s] 51%|█████     | 152/300 [01:33<01:27,  1.69it/s] 51%|█████     | 153/300 [01:34<01:27,  1.68it/s] 51%|█████▏    | 154/300 [01:35<01:28,  1.66it/s] 52%|█████▏    | 155/300 [01:35<01:27,  1.65it/s] 52%|█████▏    | 156/300 [01:36<01:27,  1.65it/s] 52%|█████▏    | 157/300 [01:36<01:25,  1.66it/s] 53%|█████▎    | 158/300 [01:37<01:24,  1.69it/s] 53%|█████▎    | 159/300 [01:38<01:23,  1.68it/s] 53%|█████▎    | 160/300 [01:38<01:23,  1.68it/s] 54%|█████▎    | 161/300 [01:39<01:22,  1.68it/s] 54%|█████▍    | 162/300 [01:39<01:22,  1.67it/s] 54%|█████▍    | 163/300 [01:40<01:22,  1.66it/s] 55%|█████▍    | 164/300 [01:41<01:22,  1.65it/s] 55%|█████▌    | 165/300 [01:41<01:20,  1.68it/s] 55%|█████▌    | 166/300 [01:42<01:19,  1.68it/s] 56%|█████▌    | 167/300 [01:42<01:19,  1.68it/s] 56%|█████▌    | 168/300 [01:43<01:18,  1.69it/s] 56%|█████▋    | 169/300 [01:44<01:19,  1.65it/s] 57%|█████▋    | 170/300 [01:44<01:19,  1.64it/s] 57%|█████▋    | 171/300 [01:45<01:18,  1.65it/s] 57%|█████▋    | 172/300 [01:45<01:16,  1.67it/s] 58%|█████▊    | 173/300 [01:46<01:16,  1.66it/s] 58%|█████▊    | 174/300 [01:47<01:16,  1.66it/s] 58%|█████▊    | 175/300 [01:47<01:14,  1.68it/s] 59%|█████▊    | 176/300 [01:48<01:13,  1.68it/s] 59%|█████▉    | 177/300 [01:48<01:12,  1.69it/s] 59%|█████▉    | 178/300 [01:49<01:13,  1.67it/s] 60%|█████▉    | 179/300 [01:50<01:13,  1.66it/s] 60%|██████    | 180/300 [01:50<01:12,  1.66it/s] 60%|██████    | 181/300 [01:51<01:12,  1.64it/s] 61%|██████    | 182/300 [01:51<01:13,  1.61it/s] 61%|██████    | 183/300 [01:52<01:12,  1.61it/s] 61%|██████▏   | 184/300 [01:53<01:13,  1.58it/s] 62%|██████▏   | 185/300 [01:53<01:12,  1.59it/s] 62%|██████▏   | 186/300 [01:54<01:10,  1.62it/s] 62%|██████▏   | 187/300 [01:55<01:10,  1.61it/s] 63%|██████▎   | 188/300 [01:55<01:09,  1.60it/s] 63%|██████▎   | 189/300 [01:56<01:10,  1.58it/s] 63%|██████▎   | 190/300 [01:56<01:09,  1.58it/s] 64%|██████▎   | 191/300 [01:57<01:08,  1.59it/s] 64%|██████▍   | 192/300 [01:58<01:08,  1.58it/s] 64%|██████▍   | 193/300 [01:58<01:07,  1.59it/s] 65%|██████▍   | 194/300 [01:59<01:06,  1.59it/s] 65%|██████▌   | 195/300 [02:00<01:06,  1.59it/s] 65%|██████▌   | 196/300 [02:00<01:05,  1.60it/s] 66%|██████▌   | 197/300 [02:01<01:03,  1.61it/s] 66%|██████▌   | 198/300 [02:01<01:02,  1.64it/s] 66%|██████▋   | 199/300 [02:02<01:01,  1.65it/s] 67%|██████▋   | 200/300 [02:03<01:00,  1.65it/s] 67%|██████▋   | 201/300 [02:03<01:00,  1.63it/s] 67%|██████▋   | 202/300 [02:04<01:00,  1.62it/s] 68%|██████▊   | 203/300 [02:05<01:00,  1.60it/s] 68%|██████▊   | 204/300 [02:05<00:58,  1.64it/s] 68%|██████▊   | 205/300 [02:06<00:58,  1.64it/s] 69%|██████▊   | 206/300 [02:06<00:57,  1.64it/s] 69%|██████▉   | 207/300 [02:07<00:57,  1.62it/s] 69%|██████▉   | 208/300 [02:08<00:56,  1.62it/s] 70%|██████▉   | 209/300 [02:08<00:56,  1.62it/s] 70%|███████   | 210/300 [02:09<00:55,  1.61it/s] 70%|███████   | 211/300 [02:09<00:55,  1.60it/s] 71%|███████   | 212/300 [02:10<00:54,  1.63it/s] 71%|███████   | 213/300 [02:11<00:53,  1.63it/s] 71%|███████▏  | 214/300 [02:11<00:52,  1.63it/s] 72%|███████▏  | 215/300 [02:12<00:51,  1.64it/s] 72%|███████▏  | 216/300 [02:12<00:51,  1.63it/s] 72%|███████▏  | 217/300 [02:13<00:51,  1.60it/s] 73%|███████▎  | 218/300 [02:14<00:51,  1.59it/s] 73%|███████▎  | 219/300 [02:14<00:50,  1.60it/s] 73%|███████▎  | 220/300 [02:15<00:50,  1.59it/s] 74%|███████▎  | 221/300 [02:16<00:49,  1.60it/s] 74%|███████▍  | 222/300 [02:16<00:48,  1.59it/s] 74%|███████▍  | 223/300 [02:17<00:48,  1.60it/s] 75%|███████▍  | 224/300 [02:18<00:47,  1.60it/s] 75%|███████▌  | 225/300 [02:18<00:46,  1.61it/s] 75%|███████▌  | 226/300 [02:19<00:46,  1.61it/s] 76%|███████▌  | 227/300 [02:19<00:45,  1.60it/s] 76%|███████▌  | 228/300 [02:20<00:45,  1.60it/s] 76%|███████▋  | 229/300 [02:21<00:44,  1.61it/s] 77%|███████▋  | 230/300 [02:21<00:43,  1.62it/s] 77%|███████▋  | 231/300 [02:22<00:42,  1.64it/s] 77%|███████▋  | 232/300 [02:22<00:41,  1.65it/s] 78%|███████▊  | 233/300 [02:23<00:40,  1.66it/s] 78%|███████▊  | 234/300 [02:24<00:39,  1.66it/s] 78%|███████▊  | 235/300 [02:24<00:39,  1.66it/s] 79%|███████▊  | 236/300 [02:25<00:38,  1.68it/s] 79%|███████▉  | 237/300 [02:25<00:37,  1.69it/s] 79%|███████▉  | 238/300 [02:26<00:36,  1.68it/s] 80%|███████▉  | 239/300 [02:27<00:35,  1.71it/s] 80%|████████  | 240/300 [02:27<00:35,  1.70it/s] 80%|████████  | 241/300 [02:28<00:34,  1.70it/s] 81%|████████  | 242/300 [02:28<00:34,  1.69it/s] 81%|████████  | 243/300 [02:29<00:33,  1.71it/s] 81%|████████▏ | 244/300 [02:30<00:33,  1.69it/s] 82%|████████▏ | 245/300 [02:30<00:32,  1.68it/s] 82%|████████▏ | 246/300 [02:31<00:32,  1.68it/s] 82%|████████▏ | 247/300 [02:31<00:31,  1.67it/s] 83%|████████▎ | 248/300 [02:32<00:30,  1.68it/s] 83%|████████▎ | 249/300 [02:33<00:30,  1.66it/s] 83%|████████▎ | 250/300 [02:33<00:29,  1.69it/s] 84%|████████▎ | 251/300 [02:34<00:28,  1.71it/s] 84%|████████▍ | 252/300 [02:34<00:27,  1.73it/s] 84%|████████▍ | 253/300 [02:35<00:27,  1.72it/s] 85%|████████▍ | 254/300 [02:35<00:27,  1.70it/s] 85%|████████▌ | 255/300 [02:36<00:26,  1.70it/s] 85%|████████▌ | 256/300 [02:37<00:25,  1.70it/s] 86%|████████▌ | 257/300 [02:37<00:25,  1.70it/s] 86%|████████▌ | 258/300 [02:38<00:24,  1.71it/s] 86%|████████▋ | 259/300 [02:38<00:24,  1.71it/s] 87%|████████▋ | 260/300 [02:39<00:23,  1.70it/s] 87%|████████▋ | 261/300 [02:40<00:22,  1.72it/s] 87%|████████▋ | 262/300 [02:40<00:22,  1.71it/s] 88%|████████▊ | 263/300 [02:41<00:21,  1.73it/s] 88%|████████▊ | 264/300 [02:41<00:21,  1.71it/s] 88%|████████▊ | 265/300 [02:42<00:20,  1.70it/s] 89%|████████▊ | 266/300 [02:42<00:20,  1.68it/s] 89%|████████▉ | 267/300 [02:43<00:19,  1.67it/s] 89%|████████▉ | 268/300 [02:44<00:19,  1.68it/s] 90%|████████▉ | 269/300 [02:44<00:18,  1.67it/s] 90%|█████████ | 270/300 [02:45<00:17,  1.68it/s] 90%|█████████ | 271/300 [02:45<00:17,  1.68it/s] 91%|█████████ | 272/300 [02:46<00:16,  1.68it/s] 91%|█████████ | 273/300 [02:47<00:15,  1.71it/s] 91%|█████████▏| 274/300 [02:47<00:15,  1.69it/s] 92%|█████████▏| 275/300 [02:48<00:14,  1.67it/s] 92%|█████████▏| 276/300 [02:48<00:14,  1.66it/s] 92%|█████████▏| 277/300 [02:49<00:13,  1.66it/s] 93%|█████████▎| 278/300 [02:50<00:13,  1.66it/s] 93%|█████████▎| 279/300 [02:50<00:12,  1.67it/s] 93%|█████████▎| 280/300 [02:51<00:11,  1.68it/s] 94%|█████████▎| 281/300 [02:51<00:11,  1.68it/s] 94%|█████████▍| 282/300 [02:52<00:10,  1.68it/s] 94%|█████████▍| 283/300 [02:53<00:10,  1.68it/s] 95%|█████████▍| 284/300 [02:53<00:09,  1.68it/s] 95%|█████████▌| 285/300 [02:54<00:08,  1.69it/s] 95%|█████████▌| 286/300 [02:54<00:08,  1.69it/s] 96%|█████████▌| 287/300 [02:55<00:07,  1.70it/s] 96%|█████████▌| 288/300 [02:56<00:07,  1.69it/s] 96%|█████████▋| 289/300 [02:56<00:06,  1.71it/s] 97%|█████████▋| 290/300 [02:57<00:05,  1.72it/s] 97%|█████████▋| 291/300 [02:57<00:05,  1.70it/s] 97%|█████████▋| 292/300 [02:58<00:04,  1.70it/s] 98%|█████████▊| 293/300 [02:59<00:04,  1.69it/s] 98%|█████████▊| 294/300 [02:59<00:03,  1.70it/s] 98%|█████████▊| 295/300 [03:00<00:02,  1.69it/s] 99%|█████████▊| 296/300 [03:00<00:02,  1.67it/s] 99%|█████████▉| 297/300 [03:01<00:01,  1.67it/s] 99%|█████████▉| 298/300 [03:02<00:01,  1.67it/s]100%|█████████▉| 299/300 [03:02<00:00,  1.67it/s]100%|██████████| 300/300 [03:03<00:00,  1.70it/s]100%|██████████| 300/300 [03:03<00:00,  1.64it/s]
W&B disabled.
W&B online. Running your script from this directory will now sync to the cloud.
wandb: Currently logged in as: hl57. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /media/techt/One Touch/DD/SRe2L/train/wandb/run-20231030_150139-pbp6frt8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ghostly-orb-577
wandb: ⭐️ View project at https://wandb.ai/hl57/final_rn18_fkd
wandb: 🚀 View run at https://wandb.ai/hl57/final_rn18_fkd/runs/pbp6frt8
======= FKD: dataset info ======
path: ../relabel/FKD_cutmix_fp16/imagenette/448/
num img: 100
batch size: 100
max epoch: 300
================================
load data successfully
=> loading student model 'resnet18'
TRAIN Iter 0: lr = 0.001000,	loss = 0.016499,	Top-1 err = 90.000000,	Top-5 err = 49.000000,	train_time = 3.300628
TEST Iter 0: loss = 14.329912,	Top-1 err = 90.089172,	Top-5 err = 49.859873,	val_time = 13.025011
TRAIN Iter 10: lr = 0.000997,	loss = 0.012484,	Top-1 err = 67.000000,	Top-5 err = 19.000000,	train_time = 2.281794
TEST Iter 10: loss = 20.102427,	Top-1 err = 85.121019,	Top-5 err = 38.751592,	val_time = 13.073473
TRAIN Iter 20: lr = 0.000989,	loss = 0.012544,	Top-1 err = 56.000000,	Top-5 err = 11.000000,	train_time = 2.285302
TEST Iter 20: loss = 8.209523,	Top-1 err = 76.687898,	Top-5 err = 33.707006,	val_time = 13.003486
TRAIN Iter 30: lr = 0.000976,	loss = 0.011448,	Top-1 err = 42.000000,	Top-5 err = 8.000000,	train_time = 2.319997
TEST Iter 30: loss = 6.257045,	Top-1 err = 72.331210,	Top-5 err = 27.719745,	val_time = 13.044946
TRAIN Iter 40: lr = 0.000957,	loss = 0.010224,	Top-1 err = 39.000000,	Top-5 err = 9.000000,	train_time = 2.291949
TEST Iter 40: loss = 4.530281,	Top-1 err = 65.936306,	Top-5 err = 21.656051,	val_time = 13.095353
TRAIN Iter 50: lr = 0.000933,	loss = 0.008645,	Top-1 err = 70.000000,	Top-5 err = 23.000000,	train_time = 2.243011
TEST Iter 50: loss = 4.655583,	Top-1 err = 59.821656,	Top-5 err = 18.853503,	val_time = 12.895114
TRAIN Iter 60: lr = 0.000905,	loss = 0.008284,	Top-1 err = 58.000000,	Top-5 err = 19.000000,	train_time = 2.286829
TEST Iter 60: loss = 3.267276,	Top-1 err = 56.509554,	Top-5 err = 13.222930,	val_time = 13.146877
TRAIN Iter 70: lr = 0.000872,	loss = 0.008177,	Top-1 err = 22.000000,	Top-5 err = 2.000000,	train_time = 2.300101
TEST Iter 70: loss = 4.008826,	Top-1 err = 60.076433,	Top-5 err = 18.777070,	val_time = 12.941727
TRAIN Iter 80: lr = 0.000835,	loss = 0.006832,	Top-1 err = 24.000000,	Top-5 err = 2.000000,	train_time = 2.223216
TEST Iter 80: loss = 3.418939,	Top-1 err = 58.267516,	Top-5 err = 14.191083,	val_time = 13.367875
TRAIN Iter 90: lr = 0.000794,	loss = 0.006211,	Top-1 err = 34.000000,	Top-5 err = 2.000000,	train_time = 2.239158
TEST Iter 90: loss = 2.887301,	Top-1 err = 50.343949,	Top-5 err = 10.675159,	val_time = 13.126970
TRAIN Iter 100: lr = 0.000750,	loss = 0.006361,	Top-1 err = 33.000000,	Top-5 err = 7.000000,	train_time = 2.308120
TEST Iter 100: loss = 2.714936,	Top-1 err = 49.401274,	Top-5 err = 11.312102,	val_time = 12.832920
TRAIN Iter 110: lr = 0.000703,	loss = 0.005515,	Top-1 err = 68.000000,	Top-5 err = 15.000000,	train_time = 2.257845
TEST Iter 110: loss = 2.355974,	Top-1 err = 49.019108,	Top-5 err = 10.547771,	val_time = 12.931180
TRAIN Iter 120: lr = 0.000655,	loss = 0.005507,	Top-1 err = 14.000000,	Top-5 err = 2.000000,	train_time = 2.291942
TEST Iter 120: loss = 2.496621,	Top-1 err = 46.420382,	Top-5 err = 9.452229,	val_time = 12.752007
TRAIN Iter 130: lr = 0.000604,	loss = 0.005083,	Top-1 err = 46.000000,	Top-5 err = 6.000000,	train_time = 2.299535
TEST Iter 130: loss = 2.731460,	Top-1 err = 49.987261,	Top-5 err = 10.165605,	val_time = 12.989755
TRAIN Iter 140: lr = 0.000552,	loss = 0.005463,	Top-1 err = 9.000000,	Top-5 err = 0.000000,	train_time = 2.290737
TEST Iter 140: loss = 2.879686,	Top-1 err = 49.299363,	Top-5 err = 9.859873,	val_time = 13.021460
TRAIN Iter 150: lr = 0.000500,	loss = 0.004311,	Top-1 err = 15.000000,	Top-5 err = 1.000000,	train_time = 2.506119
TEST Iter 150: loss = 2.506506,	Top-1 err = 45.019108,	Top-5 err = 8.891720,	val_time = 13.196780
TRAIN Iter 160: lr = 0.000448,	loss = 0.004743,	Top-1 err = 47.000000,	Top-5 err = 3.000000,	train_time = 2.313085
TEST Iter 160: loss = 2.077268,	Top-1 err = 41.859873,	Top-5 err = 7.286624,	val_time = 12.947573
TRAIN Iter 170: lr = 0.000396,	loss = 0.003759,	Top-1 err = 24.000000,	Top-5 err = 1.000000,	train_time = 2.259910
TEST Iter 170: loss = 1.960237,	Top-1 err = 44.076433,	Top-5 err = 7.541401,	val_time = 12.932537
TRAIN Iter 180: lr = 0.000345,	loss = 0.003558,	Top-1 err = 12.000000,	Top-5 err = 2.000000,	train_time = 2.311308
TEST Iter 180: loss = 2.276397,	Top-1 err = 44.713376,	Top-5 err = 7.847134,	val_time = 13.031097
TRAIN Iter 190: lr = 0.000297,	loss = 0.003855,	Top-1 err = 8.000000,	Top-5 err = 0.000000,	train_time = 2.337558
TEST Iter 190: loss = 1.890614,	Top-1 err = 39.847134,	Top-5 err = 6.649682,	val_time = 13.036557
TRAIN Iter 200: lr = 0.000250,	loss = 0.003241,	Top-1 err = 6.000000,	Top-5 err = 0.000000,	train_time = 2.322952
TEST Iter 200: loss = 2.118183,	Top-1 err = 41.885350,	Top-5 err = 6.649682,	val_time = 13.160197
TRAIN Iter 210: lr = 0.000206,	loss = 0.003748,	Top-1 err = 7.000000,	Top-5 err = 0.000000,	train_time = 2.492332
TEST Iter 210: loss = 2.041594,	Top-1 err = 41.019108,	Top-5 err = 6.904459,	val_time = 13.447312
TRAIN Iter 220: lr = 0.000165,	loss = 0.003107,	Top-1 err = 21.000000,	Top-5 err = 1.000000,	train_time = 2.301632
TEST Iter 220: loss = 1.797641,	Top-1 err = 39.031847,	Top-5 err = 6.012739,	val_time = 13.040827
TRAIN Iter 230: lr = 0.000128,	loss = 0.003460,	Top-1 err = 11.000000,	Top-5 err = 1.000000,	train_time = 2.344965
TEST Iter 230: loss = 1.798654,	Top-1 err = 39.108280,	Top-5 err = 5.757962,	val_time = 13.100915
TRAIN Iter 240: lr = 0.000095,	loss = 0.003281,	Top-1 err = 5.000000,	Top-5 err = 0.000000,	train_time = 2.413943
TEST Iter 240: loss = 1.723606,	Top-1 err = 37.885350,	Top-5 err = 5.375796,	val_time = 13.220854
TRAIN Iter 250: lr = 0.000067,	loss = 0.003436,	Top-1 err = 24.000000,	Top-5 err = 3.000000,	train_time = 2.301026
TEST Iter 250: loss = 1.691843,	Top-1 err = 36.968153,	Top-5 err = 5.324841,	val_time = 13.022941
TRAIN Iter 260: lr = 0.000043,	loss = 0.003136,	Top-1 err = 39.000000,	Top-5 err = 3.000000,	train_time = 2.203882
TEST Iter 260: loss = 1.667140,	Top-1 err = 36.509554,	Top-5 err = 4.840764,	val_time = 12.969804
TRAIN Iter 270: lr = 0.000024,	loss = 0.003785,	Top-1 err = 11.000000,	Top-5 err = 1.000000,	train_time = 2.316188
TEST Iter 270: loss = 1.647119,	Top-1 err = 36.229299,	Top-5 err = 4.917197,	val_time = 12.865548
TRAIN Iter 280: lr = 0.000011,	loss = 0.003768,	Top-1 err = 73.000000,	Top-5 err = 16.000000,	train_time = 2.327238
TEST Iter 280: loss = 1.661468,	Top-1 err = 36.382166,	Top-5 err = 4.942675,	val_time = 12.973187
TRAIN Iter 290: lr = 0.000003,	loss = 0.003223,	Top-1 err = 28.000000,	Top-5 err = 2.000000,	train_time = 2.320314
TEST Iter 290: loss = 1.669594,	Top-1 err = 36.917197,	Top-5 err = 5.070064,	val_time = 12.887311
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  train/Top1 ▁▃▄▅▂▄▆▂▆▅▁▃▄▆▇█▅▄▃▃▅███▄▄█▇█▃▄█▆█▆▇█▆▇▇
wandb:  train/Top5 ▁▅▇▇▄▆▇▄▇▇▂▇▇▇▇█▇▆▅▆████▇▇███▇▇█▇█▇█████
wandb: train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  train/loss ██▇▇▅▃▄▃▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▂▁▂▁▁▁▁▁▁▁
wandb:    train/lr ███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:   val/epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███
wandb:    val/loss ▆█▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    val/top1 ▁▂▃▃▄▅▅▅▅▆▆▆▇▆▆▇▇▇▇█▇▇█████████
wandb:    val/top5 ▁▃▄▄▅▆▇▆▇▇▇▇▇▇▇▇███████████████
wandb: 
wandb: Run summary:
wandb:  train/Top1 86.0
wandb:  train/Top5 100.0
wandb: train/epoch 299
wandb:  train/loss 0.00306
wandb:    train/lr 0.0
wandb:   val/epoch 299
wandb:    val/loss 1.67561
wandb:    val/top1 63.03185
wandb:    val/top5 94.8535
wandb: 
wandb: 🚀 View run ghostly-orb-577 at: https://wandb.ai/hl57/final_rn18_fkd/runs/pbp6frt8
wandb: ️⚡ View job at https://wandb.ai/hl57/final_rn18_fkd/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjk3MzkyNjU3/version_details/v52
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231030_150139-pbp6frt8/logs
TEST Iter 299: loss = 1.675612,	Top-1 err = 36.968153,	Top-5 err = 5.146497,	val_time = 12.975143
