/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
r_bn:  0.01
lr:  0.25
bc shape torch.Size([10, 10, 512])
get_images call
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
------------iteration 0----------
total loss 117.03938403965729
main criterion 92.84535137058991
weighted_aux_loss 24.194032669067383
loss_r_bn_feature 2419.4033203125
------------iteration 100----------
total loss 64.24812311649438
main criterion 45.805875725747306
weighted_aux_loss 18.44224739074707
loss_r_bn_feature 1844.2247314453125
------------iteration 200----------
total loss 49.677727563735495
main criterion 32.70905004298354
weighted_aux_loss 16.968677520751953
loss_r_bn_feature 1696.8677978515625
------------iteration 300----------
total loss 50.34882482967042
main criterion 33.75484594783448
weighted_aux_loss 16.593978881835938
loss_r_bn_feature 1659.39794921875
------------iteration 400----------
total loss 45.7833400397036
main criterion 30.3659816412661
weighted_aux_loss 15.4173583984375
loss_r_bn_feature 1541.73583984375
------------iteration 500----------
total loss 45.1249024923101
main criterion 31.030392413879927
weighted_aux_loss 14.094510078430176
loss_r_bn_feature 1409.4510498046875
------------iteration 600----------
total loss 43.3001756298963
main criterion 30.704126321119443
weighted_aux_loss 12.596049308776855
loss_r_bn_feature 1259.60498046875
------------iteration 700----------
total loss 37.82803250952007
main criterion 25.65511514349224
weighted_aux_loss 12.172917366027832
loss_r_bn_feature 1217.291748046875
------------iteration 800----------
total loss 42.243736148620215
main criterion 29.997464061523047
weighted_aux_loss 12.246272087097168
loss_r_bn_feature 1224.627197265625
------------iteration 900----------
total loss 50.39758195754627
main criterion 40.82911195632557
weighted_aux_loss 9.568470001220703
loss_r_bn_feature 956.8470458984375
------------iteration 1000----------
total loss 44.01095805646861
main criterion 34.79323421003306
weighted_aux_loss 9.217723846435547
loss_r_bn_feature 921.7723999023438
------------iteration 1100----------
total loss 38.261099985549336
main criterion 29.7186872276758
weighted_aux_loss 8.542412757873535
loss_r_bn_feature 854.2413330078125
------------iteration 1200----------
total loss 29.052822885860042
main criterion 20.06461697613104
weighted_aux_loss 8.988205909729004
loss_r_bn_feature 898.8206176757812
------------iteration 1300----------
total loss 26.81817113111963
main criterion 18.91046153257837
weighted_aux_loss 7.90770959854126
loss_r_bn_feature 790.77099609375
------------iteration 1400----------
total loss 26.949688245664255
main criterion 20.428246786008494
weighted_aux_loss 6.521441459655762
loss_r_bn_feature 652.1441650390625
------------iteration 1500----------
total loss 23.496330580579414
main criterion 17.345483145581856
weighted_aux_loss 6.150847434997559
loss_r_bn_feature 615.0847778320312
------------iteration 1600----------
total loss 25.484528771746632
main criterion 20.253087750781056
weighted_aux_loss 5.231441020965576
loss_r_bn_feature 523.1441040039062
------------iteration 1700----------
total loss 30.79190090553578
main criterion 25.217877658770643
weighted_aux_loss 5.574023246765137
loss_r_bn_feature 557.40234375
------------iteration 1800----------
total loss 32.96013639541454
main criterion 27.308743935545156
weighted_aux_loss 5.651392459869385
loss_r_bn_feature 565.1392822265625
------------iteration 1900----------
total loss 19.1798913286407
main criterion 14.186583738156083
weighted_aux_loss 4.993307590484619
loss_r_bn_feature 499.3307800292969
=> using pytorch pre-trained model 'resnet18'
process data from ../recover/syn_data/imagenette/247
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 1/300 [00:02<10:09,  2.04s/it]  1%|          | 2/300 [00:02<06:02,  1.22s/it]  1%|          | 3/300 [00:03<04:40,  1.06it/s]  1%|▏         | 4/300 [00:03<04:05,  1.21it/s]  2%|▏         | 5/300 [00:04<03:45,  1.31it/s]  2%|▏         | 6/300 [00:05<03:35,  1.37it/s]  2%|▏         | 7/300 [00:05<03:23,  1.44it/s]  3%|▎         | 8/300 [00:06<03:18,  1.47it/s]  3%|▎         | 9/300 [00:07<03:12,  1.51it/s]  3%|▎         | 10/300 [00:07<03:08,  1.54it/s]  4%|▎         | 11/300 [00:08<03:07,  1.54it/s]  4%|▍         | 12/300 [00:09<03:04,  1.56it/s]  4%|▍         | 13/300 [00:09<03:03,  1.57it/s]  5%|▍         | 14/300 [00:10<03:00,  1.59it/s]  5%|▌         | 15/300 [00:10<03:01,  1.57it/s]  5%|▌         | 16/300 [00:11<03:03,  1.55it/s]  6%|▌         | 17/300 [00:12<03:02,  1.55it/s]  6%|▌         | 18/300 [00:12<03:00,  1.56it/s]  6%|▋         | 19/300 [00:13<03:00,  1.55it/s]  7%|▋         | 20/300 [00:14<03:01,  1.54it/s]  7%|▋         | 21/300 [00:14<02:58,  1.56it/s]  7%|▋         | 22/300 [00:15<02:59,  1.55it/s]  8%|▊         | 23/300 [00:16<02:57,  1.56it/s]  8%|▊         | 24/300 [00:16<02:57,  1.55it/s]  8%|▊         | 25/300 [00:17<02:57,  1.55it/s]  9%|▊         | 26/300 [00:18<02:55,  1.56it/s]  9%|▉         | 27/300 [00:18<02:54,  1.56it/s]  9%|▉         | 28/300 [00:19<02:54,  1.56it/s] 10%|▉         | 29/300 [00:19<02:52,  1.57it/s] 10%|█         | 30/300 [00:20<02:52,  1.56it/s] 10%|█         | 31/300 [00:21<02:52,  1.56it/s] 11%|█         | 32/300 [00:21<02:53,  1.55it/s] 11%|█         | 33/300 [00:22<02:52,  1.54it/s] 11%|█▏        | 34/300 [00:23<02:51,  1.55it/s] 12%|█▏        | 35/300 [00:23<02:49,  1.56it/s] 12%|█▏        | 36/300 [00:24<02:48,  1.56it/s] 12%|█▏        | 37/300 [00:25<02:47,  1.57it/s] 13%|█▎        | 38/300 [00:25<02:45,  1.58it/s] 13%|█▎        | 39/300 [00:26<02:45,  1.57it/s] 13%|█▎        | 40/300 [00:26<02:44,  1.58it/s] 14%|█▎        | 41/300 [00:27<02:43,  1.59it/s] 14%|█▍        | 42/300 [00:28<02:44,  1.57it/s] 14%|█▍        | 43/300 [00:28<02:45,  1.56it/s] 15%|█▍        | 44/300 [00:29<02:46,  1.54it/s] 15%|█▌        | 45/300 [00:30<02:44,  1.55it/s] 15%|█▌        | 46/300 [00:30<02:42,  1.56it/s] 16%|█▌        | 47/300 [00:31<02:43,  1.55it/s] 16%|█▌        | 48/300 [00:32<02:42,  1.55it/s] 16%|█▋        | 49/300 [00:32<02:41,  1.56it/s] 17%|█▋        | 50/300 [00:33<02:41,  1.55it/s] 17%|█▋        | 51/300 [00:34<02:39,  1.56it/s] 17%|█▋        | 52/300 [00:34<02:37,  1.57it/s] 18%|█▊        | 53/300 [00:35<02:38,  1.56it/s] 18%|█▊        | 54/300 [00:35<02:39,  1.55it/s] 18%|█▊        | 55/300 [00:36<02:36,  1.56it/s] 19%|█▊        | 56/300 [00:37<02:35,  1.57it/s] 19%|█▉        | 57/300 [00:37<02:33,  1.58it/s] 19%|█▉        | 58/300 [00:38<02:35,  1.56it/s] 20%|█▉        | 59/300 [00:39<02:33,  1.57it/s] 20%|██        | 60/300 [00:39<02:32,  1.57it/s] 20%|██        | 61/300 [00:40<02:31,  1.58it/s] 21%|██        | 62/300 [00:41<02:31,  1.57it/s] 21%|██        | 63/300 [00:41<02:32,  1.56it/s] 21%|██▏       | 64/300 [00:42<02:31,  1.55it/s] 22%|██▏       | 65/300 [00:43<02:31,  1.55it/s] 22%|██▏       | 66/300 [00:43<02:29,  1.56it/s] 22%|██▏       | 67/300 [00:44<02:27,  1.57it/s] 23%|██▎       | 68/300 [00:44<02:27,  1.58it/s] 23%|██▎       | 69/300 [00:45<02:27,  1.57it/s] 23%|██▎       | 70/300 [00:46<02:27,  1.56it/s] 24%|██▎       | 71/300 [00:46<02:26,  1.56it/s] 24%|██▍       | 72/300 [00:47<02:26,  1.56it/s] 24%|██▍       | 73/300 [00:48<02:26,  1.55it/s] 25%|██▍       | 74/300 [00:48<02:24,  1.56it/s] 25%|██▌       | 75/300 [00:49<02:25,  1.55it/s] 25%|██▌       | 76/300 [00:50<02:24,  1.55it/s] 26%|██▌       | 77/300 [00:50<02:24,  1.54it/s] 26%|██▌       | 78/300 [00:51<02:24,  1.53it/s] 26%|██▋       | 79/300 [00:52<02:23,  1.54it/s] 27%|██▋       | 80/300 [00:52<02:22,  1.55it/s] 27%|██▋       | 81/300 [00:53<02:20,  1.56it/s] 27%|██▋       | 82/300 [00:53<02:20,  1.55it/s] 28%|██▊       | 83/300 [00:54<02:20,  1.55it/s] 28%|██▊       | 84/300 [00:55<02:20,  1.54it/s] 28%|██▊       | 85/300 [00:55<02:17,  1.57it/s] 29%|██▊       | 86/300 [00:56<02:15,  1.58it/s] 29%|██▉       | 87/300 [00:57<02:13,  1.59it/s] 29%|██▉       | 88/300 [00:57<02:14,  1.58it/s] 30%|██▉       | 89/300 [00:58<02:13,  1.58it/s] 30%|███       | 90/300 [00:59<02:14,  1.56it/s] 30%|███       | 91/300 [00:59<02:12,  1.58it/s] 31%|███       | 92/300 [01:00<02:11,  1.58it/s] 31%|███       | 93/300 [01:00<02:12,  1.56it/s] 31%|███▏      | 94/300 [01:01<02:12,  1.56it/s] 32%|███▏      | 95/300 [01:02<02:12,  1.55it/s] 32%|███▏      | 96/300 [01:02<02:10,  1.56it/s] 32%|███▏      | 97/300 [01:03<02:08,  1.58it/s] 33%|███▎      | 98/300 [01:04<02:07,  1.59it/s] 33%|███▎      | 99/300 [01:04<02:05,  1.60it/s] 33%|███▎      | 100/300 [01:05<02:05,  1.60it/s] 34%|███▎      | 101/300 [01:05<02:05,  1.58it/s] 34%|███▍      | 102/300 [01:06<02:04,  1.58it/s] 34%|███▍      | 103/300 [01:07<02:05,  1.57it/s] 35%|███▍      | 104/300 [01:07<02:04,  1.57it/s] 35%|███▌      | 105/300 [01:08<02:04,  1.57it/s] 35%|███▌      | 106/300 [01:09<02:03,  1.57it/s] 36%|███▌      | 107/300 [01:09<02:02,  1.58it/s] 36%|███▌      | 108/300 [01:10<02:00,  1.60it/s] 36%|███▋      | 109/300 [01:11<02:00,  1.59it/s] 37%|███▋      | 110/300 [01:11<01:58,  1.60it/s] 37%|███▋      | 111/300 [01:12<01:57,  1.62it/s] 37%|███▋      | 112/300 [01:12<01:55,  1.62it/s] 38%|███▊      | 113/300 [01:13<01:55,  1.62it/s] 38%|███▊      | 114/300 [01:14<01:54,  1.62it/s] 38%|███▊      | 115/300 [01:14<01:55,  1.60it/s] 39%|███▊      | 116/300 [01:15<01:55,  1.59it/s] 39%|███▉      | 117/300 [01:16<01:54,  1.59it/s] 39%|███▉      | 118/300 [01:16<01:53,  1.60it/s] 40%|███▉      | 119/300 [01:17<01:54,  1.58it/s] 40%|████      | 120/300 [01:17<01:54,  1.58it/s] 40%|████      | 121/300 [01:18<01:55,  1.56it/s] 41%|████      | 122/300 [01:19<01:53,  1.57it/s] 41%|████      | 123/300 [01:19<01:54,  1.55it/s] 41%|████▏     | 124/300 [01:20<01:55,  1.53it/s] 42%|████▏     | 125/300 [01:21<01:54,  1.53it/s] 42%|████▏     | 126/300 [01:21<01:53,  1.54it/s] 42%|████▏     | 127/300 [01:22<01:53,  1.52it/s] 43%|████▎     | 128/300 [01:23<01:52,  1.53it/s] 43%|████▎     | 129/300 [01:23<01:49,  1.56it/s] 43%|████▎     | 130/300 [01:24<01:47,  1.57it/s] 44%|████▎     | 131/300 [01:25<01:47,  1.58it/s] 44%|████▍     | 132/300 [01:25<01:46,  1.57it/s] 44%|████▍     | 133/300 [01:26<01:46,  1.57it/s] 45%|████▍     | 134/300 [01:26<01:43,  1.60it/s] 45%|████▌     | 135/300 [01:27<01:42,  1.62it/s] 45%|████▌     | 136/300 [01:28<01:40,  1.63it/s] 46%|████▌     | 137/300 [01:28<01:40,  1.61it/s] 46%|████▌     | 138/300 [01:29<01:41,  1.60it/s] 46%|████▋     | 139/300 [01:30<01:40,  1.60it/s] 47%|████▋     | 140/300 [01:30<01:39,  1.62it/s] 47%|████▋     | 141/300 [01:31<01:38,  1.61it/s] 47%|████▋     | 142/300 [01:31<01:37,  1.62it/s] 48%|████▊     | 143/300 [01:32<01:38,  1.60it/s] 48%|████▊     | 144/300 [01:33<01:36,  1.62it/s] 48%|████▊     | 145/300 [01:33<01:37,  1.59it/s] 49%|████▊     | 146/300 [01:34<01:35,  1.61it/s] 49%|████▉     | 147/300 [01:35<01:36,  1.59it/s] 49%|████▉     | 148/300 [01:35<01:36,  1.57it/s] 50%|████▉     | 149/300 [01:36<01:36,  1.56it/s] 50%|█████     | 150/300 [01:36<01:36,  1.56it/s] 50%|█████     | 151/300 [01:37<01:36,  1.54it/s] 51%|█████     | 152/300 [01:38<01:34,  1.56it/s] 51%|█████     | 153/300 [01:38<01:34,  1.56it/s] 51%|█████▏    | 154/300 [01:39<01:33,  1.56it/s] 52%|█████▏    | 155/300 [01:40<01:33,  1.55it/s] 52%|█████▏    | 156/300 [01:40<01:33,  1.55it/s] 52%|█████▏    | 157/300 [01:41<01:32,  1.55it/s] 53%|█████▎    | 158/300 [01:42<01:32,  1.54it/s] 53%|█████▎    | 159/300 [01:42<01:31,  1.54it/s] 53%|█████▎    | 160/300 [01:43<01:31,  1.53it/s] 54%|█████▎    | 161/300 [01:44<01:29,  1.55it/s] 54%|█████▍    | 162/300 [01:44<01:29,  1.55it/s] 54%|█████▍    | 163/300 [01:45<01:28,  1.56it/s] 55%|█████▍    | 164/300 [01:46<01:27,  1.56it/s] 55%|█████▌    | 165/300 [01:46<01:26,  1.55it/s] 55%|█████▌    | 166/300 [01:47<01:26,  1.55it/s] 56%|█████▌    | 167/300 [01:47<01:26,  1.54it/s] 56%|█████▌    | 168/300 [01:48<01:25,  1.54it/s] 56%|█████▋    | 169/300 [01:49<01:24,  1.55it/s] 57%|█████▋    | 170/300 [01:49<01:23,  1.55it/s] 57%|█████▋    | 171/300 [01:50<01:23,  1.54it/s] 57%|█████▋    | 172/300 [01:51<01:22,  1.54it/s] 58%|█████▊    | 173/300 [01:51<01:22,  1.55it/s] 58%|█████▊    | 174/300 [01:52<01:20,  1.56it/s] 58%|█████▊    | 175/300 [01:53<01:20,  1.56it/s] 59%|█████▊    | 176/300 [01:53<01:19,  1.56it/s] 59%|█████▉    | 177/300 [01:54<01:18,  1.56it/s] 59%|█████▉    | 178/300 [01:55<01:19,  1.53it/s] 60%|█████▉    | 179/300 [01:55<01:18,  1.53it/s] 60%|██████    | 180/300 [01:56<01:18,  1.54it/s] 60%|██████    | 181/300 [01:56<01:16,  1.56it/s] 61%|██████    | 182/300 [01:57<01:16,  1.54it/s] 61%|██████    | 183/300 [01:58<01:15,  1.55it/s] 61%|██████▏   | 184/300 [01:58<01:15,  1.54it/s] 62%|██████▏   | 185/300 [01:59<01:14,  1.55it/s] 62%|██████▏   | 186/300 [02:00<01:11,  1.59it/s] 62%|██████▏   | 187/300 [02:00<01:10,  1.61it/s] 63%|██████▎   | 188/300 [02:01<01:08,  1.62it/s] 63%|██████▎   | 189/300 [02:02<01:09,  1.60it/s] 63%|██████▎   | 190/300 [02:02<01:08,  1.62it/s] 64%|██████▎   | 191/300 [02:03<01:08,  1.60it/s] 64%|██████▍   | 192/300 [02:03<01:08,  1.58it/s] 64%|██████▍   | 193/300 [02:04<01:08,  1.57it/s] 65%|██████▍   | 194/300 [02:05<01:06,  1.60it/s] 65%|██████▌   | 195/300 [02:05<01:05,  1.61it/s] 65%|██████▌   | 196/300 [02:06<01:04,  1.61it/s] 66%|██████▌   | 197/300 [02:07<01:03,  1.61it/s] 66%|██████▌   | 198/300 [02:07<01:03,  1.61it/s] 66%|██████▋   | 199/300 [02:08<01:03,  1.59it/s] 67%|██████▋   | 200/300 [02:08<01:02,  1.60it/s] 67%|██████▋   | 201/300 [02:09<01:02,  1.59it/s] 67%|██████▋   | 202/300 [02:10<01:01,  1.60it/s] 68%|██████▊   | 203/300 [02:10<01:00,  1.61it/s] 68%|██████▊   | 204/300 [02:11<00:59,  1.62it/s] 68%|██████▊   | 205/300 [02:11<00:58,  1.61it/s] 69%|██████▊   | 206/300 [02:12<00:58,  1.59it/s] 69%|██████▉   | 207/300 [02:13<00:58,  1.58it/s] 69%|██████▉   | 208/300 [02:13<00:58,  1.58it/s] 70%|██████▉   | 209/300 [02:14<00:58,  1.56it/s] 70%|███████   | 210/300 [02:15<00:58,  1.55it/s] 70%|███████   | 211/300 [02:15<00:57,  1.54it/s] 71%|███████   | 212/300 [02:16<00:57,  1.54it/s] 71%|███████   | 213/300 [02:17<00:56,  1.54it/s] 71%|███████▏  | 214/300 [02:17<00:55,  1.56it/s] 72%|███████▏  | 215/300 [02:18<00:54,  1.56it/s] 72%|███████▏  | 216/300 [02:19<00:53,  1.57it/s] 72%|███████▏  | 217/300 [02:19<00:53,  1.56it/s] 73%|███████▎  | 218/300 [02:20<00:52,  1.57it/s] 73%|███████▎  | 219/300 [02:21<00:52,  1.55it/s] 73%|███████▎  | 220/300 [02:21<00:51,  1.55it/s] 74%|███████▎  | 221/300 [02:22<00:51,  1.55it/s] 74%|███████▍  | 222/300 [02:22<00:49,  1.57it/s] 74%|███████▍  | 223/300 [02:23<00:49,  1.56it/s] 75%|███████▍  | 224/300 [02:24<00:49,  1.55it/s] 75%|███████▌  | 225/300 [02:24<00:47,  1.57it/s] 75%|███████▌  | 226/300 [02:25<00:47,  1.56it/s] 76%|███████▌  | 227/300 [02:26<00:46,  1.57it/s] 76%|███████▌  | 228/300 [02:26<00:45,  1.57it/s] 76%|███████▋  | 229/300 [02:27<00:45,  1.56it/s] 77%|███████▋  | 230/300 [02:28<00:44,  1.56it/s] 77%|███████▋  | 231/300 [02:28<00:44,  1.55it/s] 77%|███████▋  | 232/300 [02:29<00:43,  1.57it/s] 78%|███████▊  | 233/300 [02:29<00:42,  1.57it/s] 78%|███████▊  | 234/300 [02:30<00:41,  1.58it/s] 78%|███████▊  | 235/300 [02:31<00:41,  1.57it/s] 79%|███████▊  | 236/300 [02:31<00:40,  1.57it/s] 79%|███████▉  | 237/300 [02:32<00:40,  1.57it/s] 79%|███████▉  | 238/300 [02:33<00:39,  1.58it/s] 80%|███████▉  | 239/300 [02:33<00:38,  1.59it/s] 80%|████████  | 240/300 [02:34<00:38,  1.57it/s] 80%|████████  | 241/300 [02:35<00:37,  1.59it/s] 81%|████████  | 242/300 [02:35<00:36,  1.58it/s] 81%|████████  | 243/300 [02:36<00:36,  1.57it/s] 81%|████████▏ | 244/300 [02:36<00:35,  1.57it/s] 82%|████████▏ | 245/300 [02:37<00:34,  1.57it/s] 82%|████████▏ | 246/300 [02:38<00:34,  1.58it/s] 82%|████████▏ | 247/300 [02:38<00:33,  1.58it/s] 83%|████████▎ | 248/300 [02:39<00:32,  1.59it/s] 83%|████████▎ | 249/300 [02:40<00:32,  1.57it/s] 83%|████████▎ | 250/300 [02:40<00:31,  1.58it/s] 84%|████████▎ | 251/300 [02:41<00:31,  1.57it/s] 84%|████████▍ | 252/300 [02:42<00:30,  1.58it/s] 84%|████████▍ | 253/300 [02:42<00:30,  1.57it/s] 85%|████████▍ | 254/300 [02:43<00:29,  1.56it/s] 85%|████████▌ | 255/300 [02:43<00:28,  1.56it/s] 85%|████████▌ | 256/300 [02:44<00:28,  1.57it/s] 86%|████████▌ | 257/300 [02:45<00:27,  1.55it/s] 86%|████████▌ | 258/300 [02:45<00:26,  1.56it/s] 86%|████████▋ | 259/300 [02:46<00:26,  1.58it/s] 87%|████████▋ | 260/300 [02:47<00:25,  1.56it/s] 87%|████████▋ | 261/300 [02:47<00:25,  1.56it/s] 87%|████████▋ | 262/300 [02:48<00:24,  1.57it/s] 88%|████████▊ | 263/300 [02:49<00:23,  1.56it/s] 88%|████████▊ | 264/300 [02:49<00:23,  1.56it/s] 88%|████████▊ | 265/300 [02:50<00:22,  1.57it/s] 89%|████████▊ | 266/300 [02:50<00:21,  1.58it/s] 89%|████████▉ | 267/300 [02:51<00:20,  1.59it/s] 89%|████████▉ | 268/300 [02:52<00:20,  1.58it/s] 90%|████████▉ | 269/300 [02:52<00:19,  1.59it/s] 90%|█████████ | 270/300 [02:53<00:19,  1.58it/s] 90%|█████████ | 271/300 [02:54<00:18,  1.56it/s] 91%|█████████ | 272/300 [02:54<00:17,  1.58it/s] 91%|█████████ | 273/300 [02:55<00:17,  1.58it/s] 91%|█████████▏| 274/300 [02:56<00:16,  1.59it/s] 92%|█████████▏| 275/300 [02:56<00:15,  1.60it/s] 92%|█████████▏| 276/300 [02:57<00:15,  1.59it/s] 92%|█████████▏| 277/300 [02:57<00:14,  1.58it/s] 93%|█████████▎| 278/300 [02:58<00:13,  1.58it/s] 93%|█████████▎| 279/300 [02:59<00:13,  1.59it/s] 93%|█████████▎| 280/300 [02:59<00:12,  1.59it/s] 94%|█████████▎| 281/300 [03:00<00:11,  1.61it/s] 94%|█████████▍| 282/300 [03:01<00:11,  1.60it/s] 94%|█████████▍| 283/300 [03:01<00:10,  1.60it/s] 95%|█████████▍| 284/300 [03:02<00:10,  1.59it/s] 95%|█████████▌| 285/300 [03:02<00:09,  1.59it/s] 95%|█████████▌| 286/300 [03:03<00:08,  1.58it/s] 96%|█████████▌| 287/300 [03:04<00:08,  1.59it/s] 96%|█████████▌| 288/300 [03:04<00:07,  1.57it/s] 96%|█████████▋| 289/300 [03:05<00:06,  1.58it/s] 97%|█████████▋| 290/300 [03:06<00:06,  1.58it/s] 97%|█████████▋| 291/300 [03:06<00:05,  1.59it/s] 97%|█████████▋| 292/300 [03:07<00:05,  1.59it/s] 98%|█████████▊| 293/300 [03:07<00:04,  1.60it/s] 98%|█████████▊| 294/300 [03:08<00:03,  1.60it/s] 98%|█████████▊| 295/300 [03:09<00:03,  1.58it/s] 99%|█████████▊| 296/300 [03:09<00:02,  1.59it/s] 99%|█████████▉| 297/300 [03:10<00:01,  1.58it/s] 99%|█████████▉| 298/300 [03:11<00:01,  1.57it/s]100%|█████████▉| 299/300 [03:11<00:00,  1.57it/s]100%|██████████| 300/300 [03:12<00:00,  1.56it/s]100%|██████████| 300/300 [03:12<00:00,  1.56it/s]
W&B disabled.
W&B online. Running your script from this directory will now sync to the cloud.
wandb: Currently logged in as: hl57. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /media/techt/One Touch/DD/SRe2L/train/wandb/run-20231019_154804-oi14gbfz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-firebrand-414
wandb: ⭐️ View project at https://wandb.ai/hl57/final_rn18_fkd
wandb: 🚀 View run at https://wandb.ai/hl57/final_rn18_fkd/runs/oi14gbfz
======= FKD: dataset info ======
path: ../relabel/FKD_cutmix_fp16/imagenette/247/
num img: 100
batch size: 100
max epoch: 300
================================
load data successfully
=> loading student model 'resnet18'

Epoch: 0
TRAIN Iter 0: lr = 0.001000,	loss = 0.000217,	Top-1 err = 87.000000,	Top-5 err = 49.000000,	train_time = 3.317747
TEST Iter 0: loss = 6.253586,	Top-1 err = 89.324841,	Top-5 err = 47.796178,	val_time = 12.939971

Epoch: 1

Epoch: 2

Epoch: 3

Epoch: 4

Epoch: 5

Epoch: 6

Epoch: 7

Epoch: 8

Epoch: 9

Epoch: 10
TRAIN Iter 10: lr = 0.000997,	loss = 0.000145,	Top-1 err = 63.000000,	Top-5 err = 9.000000,	train_time = 2.232867
TEST Iter 10: loss = 16.488552,	Top-1 err = 81.859873,	Top-5 err = 44.738854,	val_time = 12.949534

Epoch: 11

Epoch: 12

Epoch: 13

Epoch: 14

Epoch: 15

Epoch: 16

Epoch: 17

Epoch: 18

Epoch: 19

Epoch: 20
TRAIN Iter 20: lr = 0.000989,	loss = 0.000084,	Top-1 err = 54.000000,	Top-5 err = 11.000000,	train_time = 2.357324
TEST Iter 20: loss = 9.507884,	Top-1 err = 79.082803,	Top-5 err = 31.949045,	val_time = 13.245400

Epoch: 21

Epoch: 22

Epoch: 23

Epoch: 24

Epoch: 25

Epoch: 26

Epoch: 27

Epoch: 28

Epoch: 29

Epoch: 30
TRAIN Iter 30: lr = 0.000976,	loss = 0.000074,	Top-1 err = 48.000000,	Top-5 err = 9.000000,	train_time = 2.216939
TEST Iter 30: loss = 15.679915,	Top-1 err = 79.872611,	Top-5 err = 37.426752,	val_time = 12.745279

Epoch: 31

Epoch: 32

Epoch: 33

Epoch: 34

Epoch: 35

Epoch: 36

Epoch: 37

Epoch: 38

Epoch: 39

Epoch: 40
TRAIN Iter 40: lr = 0.000957,	loss = 0.000054,	Top-1 err = 77.000000,	Top-5 err = 12.000000,	train_time = 2.190245
TEST Iter 40: loss = 10.112582,	Top-1 err = 74.624204,	Top-5 err = 33.732484,	val_time = 12.639409

Epoch: 41

Epoch: 42

Epoch: 43

Epoch: 44

Epoch: 45

Epoch: 46

Epoch: 47

Epoch: 48

Epoch: 49

Epoch: 50
TRAIN Iter 50: lr = 0.000933,	loss = 0.000044,	Top-1 err = 12.000000,	Top-5 err = 1.000000,	train_time = 2.212640
TEST Iter 50: loss = 6.604045,	Top-1 err = 69.350318,	Top-5 err = 24.331210,	val_time = 12.612504

Epoch: 51

Epoch: 52

Epoch: 53

Epoch: 54

Epoch: 55

Epoch: 56

Epoch: 57

Epoch: 58

Epoch: 59

Epoch: 60
TRAIN Iter 60: lr = 0.000905,	loss = 0.000048,	Top-1 err = 27.000000,	Top-5 err = 3.000000,	train_time = 2.296447
TEST Iter 60: loss = 6.294065,	Top-1 err = 69.350318,	Top-5 err = 22.955414,	val_time = 12.670608

Epoch: 61

Epoch: 62

Epoch: 63

Epoch: 64

Epoch: 65

Epoch: 66

Epoch: 67

Epoch: 68

Epoch: 69

Epoch: 70
TRAIN Iter 70: lr = 0.000872,	loss = 0.000039,	Top-1 err = 45.000000,	Top-5 err = 4.000000,	train_time = 2.209138
TEST Iter 70: loss = 3.673793,	Top-1 err = 57.350318,	Top-5 err = 16.050955,	val_time = 12.685192

Epoch: 71

Epoch: 72

Epoch: 73

Epoch: 74

Epoch: 75

Epoch: 76

Epoch: 77

Epoch: 78

Epoch: 79

Epoch: 80
TRAIN Iter 80: lr = 0.000835,	loss = 0.000042,	Top-1 err = 29.000000,	Top-5 err = 4.000000,	train_time = 2.256246
TEST Iter 80: loss = 3.881776,	Top-1 err = 57.630573,	Top-5 err = 18.242038,	val_time = 12.688039

Epoch: 81

Epoch: 82

Epoch: 83

Epoch: 84

Epoch: 85

Epoch: 86

Epoch: 87

Epoch: 88

Epoch: 89

Epoch: 90
TRAIN Iter 90: lr = 0.000794,	loss = 0.000034,	Top-1 err = 21.000000,	Top-5 err = 2.000000,	train_time = 2.321255
TEST Iter 90: loss = 3.683552,	Top-1 err = 59.923567,	Top-5 err = 14.420382,	val_time = 12.631614

Epoch: 91

Epoch: 92

Epoch: 93

Epoch: 94

Epoch: 95

Epoch: 96

Epoch: 97

Epoch: 98

Epoch: 99

Epoch: 100
TRAIN Iter 100: lr = 0.000750,	loss = 0.000033,	Top-1 err = 17.000000,	Top-5 err = 3.000000,	train_time = 2.190103
TEST Iter 100: loss = 3.747382,	Top-1 err = 59.566879,	Top-5 err = 15.464968,	val_time = 12.732210

Epoch: 101

Epoch: 102

Epoch: 103

Epoch: 104

Epoch: 105

Epoch: 106

Epoch: 107

Epoch: 108

Epoch: 109

Epoch: 110
TRAIN Iter 110: lr = 0.000703,	loss = 0.000031,	Top-1 err = 29.000000,	Top-5 err = 5.000000,	train_time = 2.210915
TEST Iter 110: loss = 3.544539,	Top-1 err = 54.751592,	Top-5 err = 13.095541,	val_time = 12.651393

Epoch: 111

Epoch: 112

Epoch: 113

Epoch: 114

Epoch: 115

Epoch: 116

Epoch: 117

Epoch: 118

Epoch: 119

Epoch: 120
TRAIN Iter 120: lr = 0.000655,	loss = 0.000029,	Top-1 err = 5.000000,	Top-5 err = 0.000000,	train_time = 2.242660
TEST Iter 120: loss = 3.491617,	Top-1 err = 55.872611,	Top-5 err = 13.859873,	val_time = 12.609764

Epoch: 121

Epoch: 122

Epoch: 123

Epoch: 124

Epoch: 125

Epoch: 126

Epoch: 127

Epoch: 128

Epoch: 129

Epoch: 130
TRAIN Iter 130: lr = 0.000604,	loss = 0.000027,	Top-1 err = 91.000000,	Top-5 err = 44.000000,	train_time = 2.212212
TEST Iter 130: loss = 3.440874,	Top-1 err = 54.420382,	Top-5 err = 12.407643,	val_time = 12.746729

Epoch: 131

Epoch: 132

Epoch: 133

Epoch: 134

Epoch: 135

Epoch: 136

Epoch: 137

Epoch: 138

Epoch: 139

Epoch: 140
TRAIN Iter 140: lr = 0.000552,	loss = 0.000027,	Top-1 err = 40.000000,	Top-5 err = 3.000000,	train_time = 2.229456
TEST Iter 140: loss = 3.396385,	Top-1 err = 56.101911,	Top-5 err = 14.242038,	val_time = 12.713902

Epoch: 141

Epoch: 142

Epoch: 143

Epoch: 144

Epoch: 145

Epoch: 146

Epoch: 147

Epoch: 148

Epoch: 149

Epoch: 150
TRAIN Iter 150: lr = 0.000500,	loss = 0.000028,	Top-1 err = 60.000000,	Top-5 err = 8.000000,	train_time = 2.223631
TEST Iter 150: loss = 2.869383,	Top-1 err = 53.299363,	Top-5 err = 12.891720,	val_time = 12.716783

Epoch: 151

Epoch: 152

Epoch: 153

Epoch: 154

Epoch: 155

Epoch: 156

Epoch: 157

Epoch: 158

Epoch: 159

Epoch: 160
TRAIN Iter 160: lr = 0.000448,	loss = 0.000028,	Top-1 err = 60.000000,	Top-5 err = 4.000000,	train_time = 2.274567
TEST Iter 160: loss = 3.031179,	Top-1 err = 53.961783,	Top-5 err = 13.171975,	val_time = 12.647469

Epoch: 161

Epoch: 162

Epoch: 163

Epoch: 164

Epoch: 165

Epoch: 166

Epoch: 167

Epoch: 168

Epoch: 169

Epoch: 170
TRAIN Iter 170: lr = 0.000396,	loss = 0.000024,	Top-1 err = 6.000000,	Top-5 err = 0.000000,	train_time = 2.219153
TEST Iter 170: loss = 3.075269,	Top-1 err = 54.955414,	Top-5 err = 12.764331,	val_time = 12.700598

Epoch: 171

Epoch: 172

Epoch: 173

Epoch: 174

Epoch: 175

Epoch: 176

Epoch: 177

Epoch: 178

Epoch: 179

Epoch: 180
TRAIN Iter 180: lr = 0.000345,	loss = 0.000023,	Top-1 err = 3.000000,	Top-5 err = 0.000000,	train_time = 2.246192
TEST Iter 180: loss = 3.194152,	Top-1 err = 51.414013,	Top-5 err = 11.974522,	val_time = 12.645445

Epoch: 181

Epoch: 182

Epoch: 183

Epoch: 184

Epoch: 185

Epoch: 186

Epoch: 187

Epoch: 188

Epoch: 189

Epoch: 190
TRAIN Iter 190: lr = 0.000297,	loss = 0.000024,	Top-1 err = 24.000000,	Top-5 err = 2.000000,	train_time = 2.243555
TEST Iter 190: loss = 4.323869,	Top-1 err = 55.872611,	Top-5 err = 14.420382,	val_time = 12.671488

Epoch: 191

Epoch: 192

Epoch: 193

Epoch: 194

Epoch: 195

Epoch: 196

Epoch: 197

Epoch: 198

Epoch: 199

Epoch: 200
TRAIN Iter 200: lr = 0.000250,	loss = 0.000025,	Top-1 err = 74.000000,	Top-5 err = 8.000000,	train_time = 2.179385
TEST Iter 200: loss = 3.104485,	Top-1 err = 52.407643,	Top-5 err = 11.821656,	val_time = 12.630450

Epoch: 201

Epoch: 202

Epoch: 203

Epoch: 204

Epoch: 205

Epoch: 206

Epoch: 207

Epoch: 208

Epoch: 209

Epoch: 210
TRAIN Iter 210: lr = 0.000206,	loss = 0.000031,	Top-1 err = 43.000000,	Top-5 err = 2.000000,	train_time = 2.250033
TEST Iter 210: loss = 3.161248,	Top-1 err = 51.464968,	Top-5 err = 11.541401,	val_time = 12.770992

Epoch: 211

Epoch: 212

Epoch: 213

Epoch: 214

Epoch: 215

Epoch: 216

Epoch: 217

Epoch: 218

Epoch: 219

Epoch: 220
TRAIN Iter 220: lr = 0.000165,	loss = 0.000022,	Top-1 err = 72.000000,	Top-5 err = 5.000000,	train_time = 2.257209
TEST Iter 220: loss = 3.005558,	Top-1 err = 51.898089,	Top-5 err = 11.490446,	val_time = 12.737994

Epoch: 221

Epoch: 222

Epoch: 223

Epoch: 224

Epoch: 225

Epoch: 226

Epoch: 227

Epoch: 228

Epoch: 229

Epoch: 230
TRAIN Iter 230: lr = 0.000128,	loss = 0.000023,	Top-1 err = 12.000000,	Top-5 err = 0.000000,	train_time = 2.238640
TEST Iter 230: loss = 2.997847,	Top-1 err = 51.592357,	Top-5 err = 12.127389,	val_time = 12.688418

Epoch: 231

Epoch: 232

Epoch: 233

Epoch: 234

Epoch: 235

Epoch: 236

Epoch: 237

Epoch: 238

Epoch: 239

Epoch: 240
TRAIN Iter 240: lr = 0.000095,	loss = 0.000022,	Top-1 err = 83.000000,	Top-5 err = 17.000000,	train_time = 2.229301
TEST Iter 240: loss = 2.785918,	Top-1 err = 50.394904,	Top-5 err = 11.133758,	val_time = 12.627072

Epoch: 241

Epoch: 242

Epoch: 243

Epoch: 244

Epoch: 245

Epoch: 246

Epoch: 247

Epoch: 248

Epoch: 249

Epoch: 250
TRAIN Iter 250: lr = 0.000067,	loss = 0.000024,	Top-1 err = 42.000000,	Top-5 err = 1.000000,	train_time = 2.253636
TEST Iter 250: loss = 2.647630,	Top-1 err = 49.350318,	Top-5 err = 10.598726,	val_time = 12.615455

Epoch: 251

Epoch: 252

Epoch: 253

Epoch: 254

Epoch: 255

Epoch: 256

Epoch: 257

Epoch: 258

Epoch: 259

Epoch: 260
TRAIN Iter 260: lr = 0.000043,	loss = 0.000019,	Top-1 err = 3.000000,	Top-5 err = 0.000000,	train_time = 2.293854
TEST Iter 260: loss = 2.760875,	Top-1 err = 49.808917,	Top-5 err = 10.955414,	val_time = 12.575556

Epoch: 261

Epoch: 262

Epoch: 263

Epoch: 264

Epoch: 265

Epoch: 266

Epoch: 267

Epoch: 268

Epoch: 269

Epoch: 270
TRAIN Iter 270: lr = 0.000024,	loss = 0.000025,	Top-1 err = 43.000000,	Top-5 err = 3.000000,	train_time = 2.220986
TEST Iter 270: loss = 2.730215,	Top-1 err = 48.840764,	Top-5 err = 10.471338,	val_time = 12.652003

Epoch: 271

Epoch: 272

Epoch: 273

Epoch: 274

Epoch: 275

Epoch: 276

Epoch: 277

Epoch: 278

Epoch: 279

Epoch: 280
TRAIN Iter 280: lr = 0.000011,	loss = 0.000018,	Top-1 err = 84.000000,	Top-5 err = 21.000000,	train_time = 2.223431
TEST Iter 280: loss = 2.682946,	Top-1 err = 48.917197,	Top-5 err = 10.216561,	val_time = 12.587369

Epoch: 281

Epoch: 282

Epoch: 283

Epoch: 284

Epoch: 285

Epoch: 286

Epoch: 287

Epoch: 288

Epoch: 289

Epoch: 290
TRAIN Iter 290: lr = 0.000003,	loss = 0.000022,	Top-1 err = 12.000000,	Top-5 err = 1.000000,	train_time = 2.188310
TEST Iter 290: loss = 2.597156,	Top-1 err = 48.738854,	Top-5 err = 9.987261,	val_time = 12.614265

Epoch: 291

Epoch: 292

Epoch: 293

Epoch: 294

Epoch: 295

Epoch: 296

Epoch: 297

Epoch: 298

Epoch: 299
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  train/Top1 ▁▂▄▃▆▄▅▆▆▇▇▅▆▄▇▆▆▅▁▁▆█▄▄█▆██▂█▂▁█▁▇▇▅█▇▇
wandb:  train/Top5 ▂▄▇▇█▇███████████▇▁▅██▇▇████▆█▅▆█▄██████
wandb: train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  train/loss █▇▆▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁
wandb:    train/lr ███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:   val/epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███
wandb:    val/loss ▃█▄█▅▃▃▂▂▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁
wandb:    val/top1 ▁▂▃▃▄▄▄▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████
wandb:    val/top5 ▁▂▄▃▄▅▆▇▆▇▇▇▇█▇▇▇▇█▇███████████
wandb: 
wandb: Run summary:
wandb:  train/Top1 87.0
wandb:  train/Top5 99.0
wandb: train/epoch 299
wandb:  train/loss 3e-05
wandb:    train/lr 0.0
wandb:   val/epoch 299
wandb:    val/loss 2.5925
wandb:    val/top1 51.51592
wandb:    val/top5 89.96178
wandb: 
wandb: 🚀 View run noble-firebrand-414 at: https://wandb.ai/hl57/final_rn18_fkd/runs/oi14gbfz
wandb: ️⚡ View job at https://wandb.ai/hl57/final_rn18_fkd/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjk3MzkyNjU3/version_details/v39
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231019_154804-oi14gbfz/logs
TEST Iter 299: loss = 2.592504,	Top-1 err = 48.484076,	Top-5 err = 10.038217,	val_time = 12.684671
