/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
r_bn:  1.0
lr:  0.1
ipc_id =  0
get_images call
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
per-class-batchnorm:  False
------------iteration 0----------
total loss 533.3699951171875
main criterion 16.12049102783203
weighted_aux_loss 517.24951171875
loss_r_bn_feature 517.24951171875
Verifier accuracy:  0.0
------------iteration 100----------
total loss 386.2451477050781
main criterion 11.746938705444336
weighted_aux_loss 374.4981994628906
loss_r_bn_feature 374.4981994628906
Traceback (most recent call last):
  File "data_synthesis.py", line 375, in <module>
    main_syn(args)
  File "data_synthesis.py", line 295, in main_syn
    get_images(args, model_teacher, hook_for_display, ipc_id, bc_i=bc_i)
  File "data_synthesis.py", line 159, in get_images
    hook_for_display(inputs, targets)
  File "data_synthesis.py", line 294, in <lambda>
    hook_for_display = lambda x,y: validate(x, y, model_verifier)
  File "data_synthesis.py", line 218, in validate
    output = model(input)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/mobilenetv2.py", line 174, in forward
    return self._forward_impl(x)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/mobilenetv2.py", line 166, in _forward_impl
    x = self.features(x)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/mobilenetv2.py", line 64, in forward
    return self.conv(x)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 920.00 MiB (GPU 0; 23.69 GiB total capacity; 19.66 GiB already allocated; 418.69 MiB free; 21.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
=> using pytorch pre-trained model 'resnet18'
process data from ../recover/syn_data/tiny-imagenet/219
Traceback (most recent call last):
  File "generate_soft_label.py", line 250, in <module>
    main()
  File "generate_soft_label.py", line 126, in main
    main_worker(args.gpu, ngpus_per_node, args)
  File "generate_soft_label.py", line 198, in main_worker
    train_dataset = ImageFolder_FKD_MIX(
  File "/media/techt/One Touch/DD/SRe2L/relabel/utils_fkd.py", line 153, in __init__
    super(ImageFolder_FKD_MIX, self).__init__(**kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 309, in __init__
    super().__init__(
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 144, in __init__
    classes, class_to_idx = self.find_classes(self.root)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 218, in find_classes
    return find_classes(directory)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 42, in find_classes
    raise FileNotFoundError(f"Couldn't find any class folder in {directory}.")
FileNotFoundError: Couldn't find any class folder in ../recover/syn_data/tiny-imagenet/219.
W&B disabled.
W&B online. Running your script from this directory will now sync to the cloud.
wandb: Currently logged in as: hl57. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /media/techt/One Touch/DD/SRe2L/train/wandb/run-20231005_201131-mptzrb3c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-vortex-384
wandb: ‚≠êÔ∏è View project at https://wandb.ai/hl57/final_rn18_fkd
wandb: üöÄ View run at https://wandb.ai/hl57/final_rn18_fkd/runs/mptzrb3c
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: üöÄ View run dainty-vortex-384 at: https://wandb.ai/hl57/final_rn18_fkd/runs/mptzrb3c
wandb: Ô∏è‚ö° View job at https://wandb.ai/hl57/final_rn18_fkd/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjk3MzkyNjU3/version_details/v37
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231005_201131-mptzrb3c/logs
Traceback (most recent call last):
  File "train_FKD.py", line 390, in <module>
    main()
  File "train_FKD.py", line 109, in main
    train_dataset = ImageFolder_FKD_MIX(
  File "/media/techt/One Touch/DD/SRe2L/train/../relabel/utils_fkd.py", line 153, in __init__
    super(ImageFolder_FKD_MIX, self).__init__(**kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 309, in __init__
    super().__init__(
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 144, in __init__
    classes, class_to_idx = self.find_classes(self.root)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 218, in find_classes
    return find_classes(directory)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 42, in find_classes
    raise FileNotFoundError(f"Couldn't find any class folder in {directory}.")
FileNotFoundError: Couldn't find any class folder in ../recover/syn_data/tiny-imagenet/219.
