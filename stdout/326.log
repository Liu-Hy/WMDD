r_bn:  3.0
lr:  0.25
bc loaded
bc shape (10, 1, 512)
getting batchnorm for class 0
getting batchnorm for class 1
getting batchnorm for class 2
getting batchnorm for class 3
getting batchnorm for class 4
getting batchnorm for class 5
getting batchnorm for class 6
getting batchnorm for class 7
getting batchnorm for class 8
getting batchnorm for class 9
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Execution time for computing per-class batchnorm statistics: 46.615987 seconds
get_images call
class_per_batch  10 batch_size  100 args.ipc  1
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
start_cls 0 end_cls 10
Length of input 10 is different from effective batch size 10
------------iteration 0----------
total loss 2987.9184548270005
main criterion 28.975583733250556
weighted_aux_loss 2958.94287109375
loss_r_bn_feature 986.3142700195312
------------iteration 100----------
total loss 1212.5048918896207
main criterion 10.849740522433155
weighted_aux_loss 1201.6551513671875
loss_r_bn_feature 400.5517272949219
------------iteration 200----------
total loss 1301.4067103226878
main criterion 16.909273799250194
weighted_aux_loss 1284.4974365234375
loss_r_bn_feature 428.1658020019531
------------iteration 300----------
total loss 921.5363048526283
main criterion 11.006275555753282
weighted_aux_loss 910.530029296875
loss_r_bn_feature 303.510009765625
------------iteration 400----------
total loss 810.478251182551
main criterion 8.76725264739475
weighted_aux_loss 801.7109985351562
loss_r_bn_feature 267.23699951171875
------------iteration 500----------
total loss 1073.1134930477403
main criterion 14.248014532115363
weighted_aux_loss 1058.865478515625
loss_r_bn_feature 352.95513916015625
------------iteration 600----------
total loss 960.0828676623513
main criterion 12.543683092038854
weighted_aux_loss 947.5391845703125
loss_r_bn_feature 315.8464050292969
------------iteration 700----------
total loss 955.2668398682744
main criterion 12.863275415149412
weighted_aux_loss 942.403564453125
loss_r_bn_feature 314.134521484375
------------iteration 800----------
total loss 792.6326498807498
main criterion 10.294759255749785
weighted_aux_loss 782.337890625
loss_r_bn_feature 260.779296875
------------iteration 900----------
total loss 664.1110753896604
main criterion 7.9965124013791105
weighted_aux_loss 656.1145629882812
loss_r_bn_feature 218.70484924316406
------------iteration 1000----------
total loss 583.2033042281341
main criterion 7.952693876571655
weighted_aux_loss 575.2506103515625
loss_r_bn_feature 191.7501983642578
------------iteration 1100----------
total loss 693.924735149842
main criterion 8.987601360779488
weighted_aux_loss 684.9371337890625
loss_r_bn_feature 228.3123779296875
------------iteration 1200----------
total loss 669.4217446160233
main criterion 7.841483385554496
weighted_aux_loss 661.5802612304688
loss_r_bn_feature 220.52674865722656
------------iteration 1300----------
total loss 593.9220604815958
main criterion 7.18921136050214
weighted_aux_loss 586.7328491210938
loss_r_bn_feature 195.57762145996094
------------iteration 1400----------
total loss 524.8411493646214
main criterion 6.751610790402607
weighted_aux_loss 518.0895385742188
loss_r_bn_feature 172.69651794433594
------------iteration 1500----------
total loss 1047.919003205887
main criterion 14.41387625276217
weighted_aux_loss 1033.505126953125
loss_r_bn_feature 344.501708984375
------------iteration 1600----------
total loss 411.3356689628608
main criterion 5.8127197441107965
weighted_aux_loss 405.52294921875
loss_r_bn_feature 135.17431640625
------------iteration 1700----------
total loss 493.8048135521428
main criterion 6.37054841542405
weighted_aux_loss 487.43426513671875
loss_r_bn_feature 162.47808837890625
------------iteration 1800----------
total loss 726.94141291485
main criterion 8.258368481256287
weighted_aux_loss 718.6830444335938
loss_r_bn_feature 239.56101989746094
------------iteration 1900----------
total loss 451.5535851634185
main criterion 6.296840778652887
weighted_aux_loss 445.2567443847656
loss_r_bn_feature 148.41891479492188
=> using pytorch pre-trained model 'resnet18'
process data from ../recover/syn_data/imagenette/326
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 1/300 [00:01<09:23,  1.88s/it]  1%|          | 2/300 [00:02<05:00,  1.01s/it]  1%|          | 3/300 [00:02<03:35,  1.38it/s]  1%|▏         | 4/300 [00:03<02:55,  1.69it/s]  2%|▏         | 5/300 [00:03<02:33,  1.92it/s]  2%|▏         | 6/300 [00:03<02:19,  2.11it/s]  2%|▏         | 7/300 [00:04<02:11,  2.22it/s]  3%|▎         | 8/300 [00:04<02:05,  2.32it/s]  3%|▎         | 9/300 [00:05<02:02,  2.38it/s]  3%|▎         | 10/300 [00:05<01:59,  2.42it/s]  4%|▎         | 11/300 [00:05<01:58,  2.44it/s]  4%|▍         | 12/300 [00:06<01:56,  2.48it/s]  4%|▍         | 13/300 [00:06<01:54,  2.50it/s]  5%|▍         | 14/300 [00:06<01:54,  2.50it/s]  5%|▌         | 15/300 [00:07<01:54,  2.48it/s]  5%|▌         | 16/300 [00:07<01:54,  2.48it/s]  6%|▌         | 17/300 [00:08<01:53,  2.49it/s]  6%|▌         | 18/300 [00:08<01:52,  2.51it/s]  6%|▋         | 19/300 [00:08<01:51,  2.51it/s]  7%|▋         | 20/300 [00:09<01:52,  2.49it/s]  7%|▋         | 21/300 [00:09<01:51,  2.51it/s]  7%|▋         | 22/300 [00:10<01:49,  2.53it/s]  8%|▊         | 23/300 [00:10<01:49,  2.53it/s]  8%|▊         | 24/300 [00:10<01:48,  2.55it/s]  8%|▊         | 25/300 [00:11<01:46,  2.58it/s]  9%|▊         | 26/300 [00:11<01:45,  2.60it/s]  9%|▉         | 27/300 [00:12<01:46,  2.56it/s]  9%|▉         | 28/300 [00:12<01:48,  2.50it/s] 10%|▉         | 29/300 [00:12<01:48,  2.51it/s] 10%|█         | 30/300 [00:13<01:48,  2.48it/s] 10%|█         | 31/300 [00:13<01:47,  2.50it/s] 11%|█         | 32/300 [00:14<01:47,  2.49it/s] 11%|█         | 33/300 [00:14<01:46,  2.50it/s] 11%|█▏        | 34/300 [00:14<01:46,  2.51it/s] 12%|█▏        | 35/300 [00:15<01:45,  2.52it/s] 12%|█▏        | 36/300 [00:15<01:44,  2.54it/s] 12%|█▏        | 37/300 [00:16<01:43,  2.55it/s] 13%|█▎        | 38/300 [00:16<01:45,  2.49it/s] 13%|█▎        | 39/300 [00:16<01:44,  2.50it/s] 13%|█▎        | 40/300 [00:17<01:43,  2.50it/s] 14%|█▎        | 41/300 [00:17<01:45,  2.45it/s] 14%|█▍        | 42/300 [00:18<01:51,  2.32it/s] 14%|█▍        | 43/300 [00:18<01:47,  2.39it/s] 15%|█▍        | 44/300 [00:19<01:45,  2.42it/s] 15%|█▌        | 45/300 [00:19<01:44,  2.45it/s] 15%|█▌        | 46/300 [00:19<01:43,  2.46it/s] 16%|█▌        | 47/300 [00:20<01:41,  2.48it/s] 16%|█▌        | 48/300 [00:20<01:41,  2.49it/s] 16%|█▋        | 49/300 [00:21<01:40,  2.50it/s] 17%|█▋        | 50/300 [00:21<01:39,  2.51it/s] 17%|█▋        | 51/300 [00:21<01:39,  2.50it/s] 17%|█▋        | 52/300 [00:22<01:38,  2.51it/s] 18%|█▊        | 53/300 [00:22<01:38,  2.51it/s] 18%|█▊        | 54/300 [00:23<01:37,  2.52it/s] 18%|█▊        | 55/300 [00:23<01:37,  2.52it/s] 19%|█▊        | 56/300 [00:23<01:36,  2.52it/s] 19%|█▉        | 57/300 [00:24<01:36,  2.52it/s] 19%|█▉        | 58/300 [00:24<01:35,  2.52it/s] 20%|█▉        | 59/300 [00:24<01:34,  2.54it/s] 20%|██        | 60/300 [00:25<01:33,  2.56it/s] 20%|██        | 61/300 [00:25<01:32,  2.58it/s] 21%|██        | 62/300 [00:26<01:32,  2.57it/s] 21%|██        | 63/300 [00:26<01:32,  2.57it/s] 21%|██▏       | 64/300 [00:26<01:32,  2.56it/s] 22%|██▏       | 65/300 [00:27<01:31,  2.56it/s] 22%|██▏       | 66/300 [00:27<01:31,  2.55it/s] 22%|██▏       | 67/300 [00:28<01:31,  2.55it/s] 23%|██▎       | 68/300 [00:28<01:30,  2.56it/s] 23%|██▎       | 69/300 [00:28<01:29,  2.57it/s] 23%|██▎       | 70/300 [00:29<01:29,  2.57it/s] 24%|██▎       | 71/300 [00:29<01:29,  2.57it/s] 24%|██▍       | 72/300 [00:30<01:28,  2.57it/s] 24%|██▍       | 73/300 [00:30<01:28,  2.56it/s] 25%|██▍       | 74/300 [00:30<01:28,  2.56it/s] 25%|██▌       | 75/300 [00:31<01:27,  2.57it/s] 25%|██▌       | 76/300 [00:31<01:27,  2.56it/s] 26%|██▌       | 77/300 [00:31<01:26,  2.57it/s] 26%|██▌       | 78/300 [00:32<01:27,  2.54it/s] 26%|██▋       | 79/300 [00:32<01:27,  2.52it/s] 27%|██▋       | 80/300 [00:33<01:26,  2.53it/s] 27%|██▋       | 81/300 [00:33<01:26,  2.53it/s] 27%|██▋       | 82/300 [00:33<01:25,  2.54it/s] 28%|██▊       | 83/300 [00:34<01:24,  2.57it/s] 28%|██▊       | 84/300 [00:34<01:23,  2.59it/s] 28%|██▊       | 85/300 [00:35<01:22,  2.61it/s] 29%|██▊       | 86/300 [00:35<01:21,  2.63it/s] 29%|██▉       | 87/300 [00:35<01:20,  2.64it/s] 29%|██▉       | 88/300 [00:36<01:20,  2.64it/s] 30%|██▉       | 89/300 [00:36<01:19,  2.64it/s] 30%|███       | 90/300 [00:36<01:19,  2.65it/s] 30%|███       | 91/300 [00:37<01:19,  2.64it/s] 31%|███       | 92/300 [00:37<01:18,  2.64it/s] 31%|███       | 93/300 [00:38<01:18,  2.64it/s] 31%|███▏      | 94/300 [00:38<01:17,  2.65it/s] 32%|███▏      | 95/300 [00:38<01:17,  2.66it/s] 32%|███▏      | 96/300 [00:39<01:16,  2.66it/s] 32%|███▏      | 97/300 [00:39<01:16,  2.65it/s] 33%|███▎      | 98/300 [00:40<01:16,  2.63it/s] 33%|███▎      | 99/300 [00:40<01:16,  2.63it/s] 33%|███▎      | 100/300 [00:40<01:16,  2.62it/s] 34%|███▎      | 101/300 [00:41<01:15,  2.63it/s] 34%|███▍      | 102/300 [00:41<01:15,  2.62it/s] 34%|███▍      | 103/300 [00:41<01:14,  2.65it/s] 35%|███▍      | 104/300 [00:42<01:13,  2.66it/s] 35%|███▌      | 105/300 [00:42<01:13,  2.66it/s] 35%|███▌      | 106/300 [00:43<01:13,  2.64it/s] 36%|███▌      | 107/300 [00:43<01:13,  2.64it/s] 36%|███▌      | 108/300 [00:43<01:12,  2.64it/s] 36%|███▋      | 109/300 [00:44<01:12,  2.62it/s] 37%|███▋      | 110/300 [00:44<01:12,  2.61it/s] 37%|███▋      | 111/300 [00:44<01:11,  2.63it/s] 37%|███▋      | 112/300 [00:45<01:11,  2.62it/s] 38%|███▊      | 113/300 [00:45<01:11,  2.62it/s] 38%|███▊      | 114/300 [00:46<01:11,  2.62it/s] 38%|███▊      | 115/300 [00:46<01:10,  2.64it/s] 39%|███▊      | 116/300 [00:46<01:10,  2.61it/s] 39%|███▉      | 117/300 [00:47<01:09,  2.62it/s] 39%|███▉      | 118/300 [00:47<01:09,  2.62it/s] 40%|███▉      | 119/300 [00:48<01:08,  2.63it/s] 40%|████      | 120/300 [00:48<01:08,  2.61it/s] 40%|████      | 121/300 [00:48<01:08,  2.61it/s] 41%|████      | 122/300 [00:49<01:08,  2.60it/s] 41%|████      | 123/300 [00:49<01:07,  2.62it/s] 41%|████▏     | 124/300 [00:49<01:07,  2.62it/s] 42%|████▏     | 125/300 [00:50<01:06,  2.63it/s] 42%|████▏     | 126/300 [00:50<01:05,  2.64it/s] 42%|████▏     | 127/300 [00:51<01:05,  2.64it/s] 43%|████▎     | 128/300 [00:51<01:05,  2.64it/s] 43%|████▎     | 129/300 [00:51<01:04,  2.65it/s] 43%|████▎     | 130/300 [00:52<01:03,  2.66it/s] 44%|████▎     | 131/300 [00:52<01:03,  2.66it/s] 44%|████▍     | 132/300 [00:52<01:03,  2.66it/s] 44%|████▍     | 133/300 [00:53<01:03,  2.64it/s] 45%|████▍     | 134/300 [00:53<01:02,  2.64it/s] 45%|████▌     | 135/300 [00:54<01:02,  2.65it/s] 45%|████▌     | 136/300 [00:54<01:01,  2.65it/s] 46%|████▌     | 137/300 [00:54<01:01,  2.65it/s] 46%|████▌     | 138/300 [00:55<01:01,  2.66it/s] 46%|████▋     | 139/300 [00:55<01:01,  2.62it/s] 47%|████▋     | 140/300 [00:55<01:01,  2.62it/s] 47%|████▋     | 141/300 [00:56<01:00,  2.64it/s] 47%|████▋     | 142/300 [00:56<01:00,  2.63it/s] 48%|████▊     | 143/300 [00:57<01:00,  2.61it/s] 48%|████▊     | 144/300 [00:57<00:59,  2.62it/s] 48%|████▊     | 145/300 [00:57<00:59,  2.61it/s] 49%|████▊     | 146/300 [00:58<00:58,  2.62it/s] 49%|████▉     | 147/300 [00:58<00:58,  2.62it/s] 49%|████▉     | 148/300 [00:59<00:57,  2.63it/s] 50%|████▉     | 149/300 [00:59<00:57,  2.63it/s] 50%|█████     | 150/300 [00:59<00:56,  2.64it/s] 50%|█████     | 151/300 [01:00<00:56,  2.63it/s] 51%|█████     | 152/300 [01:00<00:56,  2.62it/s] 51%|█████     | 153/300 [01:00<00:56,  2.62it/s] 51%|█████▏    | 154/300 [01:01<00:55,  2.63it/s] 52%|█████▏    | 155/300 [01:01<00:55,  2.63it/s] 52%|█████▏    | 156/300 [01:02<00:55,  2.62it/s] 52%|█████▏    | 157/300 [01:02<00:55,  2.59it/s] 53%|█████▎    | 158/300 [01:02<00:54,  2.59it/s] 53%|█████▎    | 159/300 [01:03<00:54,  2.57it/s] 53%|█████▎    | 160/300 [01:03<00:54,  2.55it/s] 54%|█████▎    | 161/300 [01:04<00:54,  2.57it/s] 54%|█████▍    | 162/300 [01:04<00:53,  2.60it/s] 54%|█████▍    | 163/300 [01:04<00:52,  2.63it/s] 55%|█████▍    | 164/300 [01:05<00:51,  2.63it/s] 55%|█████▌    | 165/300 [01:05<00:51,  2.64it/s] 55%|█████▌    | 166/300 [01:05<00:51,  2.62it/s] 56%|█████▌    | 167/300 [01:06<00:50,  2.63it/s] 56%|█████▌    | 168/300 [01:06<00:50,  2.64it/s] 56%|█████▋    | 169/300 [01:07<00:49,  2.64it/s] 57%|█████▋    | 170/300 [01:07<00:49,  2.65it/s] 57%|█████▋    | 171/300 [01:07<00:48,  2.66it/s] 57%|█████▋    | 172/300 [01:08<00:47,  2.67it/s] 58%|█████▊    | 173/300 [01:08<00:47,  2.67it/s] 58%|█████▊    | 174/300 [01:08<00:47,  2.65it/s] 58%|█████▊    | 175/300 [01:09<00:47,  2.64it/s] 59%|█████▊    | 176/300 [01:09<00:47,  2.64it/s] 59%|█████▉    | 177/300 [01:10<00:46,  2.64it/s] 59%|█████▉    | 178/300 [01:10<00:46,  2.63it/s] 60%|█████▉    | 179/300 [01:10<00:45,  2.63it/s] 60%|██████    | 180/300 [01:11<00:45,  2.64it/s] 60%|██████    | 181/300 [01:11<00:44,  2.66it/s] 61%|██████    | 182/300 [01:11<00:44,  2.67it/s] 61%|██████    | 183/300 [01:12<00:44,  2.64it/s] 61%|██████▏   | 184/300 [01:12<00:43,  2.65it/s] 62%|██████▏   | 185/300 [01:13<00:43,  2.65it/s] 62%|██████▏   | 186/300 [01:13<00:43,  2.65it/s] 62%|██████▏   | 187/300 [01:13<00:42,  2.65it/s] 63%|██████▎   | 188/300 [01:14<00:42,  2.64it/s] 63%|██████▎   | 189/300 [01:14<00:41,  2.65it/s] 63%|██████▎   | 190/300 [01:14<00:41,  2.65it/s] 64%|██████▎   | 191/300 [01:15<00:41,  2.65it/s] 64%|██████▍   | 192/300 [01:15<00:40,  2.64it/s] 64%|██████▍   | 193/300 [01:16<00:40,  2.63it/s] 65%|██████▍   | 194/300 [01:16<00:40,  2.64it/s] 65%|██████▌   | 195/300 [01:16<00:39,  2.64it/s] 65%|██████▌   | 196/300 [01:17<00:39,  2.64it/s] 66%|██████▌   | 197/300 [01:17<00:39,  2.64it/s] 66%|██████▌   | 198/300 [01:18<00:38,  2.63it/s] 66%|██████▋   | 199/300 [01:18<00:38,  2.62it/s] 67%|██████▋   | 200/300 [01:18<00:38,  2.60it/s] 67%|██████▋   | 201/300 [01:19<00:38,  2.58it/s] 67%|██████▋   | 202/300 [01:19<00:38,  2.57it/s] 68%|██████▊   | 203/300 [01:19<00:37,  2.57it/s] 68%|██████▊   | 204/300 [01:20<00:37,  2.57it/s] 68%|██████▊   | 205/300 [01:20<00:37,  2.55it/s] 69%|██████▊   | 206/300 [01:21<00:36,  2.55it/s] 69%|██████▉   | 207/300 [01:21<00:36,  2.54it/s] 69%|██████▉   | 208/300 [01:21<00:36,  2.54it/s] 70%|██████▉   | 209/300 [01:22<00:35,  2.54it/s] 70%|███████   | 210/300 [01:22<00:35,  2.56it/s] 70%|███████   | 211/300 [01:23<00:34,  2.56it/s] 71%|███████   | 212/300 [01:23<00:34,  2.56it/s] 71%|███████   | 213/300 [01:23<00:33,  2.56it/s] 71%|███████▏  | 214/300 [01:24<00:33,  2.55it/s] 72%|███████▏  | 215/300 [01:24<00:33,  2.56it/s] 72%|███████▏  | 216/300 [01:25<00:32,  2.55it/s] 72%|███████▏  | 217/300 [01:25<00:32,  2.55it/s] 73%|███████▎  | 218/300 [01:25<00:32,  2.55it/s] 73%|███████▎  | 219/300 [01:26<00:31,  2.53it/s] 73%|███████▎  | 220/300 [01:26<00:31,  2.53it/s] 74%|███████▎  | 221/300 [01:27<00:31,  2.54it/s] 74%|███████▍  | 222/300 [01:27<00:30,  2.55it/s] 74%|███████▍  | 223/300 [01:27<00:30,  2.55it/s] 75%|███████▍  | 224/300 [01:28<00:29,  2.55it/s] 75%|███████▌  | 225/300 [01:28<00:29,  2.56it/s] 75%|███████▌  | 226/300 [01:28<00:29,  2.55it/s] 76%|███████▌  | 227/300 [01:29<00:28,  2.52it/s] 76%|███████▌  | 228/300 [01:29<00:28,  2.55it/s] 76%|███████▋  | 229/300 [01:30<00:28,  2.53it/s] 77%|███████▋  | 230/300 [01:30<00:27,  2.53it/s] 77%|███████▋  | 231/300 [01:30<00:27,  2.55it/s] 77%|███████▋  | 232/300 [01:31<00:26,  2.53it/s] 78%|███████▊  | 233/300 [01:31<00:26,  2.52it/s] 78%|███████▊  | 234/300 [01:32<00:26,  2.52it/s] 78%|███████▊  | 235/300 [01:32<00:25,  2.54it/s] 79%|███████▊  | 236/300 [01:32<00:25,  2.54it/s] 79%|███████▉  | 237/300 [01:33<00:24,  2.55it/s] 79%|███████▉  | 238/300 [01:33<00:24,  2.54it/s] 80%|███████▉  | 239/300 [01:34<00:23,  2.55it/s] 80%|████████  | 240/300 [01:34<00:23,  2.55it/s] 80%|████████  | 241/300 [01:34<00:23,  2.54it/s] 81%|████████  | 242/300 [01:35<00:22,  2.55it/s] 81%|████████  | 243/300 [01:35<00:22,  2.55it/s] 81%|████████▏ | 244/300 [01:36<00:21,  2.56it/s] 82%|████████▏ | 245/300 [01:36<00:21,  2.57it/s] 82%|████████▏ | 246/300 [01:36<00:20,  2.59it/s] 82%|████████▏ | 247/300 [01:37<00:20,  2.61it/s] 83%|████████▎ | 248/300 [01:37<00:19,  2.63it/s] 83%|████████▎ | 249/300 [01:37<00:19,  2.64it/s] 83%|████████▎ | 250/300 [01:38<00:19,  2.63it/s] 84%|████████▎ | 251/300 [01:38<00:18,  2.64it/s] 84%|████████▍ | 252/300 [01:39<00:18,  2.63it/s] 84%|████████▍ | 253/300 [01:39<00:17,  2.65it/s] 85%|████████▍ | 254/300 [01:39<00:17,  2.65it/s] 85%|████████▌ | 255/300 [01:40<00:16,  2.65it/s] 85%|████████▌ | 256/300 [01:40<00:16,  2.62it/s] 86%|████████▌ | 257/300 [01:41<00:16,  2.63it/s] 86%|████████▌ | 258/300 [01:41<00:15,  2.64it/s] 86%|████████▋ | 259/300 [01:41<00:15,  2.64it/s] 87%|████████▋ | 260/300 [01:42<00:15,  2.65it/s] 87%|████████▋ | 261/300 [01:42<00:14,  2.66it/s] 87%|████████▋ | 262/300 [01:42<00:14,  2.65it/s] 88%|████████▊ | 263/300 [01:43<00:14,  2.62it/s] 88%|████████▊ | 264/300 [01:43<00:13,  2.63it/s] 88%|████████▊ | 265/300 [01:44<00:13,  2.60it/s] 89%|████████▊ | 266/300 [01:44<00:13,  2.59it/s] 89%|████████▉ | 267/300 [01:44<00:12,  2.60it/s] 89%|████████▉ | 268/300 [01:45<00:12,  2.60it/s] 90%|████████▉ | 269/300 [01:45<00:11,  2.63it/s] 90%|█████████ | 270/300 [01:45<00:11,  2.63it/s] 90%|█████████ | 271/300 [01:46<00:10,  2.64it/s] 91%|█████████ | 272/300 [01:46<00:10,  2.64it/s] 91%|█████████ | 273/300 [01:47<00:10,  2.64it/s] 91%|█████████▏| 274/300 [01:47<00:09,  2.63it/s] 92%|█████████▏| 275/300 [01:47<00:09,  2.63it/s] 92%|█████████▏| 276/300 [01:48<00:09,  2.64it/s] 92%|█████████▏| 277/300 [01:48<00:08,  2.65it/s] 93%|█████████▎| 278/300 [01:48<00:08,  2.64it/s] 93%|█████████▎| 279/300 [01:49<00:07,  2.64it/s] 93%|█████████▎| 280/300 [01:49<00:07,  2.64it/s] 94%|█████████▎| 281/300 [01:50<00:07,  2.63it/s] 94%|█████████▍| 282/300 [01:50<00:06,  2.63it/s] 94%|█████████▍| 283/300 [01:50<00:06,  2.65it/s] 95%|█████████▍| 284/300 [01:51<00:06,  2.65it/s] 95%|█████████▌| 285/300 [01:51<00:05,  2.64it/s] 95%|█████████▌| 286/300 [01:52<00:05,  2.64it/s] 96%|█████████▌| 287/300 [01:52<00:04,  2.64it/s] 96%|█████████▌| 288/300 [01:52<00:04,  2.64it/s] 96%|█████████▋| 289/300 [01:53<00:04,  2.63it/s] 97%|█████████▋| 290/300 [01:53<00:03,  2.62it/s] 97%|█████████▋| 291/300 [01:53<00:03,  2.65it/s] 97%|█████████▋| 292/300 [01:54<00:03,  2.65it/s] 98%|█████████▊| 293/300 [01:54<00:02,  2.64it/s] 98%|█████████▊| 294/300 [01:55<00:02,  2.64it/s] 98%|█████████▊| 295/300 [01:55<00:01,  2.65it/s] 99%|█████████▊| 296/300 [01:55<00:01,  2.65it/s] 99%|█████████▉| 297/300 [01:56<00:01,  2.64it/s] 99%|█████████▉| 298/300 [01:56<00:00,  2.64it/s]100%|█████████▉| 299/300 [01:56<00:00,  2.63it/s]100%|██████████| 300/300 [01:57<00:00,  2.64it/s]100%|██████████| 300/300 [01:57<00:00,  2.56it/s]
W&B disabled.
W&B online. Running your script from this directory will now sync to the cloud.
wandb: Currently logged in as: hl57. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /media/techt/One Touch/DD/SRe2L/train/wandb/run-20231023_181301-fqp92zx8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-pond-496
wandb: ⭐️ View project at https://wandb.ai/hl57/final_rn18_fkd
wandb: 🚀 View run at https://wandb.ai/hl57/final_rn18_fkd/runs/fqp92zx8
======= FKD: dataset info ======
path: ../relabel/FKD_cutmix_fp16/imagenette/326/
num img: 10
batch size: 10
max epoch: 300
================================
load data successfully
=> loading student model 'resnet18'
TRAIN Iter 0: lr = 0.001000,	loss = 0.022601,	Top-1 err = 90.000000,	Top-5 err = 60.000000,	train_time = 2.936613
TEST Iter 0: loss = 6.903706,	Top-1 err = 89.324841,	Top-5 err = 50.547771,	val_time = 15.611580
TRAIN Iter 10: lr = 0.000997,	loss = 0.013567,	Top-1 err = 80.000000,	Top-5 err = 10.000000,	train_time = 2.114023
TEST Iter 10: loss = 41.789137,	Top-1 err = 87.796178,	Top-5 err = 49.987261,	val_time = 15.716093
TRAIN Iter 20: lr = 0.000989,	loss = 0.011651,	Top-1 err = 90.000000,	Top-5 err = 60.000000,	train_time = 2.118964
TEST Iter 20: loss = 65.360373,	Top-1 err = 85.121019,	Top-5 err = 40.636943,	val_time = 15.543253
TRAIN Iter 30: lr = 0.000976,	loss = 0.009663,	Top-1 err = 90.000000,	Top-5 err = 20.000000,	train_time = 2.113371
TEST Iter 30: loss = 14.621914,	Top-1 err = 80.585987,	Top-5 err = 38.216561,	val_time = 15.537333
TRAIN Iter 40: lr = 0.000957,	loss = 0.012334,	Top-1 err = 50.000000,	Top-5 err = 10.000000,	train_time = 2.126753
TEST Iter 40: loss = 17.337499,	Top-1 err = 80.076433,	Top-5 err = 36.229299,	val_time = 15.682850
TRAIN Iter 50: lr = 0.000933,	loss = 0.008849,	Top-1 err = 40.000000,	Top-5 err = 0.000000,	train_time = 2.118848
TEST Iter 50: loss = 30.226856,	Top-1 err = 82.242038,	Top-5 err = 41.452229,	val_time = 15.561298
TRAIN Iter 60: lr = 0.000905,	loss = 0.007990,	Top-1 err = 70.000000,	Top-5 err = 0.000000,	train_time = 2.113014
TEST Iter 60: loss = 15.210917,	Top-1 err = 74.573248,	Top-5 err = 32.407643,	val_time = 16.057096
TRAIN Iter 70: lr = 0.000872,	loss = 0.007609,	Top-1 err = 80.000000,	Top-5 err = 30.000000,	train_time = 2.105429
TEST Iter 70: loss = 11.363704,	Top-1 err = 76.560510,	Top-5 err = 33.222930,	val_time = 15.569552
TRAIN Iter 80: lr = 0.000835,	loss = 0.005809,	Top-1 err = 30.000000,	Top-5 err = 0.000000,	train_time = 2.132577
TEST Iter 80: loss = 9.089048,	Top-1 err = 84.611465,	Top-5 err = 38.140127,	val_time = 15.621620
TRAIN Iter 90: lr = 0.000794,	loss = 0.008360,	Top-1 err = 10.000000,	Top-5 err = 0.000000,	train_time = 2.095132
TEST Iter 90: loss = 7.936333,	Top-1 err = 75.949045,	Top-5 err = 35.872611,	val_time = 15.468929
TRAIN Iter 100: lr = 0.000750,	loss = 0.006805,	Top-1 err = 100.000000,	Top-5 err = 30.000000,	train_time = 2.129489
TEST Iter 100: loss = 9.084491,	Top-1 err = 74.802548,	Top-5 err = 31.363057,	val_time = 15.779775
TRAIN Iter 110: lr = 0.000703,	loss = 0.006455,	Top-1 err = 100.000000,	Top-5 err = 30.000000,	train_time = 2.122070
TEST Iter 110: loss = 7.328523,	Top-1 err = 69.630573,	Top-5 err = 28.636943,	val_time = 15.567798
TRAIN Iter 120: lr = 0.000655,	loss = 0.006776,	Top-1 err = 40.000000,	Top-5 err = 0.000000,	train_time = 2.161886
TEST Iter 120: loss = 8.926502,	Top-1 err = 74.649682,	Top-5 err = 30.471338,	val_time = 15.509895
TRAIN Iter 130: lr = 0.000604,	loss = 0.007206,	Top-1 err = 30.000000,	Top-5 err = 0.000000,	train_time = 2.109632
TEST Iter 130: loss = 7.630496,	Top-1 err = 70.038217,	Top-5 err = 27.694268,	val_time = 15.693133
TRAIN Iter 140: lr = 0.000552,	loss = 0.004261,	Top-1 err = 10.000000,	Top-5 err = 0.000000,	train_time = 2.080528
TEST Iter 140: loss = 8.459402,	Top-1 err = 71.006369,	Top-5 err = 27.923567,	val_time = 15.457396
TRAIN Iter 150: lr = 0.000500,	loss = 0.005264,	Top-1 err = 90.000000,	Top-5 err = 0.000000,	train_time = 2.141043
TEST Iter 150: loss = 9.359936,	Top-1 err = 69.044586,	Top-5 err = 24.815287,	val_time = 15.313623
TRAIN Iter 160: lr = 0.000448,	loss = 0.004457,	Top-1 err = 80.000000,	Top-5 err = 0.000000,	train_time = 2.072355
TEST Iter 160: loss = 8.029751,	Top-1 err = 69.197452,	Top-5 err = 24.764331,	val_time = 15.422709
TRAIN Iter 170: lr = 0.000396,	loss = 0.005084,	Top-1 err = 30.000000,	Top-5 err = 0.000000,	train_time = 2.103347
TEST Iter 170: loss = 7.394970,	Top-1 err = 68.076433,	Top-5 err = 24.356688,	val_time = 15.646371
TRAIN Iter 180: lr = 0.000345,	loss = 0.004732,	Top-1 err = 20.000000,	Top-5 err = 0.000000,	train_time = 2.147196
TEST Iter 180: loss = 6.756706,	Top-1 err = 67.031847,	Top-5 err = 22.522293,	val_time = 15.609144
TRAIN Iter 190: lr = 0.000297,	loss = 0.003558,	Top-1 err = 50.000000,	Top-5 err = 0.000000,	train_time = 2.157616
TEST Iter 190: loss = 7.354291,	Top-1 err = 67.745223,	Top-5 err = 24.687898,	val_time = 15.755305
TRAIN Iter 200: lr = 0.000250,	loss = 0.004118,	Top-1 err = 90.000000,	Top-5 err = 40.000000,	train_time = 2.141499
TEST Iter 200: loss = 6.890729,	Top-1 err = 65.375796,	Top-5 err = 23.082803,	val_time = 15.564570
TRAIN Iter 210: lr = 0.000206,	loss = 0.002453,	Top-1 err = 0.000000,	Top-5 err = 0.000000,	train_time = 2.121022
TEST Iter 210: loss = 6.410444,	Top-1 err = 64.254777,	Top-5 err = 22.140127,	val_time = 15.615692
TRAIN Iter 220: lr = 0.000165,	loss = 0.004460,	Top-1 err = 20.000000,	Top-5 err = 0.000000,	train_time = 2.125105
TEST Iter 220: loss = 6.757807,	Top-1 err = 64.433121,	Top-5 err = 21.605096,	val_time = 15.447053
TRAIN Iter 230: lr = 0.000128,	loss = 0.003960,	Top-1 err = 40.000000,	Top-5 err = 0.000000,	train_time = 2.103660
TEST Iter 230: loss = 6.818444,	Top-1 err = 65.146497,	Top-5 err = 21.681529,	val_time = 15.748171
TRAIN Iter 240: lr = 0.000095,	loss = 0.001429,	Top-1 err = 0.000000,	Top-5 err = 0.000000,	train_time = 2.119511
TEST Iter 240: loss = 6.981833,	Top-1 err = 65.095541,	Top-5 err = 22.471338,	val_time = 15.716764
TRAIN Iter 250: lr = 0.000067,	loss = 0.002766,	Top-1 err = 90.000000,	Top-5 err = 40.000000,	train_time = 2.159674
TEST Iter 250: loss = 6.832878,	Top-1 err = 65.070064,	Top-5 err = 22.420382,	val_time = 15.733195
TRAIN Iter 260: lr = 0.000043,	loss = 0.001435,	Top-1 err = 0.000000,	Top-5 err = 0.000000,	train_time = 2.156055
TEST Iter 260: loss = 6.526513,	Top-1 err = 65.197452,	Top-5 err = 22.547771,	val_time = 15.575618
TRAIN Iter 270: lr = 0.000024,	loss = 0.002612,	Top-1 err = 0.000000,	Top-5 err = 0.000000,	train_time = 2.158335
TEST Iter 270: loss = 6.419604,	Top-1 err = 64.942675,	Top-5 err = 22.904459,	val_time = 15.357911
TRAIN Iter 280: lr = 0.000011,	loss = 0.003406,	Top-1 err = 30.000000,	Top-5 err = 0.000000,	train_time = 2.115728
TEST Iter 280: loss = 6.713890,	Top-1 err = 65.222930,	Top-5 err = 23.210191,	val_time = 15.476186
TRAIN Iter 290: lr = 0.000003,	loss = 0.003630,	Top-1 err = 30.000000,	Top-5 err = 0.000000,	train_time = 2.132084
TEST Iter 290: loss = 6.467475,	Top-1 err = 65.044586,	Top-5 err = 22.649682,	val_time = 15.517835
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  train/Top1 ▂▂▂▃▃▅▅▅▅▄▂▃▇▇▂▆▇▃▇███▇▂▄▂▃▇▇█▄▁██▆▅▇██▇
wandb:  train/Top5 ▁▅▅▆████▅█▁▃██▅█▆▁█████▃▅██████▁███▆████
wandb: train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  train/loss █▅▆▅█▆▆▄▅▅▅▄▄▃▃▃▃▃▁▁▁▁▂▂▂▂▂▂▂▁▂▁▂▁▂▃▂▁▁▂
wandb:    train/lr ███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:   val/epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███
wandb:    val/loss ▁▅█▂▂▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    val/top1 ▁▁▂▃▄▃▅▅▂▅▅▆▅▆▆▇▇▇▇▇███████████
wandb:    val/top5 ▁▁▃▄▄▃▅▅▄▅▆▆▆▇▆▇▇▇█▇███████████
wandb: 
wandb: Run summary:
wandb:  train/Top1 90.0
wandb:  train/Top5 100.0
wandb: train/epoch 299
wandb:  train/loss 0.00522
wandb:    train/lr 0.0
wandb:   val/epoch 299
wandb:    val/loss 6.44135
wandb:    val/top1 35.15924
wandb:    val/top5 77.24841
wandb: 
wandb: 🚀 View run bright-pond-496 at: https://wandb.ai/hl57/final_rn18_fkd/runs/fqp92zx8
wandb: ️⚡ View job at https://wandb.ai/hl57/final_rn18_fkd/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjk3MzkyNjU3/version_details/v47
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231023_181301-fqp92zx8/logs
TEST Iter 299: loss = 6.441352,	Top-1 err = 64.840764,	Top-5 err = 22.751592,	val_time = 15.444022
