/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
r_bn:  0.01
lr:  0.25
bc shape torch.Size([10, 10, 512])
get_images call
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
------------iteration 0----------
total loss 117.05385904566627
main criterion 92.82487039820533
weighted_aux_loss 24.228988647460938
loss_r_bn_feature 2422.89892578125
------------iteration 100----------
total loss 59.39459373328218
main criterion 40.76042129370698
weighted_aux_loss 18.634172439575195
loss_r_bn_feature 1863.4173583984375
------------iteration 200----------
total loss 51.160831615819475
main criterion 34.596161053075335
weighted_aux_loss 16.56467056274414
loss_r_bn_feature 1656.467041015625
------------iteration 300----------
total loss 46.189766692270055
main criterion 30.96156387244584
weighted_aux_loss 15.228202819824219
loss_r_bn_feature 1522.8203125
------------iteration 400----------
total loss 44.628274335665076
main criterion 30.718264951509802
weighted_aux_loss 13.910009384155273
loss_r_bn_feature 1391.0009765625
------------iteration 500----------
total loss 43.052795233863506
main criterion 28.507160964149154
weighted_aux_loss 14.545634269714355
loss_r_bn_feature 1454.5634765625
------------iteration 600----------
total loss 41.175323503546934
main criterion 26.94207288556598
weighted_aux_loss 14.233250617980957
loss_r_bn_feature 1423.3250732421875
------------iteration 700----------
total loss 40.55782734300473
main criterion 28.625020374315763
weighted_aux_loss 11.932806968688965
loss_r_bn_feature 1193.28076171875
------------iteration 800----------
total loss 38.37247181052729
main criterion 27.403039933391057
weighted_aux_loss 10.96943187713623
loss_r_bn_feature 1096.9432373046875
------------iteration 900----------
total loss 37.42322755143061
main criterion 26.41030621811762
weighted_aux_loss 11.012921333312988
loss_r_bn_feature 1101.2921142578125
------------iteration 1000----------
total loss 31.940313316417836
main criterion 22.043057418895863
weighted_aux_loss 9.897255897521973
loss_r_bn_feature 989.7256469726562
------------iteration 1100----------
total loss 32.14216308940634
main criterion 23.888193896901452
weighted_aux_loss 8.253969192504883
loss_r_bn_feature 825.3969116210938
------------iteration 1200----------
total loss 28.482760153236164
main criterion 19.75578757328011
weighted_aux_loss 8.726972579956055
loss_r_bn_feature 872.697265625
------------iteration 1300----------
total loss 28.836113777261453
main criterion 22.573727932077126
weighted_aux_loss 6.262385845184326
loss_r_bn_feature 626.2385864257812
------------iteration 1400----------
total loss 30.9419661682113
main criterion 24.855128399656614
weighted_aux_loss 6.0868377685546875
loss_r_bn_feature 608.6837768554688
------------iteration 1500----------
total loss 22.01524347542577
main criterion 16.072640840995838
weighted_aux_loss 5.942602634429932
loss_r_bn_feature 594.26025390625
------------iteration 1600----------
total loss 23.303088067243223
main criterion 17.708299992749815
weighted_aux_loss 5.594788074493408
loss_r_bn_feature 559.4788208007812
------------iteration 1700----------
total loss 21.5731812890578
main criterion 15.911023753504823
weighted_aux_loss 5.6621575355529785
loss_r_bn_feature 566.2157592773438
------------iteration 1800----------
total loss 19.80960132959956
main criterion 14.448048614298045
weighted_aux_loss 5.361552715301514
loss_r_bn_feature 536.1552734375
------------iteration 1900----------
total loss 19.847215541220432
main criterion 14.77951753935886
weighted_aux_loss 5.067698001861572
loss_r_bn_feature 506.7698059082031
=> using pytorch pre-trained model 'resnet18'
process data from ../recover/syn_data/imagenette/245
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 1/300 [00:01<09:41,  1.94s/it]  1%|          | 2/300 [00:02<05:48,  1.17s/it]  1%|          | 3/300 [00:03<04:34,  1.08it/s]  1%|▏         | 4/300 [00:03<03:59,  1.23it/s]  2%|▏         | 5/300 [00:04<03:39,  1.34it/s]  2%|▏         | 6/300 [00:05<03:28,  1.41it/s]  2%|▏         | 7/300 [00:05<03:18,  1.47it/s]  3%|▎         | 8/300 [00:06<03:13,  1.51it/s]  3%|▎         | 9/300 [00:06<03:10,  1.53it/s]  3%|▎         | 10/300 [00:07<03:07,  1.55it/s]  4%|▎         | 11/300 [00:08<03:06,  1.55it/s]  4%|▍         | 12/300 [00:08<03:04,  1.56it/s]  4%|▍         | 13/300 [00:09<03:04,  1.56it/s]  5%|▍         | 14/300 [00:10<03:03,  1.55it/s]  5%|▌         | 15/300 [00:10<03:02,  1.57it/s]  5%|▌         | 16/300 [00:11<02:59,  1.58it/s]  6%|▌         | 17/300 [00:12<02:59,  1.58it/s]  6%|▌         | 18/300 [00:12<03:00,  1.57it/s]  6%|▋         | 19/300 [00:13<02:59,  1.56it/s]  7%|▋         | 20/300 [00:13<02:58,  1.57it/s]  7%|▋         | 21/300 [00:14<02:57,  1.57it/s]  7%|▋         | 22/300 [00:15<02:55,  1.58it/s]  8%|▊         | 23/300 [00:15<02:53,  1.59it/s]  8%|▊         | 24/300 [00:16<02:52,  1.60it/s]  8%|▊         | 25/300 [00:17<02:51,  1.60it/s]  9%|▊         | 26/300 [00:17<02:51,  1.60it/s]  9%|▉         | 27/300 [00:18<02:50,  1.60it/s]  9%|▉         | 28/300 [00:18<02:48,  1.61it/s] 10%|▉         | 29/300 [00:19<02:47,  1.61it/s] 10%|█         | 30/300 [00:20<02:47,  1.61it/s] 10%|█         | 31/300 [00:20<02:46,  1.62it/s] 11%|█         | 32/300 [00:21<02:47,  1.60it/s] 11%|█         | 33/300 [00:22<02:45,  1.61it/s] 11%|█▏        | 34/300 [00:22<02:45,  1.60it/s] 12%|█▏        | 35/300 [00:23<02:45,  1.60it/s] 12%|█▏        | 36/300 [00:23<02:44,  1.60it/s] 12%|█▏        | 37/300 [00:24<02:43,  1.61it/s] 13%|█▎        | 38/300 [00:25<02:44,  1.59it/s] 13%|█▎        | 39/300 [00:25<02:44,  1.59it/s] 13%|█▎        | 40/300 [00:26<02:47,  1.56it/s] 14%|█▎        | 41/300 [00:27<02:47,  1.55it/s] 14%|█▍        | 42/300 [00:27<02:48,  1.53it/s] 14%|█▍        | 43/300 [00:28<02:45,  1.55it/s] 15%|█▍        | 44/300 [00:29<02:44,  1.56it/s] 15%|█▌        | 45/300 [00:29<02:43,  1.56it/s] 15%|█▌        | 46/300 [00:30<02:43,  1.56it/s] 16%|█▌        | 47/300 [00:31<02:42,  1.56it/s] 16%|█▌        | 48/300 [00:31<02:40,  1.57it/s] 16%|█▋        | 49/300 [00:32<02:40,  1.56it/s] 17%|█▋        | 50/300 [00:32<02:40,  1.56it/s] 17%|█▋        | 51/300 [00:33<02:40,  1.55it/s] 17%|█▋        | 52/300 [00:34<02:38,  1.56it/s] 18%|█▊        | 53/300 [00:34<02:38,  1.55it/s] 18%|█▊        | 54/300 [00:35<02:38,  1.55it/s] 18%|█▊        | 55/300 [00:36<02:37,  1.55it/s] 19%|█▊        | 56/300 [00:36<02:44,  1.49it/s] 19%|█▉        | 57/300 [00:37<02:40,  1.51it/s] 19%|█▉        | 58/300 [00:38<02:37,  1.54it/s] 20%|█▉        | 59/300 [00:38<02:34,  1.56it/s] 20%|██        | 60/300 [00:39<02:31,  1.58it/s] 20%|██        | 61/300 [00:40<02:30,  1.58it/s] 21%|██        | 62/300 [00:40<02:29,  1.59it/s] 21%|██        | 63/300 [00:41<02:27,  1.61it/s] 21%|██▏       | 64/300 [00:41<02:25,  1.62it/s] 22%|██▏       | 65/300 [00:42<02:25,  1.62it/s] 22%|██▏       | 66/300 [00:43<02:24,  1.62it/s] 22%|██▏       | 67/300 [00:43<02:24,  1.61it/s] 23%|██▎       | 68/300 [00:44<02:23,  1.61it/s] 23%|██▎       | 69/300 [00:44<02:25,  1.58it/s] 23%|██▎       | 70/300 [00:45<02:23,  1.60it/s] 24%|██▎       | 71/300 [00:46<02:22,  1.61it/s] 24%|██▍       | 72/300 [00:46<02:22,  1.60it/s] 24%|██▍       | 73/300 [00:47<02:20,  1.61it/s] 25%|██▍       | 74/300 [00:48<02:20,  1.61it/s] 25%|██▌       | 75/300 [00:48<02:20,  1.60it/s] 25%|██▌       | 76/300 [00:49<02:19,  1.61it/s] 26%|██▌       | 77/300 [00:49<02:18,  1.60it/s] 26%|██▌       | 78/300 [00:50<02:20,  1.58it/s] 26%|██▋       | 79/300 [00:51<02:19,  1.59it/s] 27%|██▋       | 80/300 [00:51<02:19,  1.58it/s] 27%|██▋       | 81/300 [00:52<02:19,  1.57it/s] 27%|██▋       | 82/300 [00:53<02:20,  1.56it/s] 28%|██▊       | 83/300 [00:53<02:19,  1.56it/s] 28%|██▊       | 84/300 [00:54<02:17,  1.57it/s] 28%|██▊       | 85/300 [00:55<02:17,  1.56it/s] 29%|██▊       | 86/300 [00:55<02:17,  1.55it/s] 29%|██▉       | 87/300 [00:56<02:17,  1.55it/s] 29%|██▉       | 88/300 [00:57<02:16,  1.56it/s] 30%|██▉       | 89/300 [00:57<02:15,  1.56it/s] 30%|███       | 90/300 [00:58<02:14,  1.56it/s] 30%|███       | 91/300 [00:58<02:13,  1.57it/s] 31%|███       | 92/300 [00:59<02:12,  1.57it/s] 31%|███       | 93/300 [01:00<02:10,  1.59it/s] 31%|███▏      | 94/300 [01:00<02:09,  1.59it/s] 32%|███▏      | 95/300 [01:01<02:08,  1.60it/s] 32%|███▏      | 96/300 [01:02<02:06,  1.61it/s] 32%|███▏      | 97/300 [01:02<02:06,  1.60it/s] 33%|███▎      | 98/300 [01:03<02:05,  1.61it/s] 33%|███▎      | 99/300 [01:03<02:04,  1.62it/s] 33%|███▎      | 100/300 [01:04<02:03,  1.61it/s] 34%|███▎      | 101/300 [01:05<02:02,  1.62it/s] 34%|███▍      | 102/300 [01:05<02:01,  1.63it/s] 34%|███▍      | 103/300 [01:06<02:02,  1.61it/s] 35%|███▍      | 104/300 [01:06<02:01,  1.62it/s] 35%|███▌      | 105/300 [01:07<02:00,  1.62it/s] 35%|███▌      | 106/300 [01:08<01:59,  1.62it/s] 36%|███▌      | 107/300 [01:08<02:00,  1.61it/s] 36%|███▌      | 108/300 [01:09<02:00,  1.60it/s] 36%|███▋      | 109/300 [01:10<02:00,  1.58it/s] 37%|███▋      | 110/300 [01:10<01:59,  1.60it/s] 37%|███▋      | 111/300 [01:11<01:59,  1.58it/s] 37%|███▋      | 112/300 [01:12<02:00,  1.56it/s] 38%|███▊      | 113/300 [01:12<01:59,  1.56it/s] 38%|███▊      | 114/300 [01:13<01:58,  1.57it/s] 38%|███▊      | 115/300 [01:13<01:56,  1.58it/s] 39%|███▊      | 116/300 [01:14<01:55,  1.59it/s] 39%|███▉      | 117/300 [01:15<01:55,  1.58it/s] 39%|███▉      | 118/300 [01:15<01:55,  1.57it/s] 40%|███▉      | 119/300 [01:16<01:54,  1.58it/s] 40%|████      | 120/300 [01:17<01:53,  1.59it/s] 40%|████      | 121/300 [01:17<01:53,  1.57it/s] 41%|████      | 122/300 [01:18<01:56,  1.52it/s] 41%|████      | 123/300 [01:19<01:55,  1.53it/s] 41%|████▏     | 124/300 [01:19<01:53,  1.55it/s] 42%|████▏     | 125/300 [01:20<01:52,  1.56it/s] 42%|████▏     | 126/300 [01:20<01:50,  1.57it/s] 42%|████▏     | 127/300 [01:21<01:49,  1.58it/s] 43%|████▎     | 128/300 [01:22<01:47,  1.60it/s] 43%|████▎     | 129/300 [01:22<01:46,  1.61it/s] 43%|████▎     | 130/300 [01:23<01:45,  1.61it/s] 44%|████▎     | 131/300 [01:24<01:45,  1.61it/s] 44%|████▍     | 132/300 [01:24<01:44,  1.60it/s] 44%|████▍     | 133/300 [01:25<01:44,  1.60it/s] 45%|████▍     | 134/300 [01:25<01:43,  1.60it/s] 45%|████▌     | 135/300 [01:26<01:43,  1.59it/s] 45%|████▌     | 136/300 [01:27<01:42,  1.60it/s] 46%|████▌     | 137/300 [01:27<01:43,  1.58it/s] 46%|████▌     | 138/300 [01:28<01:42,  1.58it/s] 46%|████▋     | 139/300 [01:29<01:42,  1.58it/s] 47%|████▋     | 140/300 [01:29<01:41,  1.57it/s] 47%|████▋     | 141/300 [01:30<01:39,  1.59it/s] 47%|████▋     | 142/300 [01:31<01:38,  1.60it/s] 48%|████▊     | 143/300 [01:31<01:37,  1.61it/s] 48%|████▊     | 144/300 [01:32<01:37,  1.60it/s] 48%|████▊     | 145/300 [01:32<01:37,  1.60it/s] 49%|████▊     | 146/300 [01:33<01:35,  1.61it/s] 49%|████▉     | 147/300 [01:34<01:35,  1.61it/s] 49%|████▉     | 148/300 [01:34<01:34,  1.62it/s] 50%|████▉     | 149/300 [01:35<01:33,  1.62it/s] 50%|█████     | 150/300 [01:35<01:32,  1.62it/s] 50%|█████     | 151/300 [01:36<01:32,  1.61it/s] 51%|█████     | 152/300 [01:37<01:31,  1.61it/s] 51%|█████     | 153/300 [01:37<01:32,  1.59it/s] 51%|█████▏    | 154/300 [01:38<01:31,  1.60it/s] 52%|█████▏    | 155/300 [01:39<01:30,  1.61it/s] 52%|█████▏    | 156/300 [01:39<01:29,  1.61it/s] 52%|█████▏    | 157/300 [01:40<01:28,  1.61it/s] 53%|█████▎    | 158/300 [01:40<01:27,  1.62it/s] 53%|█████▎    | 159/300 [01:41<01:26,  1.62it/s] 53%|█████▎    | 160/300 [01:42<01:26,  1.62it/s] 54%|█████▎    | 161/300 [01:42<01:26,  1.61it/s] 54%|█████▍    | 162/300 [01:43<01:25,  1.62it/s] 54%|█████▍    | 163/300 [01:44<01:24,  1.62it/s] 55%|█████▍    | 164/300 [01:44<01:23,  1.63it/s] 55%|█████▌    | 165/300 [01:45<01:22,  1.63it/s] 55%|█████▌    | 166/300 [01:45<01:22,  1.63it/s] 56%|█████▌    | 167/300 [01:46<01:21,  1.62it/s] 56%|█████▌    | 168/300 [01:47<01:21,  1.62it/s] 56%|█████▋    | 169/300 [01:47<01:20,  1.62it/s] 57%|█████▋    | 170/300 [01:48<01:19,  1.63it/s] 57%|█████▋    | 171/300 [01:48<01:19,  1.63it/s] 57%|█████▋    | 172/300 [01:49<01:18,  1.63it/s] 58%|█████▊    | 173/300 [01:50<01:18,  1.63it/s] 58%|█████▊    | 174/300 [01:50<01:18,  1.61it/s] 58%|█████▊    | 175/300 [01:51<01:17,  1.61it/s] 59%|█████▊    | 176/300 [01:52<01:16,  1.61it/s] 59%|█████▉    | 177/300 [01:52<01:17,  1.59it/s] 59%|█████▉    | 178/300 [01:53<01:16,  1.59it/s] 60%|█████▉    | 179/300 [01:53<01:16,  1.58it/s] 60%|██████    | 180/300 [01:54<01:15,  1.58it/s] 60%|██████    | 181/300 [01:55<01:14,  1.59it/s] 61%|██████    | 182/300 [01:55<01:13,  1.60it/s] 61%|██████    | 183/300 [01:56<01:13,  1.60it/s] 61%|██████▏   | 184/300 [01:57<01:12,  1.61it/s] 62%|██████▏   | 185/300 [01:57<01:12,  1.59it/s] 62%|██████▏   | 186/300 [01:58<01:11,  1.60it/s] 62%|██████▏   | 187/300 [01:58<01:11,  1.58it/s] 63%|██████▎   | 188/300 [01:59<01:11,  1.57it/s] 63%|██████▎   | 189/300 [02:00<01:10,  1.57it/s] 63%|██████▎   | 190/300 [02:00<01:10,  1.56it/s] 64%|██████▎   | 191/300 [02:01<01:09,  1.56it/s] 64%|██████▍   | 192/300 [02:02<01:09,  1.56it/s] 64%|██████▍   | 193/300 [02:02<01:08,  1.56it/s] 65%|██████▍   | 194/300 [02:03<01:07,  1.56it/s] 65%|██████▌   | 195/300 [02:04<01:07,  1.56it/s] 65%|██████▌   | 196/300 [02:04<01:06,  1.56it/s] 66%|██████▌   | 197/300 [02:05<01:06,  1.55it/s] 66%|██████▌   | 198/300 [02:06<01:06,  1.54it/s] 66%|██████▋   | 199/300 [02:06<01:05,  1.54it/s] 67%|██████▋   | 200/300 [02:07<01:04,  1.54it/s] 67%|██████▋   | 201/300 [02:07<01:03,  1.55it/s] 67%|██████▋   | 202/300 [02:08<01:03,  1.55it/s] 68%|██████▊   | 203/300 [02:09<01:02,  1.56it/s] 68%|██████▊   | 204/300 [02:09<01:01,  1.55it/s] 68%|██████▊   | 205/300 [02:10<01:01,  1.56it/s] 69%|██████▊   | 206/300 [02:11<01:00,  1.55it/s] 69%|██████▉   | 207/300 [02:11<00:59,  1.55it/s] 69%|██████▉   | 208/300 [02:12<00:59,  1.55it/s] 70%|██████▉   | 209/300 [02:13<00:58,  1.55it/s] 70%|███████   | 210/300 [02:13<00:57,  1.56it/s] 70%|███████   | 211/300 [02:14<00:57,  1.55it/s] 71%|███████   | 212/300 [02:15<00:56,  1.56it/s] 71%|███████   | 213/300 [02:15<00:55,  1.56it/s] 71%|███████▏  | 214/300 [02:16<00:55,  1.55it/s] 72%|███████▏  | 215/300 [02:16<00:54,  1.55it/s] 72%|███████▏  | 216/300 [02:17<00:54,  1.55it/s] 72%|███████▏  | 217/300 [02:18<00:53,  1.55it/s] 73%|███████▎  | 218/300 [02:18<00:52,  1.56it/s] 73%|███████▎  | 219/300 [02:19<00:52,  1.56it/s] 73%|███████▎  | 220/300 [02:20<00:51,  1.56it/s] 74%|███████▎  | 221/300 [02:20<00:50,  1.56it/s] 74%|███████▍  | 222/300 [02:21<00:49,  1.57it/s] 74%|███████▍  | 223/300 [02:22<00:48,  1.57it/s] 75%|███████▍  | 224/300 [02:22<00:48,  1.57it/s] 75%|███████▌  | 225/300 [02:23<00:47,  1.58it/s] 75%|███████▌  | 226/300 [02:24<00:47,  1.57it/s] 76%|███████▌  | 227/300 [02:24<00:46,  1.57it/s] 76%|███████▌  | 228/300 [02:25<00:45,  1.58it/s] 76%|███████▋  | 229/300 [02:25<00:45,  1.58it/s] 77%|███████▋  | 230/300 [02:26<00:44,  1.58it/s] 77%|███████▋  | 231/300 [02:27<00:43,  1.57it/s] 77%|███████▋  | 232/300 [02:27<00:43,  1.57it/s] 78%|███████▊  | 233/300 [02:28<00:42,  1.57it/s] 78%|███████▊  | 234/300 [02:29<00:42,  1.56it/s] 78%|███████▊  | 235/300 [02:29<00:41,  1.57it/s] 79%|███████▊  | 236/300 [02:30<00:40,  1.56it/s] 79%|███████▉  | 237/300 [02:31<00:40,  1.56it/s] 79%|███████▉  | 238/300 [02:31<00:39,  1.55it/s] 80%|███████▉  | 239/300 [02:32<00:39,  1.56it/s] 80%|████████  | 240/300 [02:32<00:38,  1.56it/s] 80%|████████  | 241/300 [02:33<00:37,  1.56it/s] 81%|████████  | 242/300 [02:34<00:37,  1.55it/s] 81%|████████  | 243/300 [02:34<00:36,  1.54it/s] 81%|████████▏ | 244/300 [02:35<00:36,  1.54it/s] 82%|████████▏ | 245/300 [02:36<00:35,  1.56it/s] 82%|████████▏ | 246/300 [02:36<00:34,  1.57it/s] 82%|████████▏ | 247/300 [02:37<00:33,  1.56it/s] 83%|████████▎ | 248/300 [02:38<00:33,  1.57it/s] 83%|████████▎ | 249/300 [02:38<00:32,  1.56it/s] 83%|████████▎ | 250/300 [02:39<00:31,  1.58it/s] 84%|████████▎ | 251/300 [02:39<00:31,  1.58it/s] 84%|████████▍ | 252/300 [02:40<00:30,  1.57it/s] 84%|████████▍ | 253/300 [02:41<00:29,  1.58it/s] 85%|████████▍ | 254/300 [02:41<00:28,  1.59it/s] 85%|████████▌ | 255/300 [02:42<00:28,  1.57it/s] 85%|████████▌ | 256/300 [02:43<00:28,  1.56it/s] 86%|████████▌ | 257/300 [02:43<00:27,  1.55it/s] 86%|████████▌ | 258/300 [02:44<00:27,  1.55it/s] 86%|████████▋ | 259/300 [02:45<00:26,  1.55it/s] 87%|████████▋ | 260/300 [02:45<00:25,  1.55it/s] 87%|████████▋ | 261/300 [02:46<00:25,  1.54it/s] 87%|████████▋ | 262/300 [02:47<00:24,  1.55it/s] 88%|████████▊ | 263/300 [02:47<00:23,  1.57it/s] 88%|████████▊ | 264/300 [02:48<00:22,  1.57it/s] 88%|████████▊ | 265/300 [02:48<00:22,  1.55it/s] 89%|████████▊ | 266/300 [02:49<00:21,  1.56it/s] 89%|████████▉ | 267/300 [02:50<00:21,  1.56it/s] 89%|████████▉ | 268/300 [02:50<00:20,  1.56it/s] 90%|████████▉ | 269/300 [02:51<00:19,  1.56it/s] 90%|█████████ | 270/300 [02:52<00:19,  1.55it/s] 90%|█████████ | 271/300 [02:52<00:18,  1.56it/s] 91%|█████████ | 272/300 [02:53<00:17,  1.56it/s] 91%|█████████ | 273/300 [02:54<00:17,  1.57it/s] 91%|█████████▏| 274/300 [02:54<00:16,  1.57it/s] 92%|█████████▏| 275/300 [02:55<00:15,  1.57it/s] 92%|█████████▏| 276/300 [02:56<00:15,  1.56it/s] 92%|█████████▏| 277/300 [02:56<00:14,  1.57it/s] 93%|█████████▎| 278/300 [02:57<00:13,  1.57it/s] 93%|█████████▎| 279/300 [02:57<00:13,  1.57it/s] 93%|█████████▎| 280/300 [02:58<00:12,  1.56it/s] 94%|█████████▎| 281/300 [02:59<00:12,  1.58it/s] 94%|█████████▍| 282/300 [02:59<00:11,  1.58it/s] 94%|█████████▍| 283/300 [03:00<00:10,  1.58it/s] 95%|█████████▍| 284/300 [03:01<00:10,  1.57it/s] 95%|█████████▌| 285/300 [03:01<00:09,  1.59it/s] 95%|█████████▌| 286/300 [03:02<00:08,  1.58it/s] 96%|█████████▌| 287/300 [03:02<00:08,  1.59it/s] 96%|█████████▌| 288/300 [03:03<00:07,  1.59it/s] 96%|█████████▋| 289/300 [03:04<00:06,  1.58it/s] 97%|█████████▋| 290/300 [03:04<00:06,  1.58it/s] 97%|█████████▋| 291/300 [03:05<00:05,  1.58it/s] 97%|█████████▋| 292/300 [03:06<00:05,  1.58it/s] 98%|█████████▊| 293/300 [03:06<00:04,  1.58it/s] 98%|█████████▊| 294/300 [03:07<00:03,  1.57it/s] 98%|█████████▊| 295/300 [03:08<00:03,  1.56it/s] 99%|█████████▊| 296/300 [03:08<00:02,  1.56it/s] 99%|█████████▉| 297/300 [03:09<00:01,  1.57it/s] 99%|█████████▉| 298/300 [03:09<00:01,  1.57it/s]100%|█████████▉| 299/300 [03:10<00:00,  1.57it/s]100%|██████████| 300/300 [03:11<00:00,  1.57it/s]100%|██████████| 300/300 [03:11<00:00,  1.57it/s]
W&B disabled.
W&B online. Running your script from this directory will now sync to the cloud.
wandb: Currently logged in as: hl57. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /media/techt/One Touch/DD/SRe2L/train/wandb/run-20231015_202032-wnlzu5r4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-glitter-411
wandb: ⭐️ View project at https://wandb.ai/hl57/final_rn18_fkd
wandb: 🚀 View run at https://wandb.ai/hl57/final_rn18_fkd/runs/wnlzu5r4
======= FKD: dataset info ======
path: ../relabel/FKD_cutmix_fp16/imagenette/245/
num img: 100
batch size: 100
max epoch: 300
================================
load data successfully
=> loading student model 'resnet18'

Epoch: 0
TRAIN Iter 0: lr = 0.001000,	loss = 0.000180,	Top-1 err = 90.000000,	Top-5 err = 52.000000,	train_time = 3.457898
TEST Iter 0: loss = 6.648474,	Top-1 err = 90.089172,	Top-5 err = 49.732484,	val_time = 13.173941

Epoch: 1

Epoch: 2

Epoch: 3

Epoch: 4

Epoch: 5

Epoch: 6

Epoch: 7

Epoch: 8

Epoch: 9

Epoch: 10
TRAIN Iter 10: lr = 0.000997,	loss = 0.000139,	Top-1 err = 64.000000,	Top-5 err = 14.000000,	train_time = 2.266000
TEST Iter 10: loss = 6.278835,	Top-1 err = 85.095541,	Top-5 err = 41.961783,	val_time = 12.854889

Epoch: 11

Epoch: 12

Epoch: 13

Epoch: 14

Epoch: 15

Epoch: 16

Epoch: 17

Epoch: 18

Epoch: 19

Epoch: 20
TRAIN Iter 20: lr = 0.000989,	loss = 0.000080,	Top-1 err = 57.000000,	Top-5 err = 9.000000,	train_time = 2.248410
TEST Iter 20: loss = 7.278447,	Top-1 err = 80.917197,	Top-5 err = 34.114650,	val_time = 12.881458

Epoch: 21

Epoch: 22

Epoch: 23

Epoch: 24

Epoch: 25

Epoch: 26

Epoch: 27

Epoch: 28

Epoch: 29

Epoch: 30
TRAIN Iter 30: lr = 0.000976,	loss = 0.000069,	Top-1 err = 53.000000,	Top-5 err = 6.000000,	train_time = 2.224462
TEST Iter 30: loss = 10.189068,	Top-1 err = 71.668790,	Top-5 err = 29.197452,	val_time = 12.901354

Epoch: 31

Epoch: 32

Epoch: 33

Epoch: 34

Epoch: 35

Epoch: 36

Epoch: 37

Epoch: 38

Epoch: 39

Epoch: 40
TRAIN Iter 40: lr = 0.000957,	loss = 0.000060,	Top-1 err = 40.000000,	Top-5 err = 7.000000,	train_time = 2.328403
TEST Iter 40: loss = 11.629839,	Top-1 err = 69.579618,	Top-5 err = 32.458599,	val_time = 12.910723

Epoch: 41

Epoch: 42

Epoch: 43

Epoch: 44

Epoch: 45

Epoch: 46

Epoch: 47

Epoch: 48

Epoch: 49

Epoch: 50
TRAIN Iter 50: lr = 0.000933,	loss = 0.000058,	Top-1 err = 70.000000,	Top-5 err = 9.000000,	train_time = 2.272702
TEST Iter 50: loss = 4.614417,	Top-1 err = 69.554140,	Top-5 err = 23.847134,	val_time = 12.856186

Epoch: 51

Epoch: 52

Epoch: 53

Epoch: 54

Epoch: 55

Epoch: 56

Epoch: 57

Epoch: 58

Epoch: 59

Epoch: 60
TRAIN Iter 60: lr = 0.000905,	loss = 0.000051,	Top-1 err = 61.000000,	Top-5 err = 7.000000,	train_time = 2.254119
TEST Iter 60: loss = 6.508882,	Top-1 err = 68.458599,	Top-5 err = 22.318471,	val_time = 13.129018

Epoch: 61

Epoch: 62

Epoch: 63

Epoch: 64

Epoch: 65

Epoch: 66

Epoch: 67

Epoch: 68

Epoch: 69

Epoch: 70
TRAIN Iter 70: lr = 0.000872,	loss = 0.000048,	Top-1 err = 64.000000,	Top-5 err = 7.000000,	train_time = 2.247913
TEST Iter 70: loss = 7.496473,	Top-1 err = 69.987261,	Top-5 err = 19.872611,	val_time = 12.799352

Epoch: 71

Epoch: 72

Epoch: 73

Epoch: 74

Epoch: 75

Epoch: 76

Epoch: 77

Epoch: 78

Epoch: 79

Epoch: 80
TRAIN Iter 80: lr = 0.000835,	loss = 0.000045,	Top-1 err = 84.000000,	Top-5 err = 25.000000,	train_time = 2.293948
TEST Iter 80: loss = 4.054166,	Top-1 err = 58.394904,	Top-5 err = 15.923567,	val_time = 12.801544

Epoch: 81

Epoch: 82

Epoch: 83

Epoch: 84

Epoch: 85

Epoch: 86

Epoch: 87

Epoch: 88

Epoch: 89

Epoch: 90
TRAIN Iter 90: lr = 0.000794,	loss = 0.000033,	Top-1 err = 78.000000,	Top-5 err = 10.000000,	train_time = 2.303802
TEST Iter 90: loss = 5.462578,	Top-1 err = 63.592357,	Top-5 err = 20.178344,	val_time = 12.915729

Epoch: 91

Epoch: 92

Epoch: 93

Epoch: 94

Epoch: 95

Epoch: 96

Epoch: 97

Epoch: 98

Epoch: 99

Epoch: 100
TRAIN Iter 100: lr = 0.000750,	loss = 0.000031,	Top-1 err = 30.000000,	Top-5 err = 2.000000,	train_time = 2.260848
TEST Iter 100: loss = 2.998699,	Top-1 err = 57.554140,	Top-5 err = 16.407643,	val_time = 12.896324

Epoch: 101

Epoch: 102

Epoch: 103

Epoch: 104

Epoch: 105

Epoch: 106

Epoch: 107

Epoch: 108

Epoch: 109

Epoch: 110
TRAIN Iter 110: lr = 0.000703,	loss = 0.000028,	Top-1 err = 90.000000,	Top-5 err = 21.000000,	train_time = 2.262931
TEST Iter 110: loss = 3.094237,	Top-1 err = 55.592357,	Top-5 err = 15.286624,	val_time = 12.807217

Epoch: 111

Epoch: 112

Epoch: 113

Epoch: 114

Epoch: 115

Epoch: 116

Epoch: 117

Epoch: 118

Epoch: 119

Epoch: 120
TRAIN Iter 120: lr = 0.000655,	loss = 0.000032,	Top-1 err = 34.000000,	Top-5 err = 0.000000,	train_time = 2.312191
TEST Iter 120: loss = 2.673867,	Top-1 err = 51.210191,	Top-5 err = 13.350318,	val_time = 12.757957

Epoch: 121

Epoch: 122

Epoch: 123

Epoch: 124

Epoch: 125

Epoch: 126

Epoch: 127

Epoch: 128

Epoch: 129

Epoch: 130
TRAIN Iter 130: lr = 0.000604,	loss = 0.000029,	Top-1 err = 5.000000,	Top-5 err = 0.000000,	train_time = 2.480877
TEST Iter 130: loss = 2.737344,	Top-1 err = 49.681529,	Top-5 err = 12.484076,	val_time = 13.466969

Epoch: 131

Epoch: 132

Epoch: 133

Epoch: 134

Epoch: 135

Epoch: 136

Epoch: 137

Epoch: 138

Epoch: 139

Epoch: 140
TRAIN Iter 140: lr = 0.000552,	loss = 0.000028,	Top-1 err = 4.000000,	Top-5 err = 0.000000,	train_time = 2.316565
TEST Iter 140: loss = 3.062573,	Top-1 err = 54.445860,	Top-5 err = 13.452229,	val_time = 12.877748

Epoch: 141

Epoch: 142

Epoch: 143

Epoch: 144

Epoch: 145

Epoch: 146

Epoch: 147

Epoch: 148

Epoch: 149

Epoch: 150
TRAIN Iter 150: lr = 0.000500,	loss = 0.000034,	Top-1 err = 57.000000,	Top-5 err = 4.000000,	train_time = 2.320514
TEST Iter 150: loss = 3.035437,	Top-1 err = 52.968153,	Top-5 err = 12.687898,	val_time = 12.898133

Epoch: 151

Epoch: 152

Epoch: 153

Epoch: 154

Epoch: 155

Epoch: 156

Epoch: 157

Epoch: 158

Epoch: 159

Epoch: 160
TRAIN Iter 160: lr = 0.000448,	loss = 0.000027,	Top-1 err = 10.000000,	Top-5 err = 0.000000,	train_time = 2.380812
TEST Iter 160: loss = 3.148342,	Top-1 err = 54.929936,	Top-5 err = 13.324841,	val_time = 12.879191

Epoch: 161

Epoch: 162

Epoch: 163

Epoch: 164

Epoch: 165

Epoch: 166

Epoch: 167

Epoch: 168

Epoch: 169

Epoch: 170
TRAIN Iter 170: lr = 0.000396,	loss = 0.000025,	Top-1 err = 5.000000,	Top-5 err = 0.000000,	train_time = 2.385722
TEST Iter 170: loss = 2.578633,	Top-1 err = 48.127389,	Top-5 err = 11.235669,	val_time = 12.782984

Epoch: 171

Epoch: 172

Epoch: 173

Epoch: 174

Epoch: 175

Epoch: 176

Epoch: 177

Epoch: 178

Epoch: 179

Epoch: 180
TRAIN Iter 180: lr = 0.000345,	loss = 0.000024,	Top-1 err = 9.000000,	Top-5 err = 0.000000,	train_time = 2.290841
TEST Iter 180: loss = 2.730161,	Top-1 err = 49.477707,	Top-5 err = 10.598726,	val_time = 13.351691

Epoch: 181

Epoch: 182

Epoch: 183

Epoch: 184

Epoch: 185

Epoch: 186

Epoch: 187

Epoch: 188

Epoch: 189

Epoch: 190
TRAIN Iter 190: lr = 0.000297,	loss = 0.000023,	Top-1 err = 4.000000,	Top-5 err = 0.000000,	train_time = 2.617002
TEST Iter 190: loss = 3.128326,	Top-1 err = 53.910828,	Top-5 err = 10.828025,	val_time = 13.033367

Epoch: 191

Epoch: 192

Epoch: 193

Epoch: 194

Epoch: 195

Epoch: 196

Epoch: 197

Epoch: 198

Epoch: 199

Epoch: 200
TRAIN Iter 200: lr = 0.000250,	loss = 0.000029,	Top-1 err = 37.000000,	Top-5 err = 1.000000,	train_time = 2.280900
TEST Iter 200: loss = 2.567905,	Top-1 err = 48.407643,	Top-5 err = 10.394904,	val_time = 13.013943

Epoch: 201

Epoch: 202

Epoch: 203

Epoch: 204

Epoch: 205

Epoch: 206

Epoch: 207

Epoch: 208

Epoch: 209

Epoch: 210
TRAIN Iter 210: lr = 0.000206,	loss = 0.000021,	Top-1 err = 47.000000,	Top-5 err = 6.000000,	train_time = 2.230921
TEST Iter 210: loss = 2.531475,	Top-1 err = 49.732484,	Top-5 err = 11.388535,	val_time = 13.139196

Epoch: 211

Epoch: 212

Epoch: 213

Epoch: 214

Epoch: 215

Epoch: 216

Epoch: 217

Epoch: 218

Epoch: 219

Epoch: 220
TRAIN Iter 220: lr = 0.000165,	loss = 0.000024,	Top-1 err = 85.000000,	Top-5 err = 22.000000,	train_time = 2.362917
TEST Iter 220: loss = 2.214268,	Top-1 err = 47.184713,	Top-5 err = 10.369427,	val_time = 13.067150

Epoch: 221

Epoch: 222

Epoch: 223

Epoch: 224

Epoch: 225

Epoch: 226

Epoch: 227

Epoch: 228

Epoch: 229

Epoch: 230
TRAIN Iter 230: lr = 0.000128,	loss = 0.000021,	Top-1 err = 79.000000,	Top-5 err = 6.000000,	train_time = 2.346819
TEST Iter 230: loss = 2.290587,	Top-1 err = 45.579618,	Top-5 err = 9.401274,	val_time = 12.860573

Epoch: 231

Epoch: 232

Epoch: 233

Epoch: 234

Epoch: 235

Epoch: 236

Epoch: 237

Epoch: 238

Epoch: 239

Epoch: 240
TRAIN Iter 240: lr = 0.000095,	loss = 0.000022,	Top-1 err = 6.000000,	Top-5 err = 0.000000,	train_time = 2.417032
TEST Iter 240: loss = 2.137918,	Top-1 err = 44.611465,	Top-5 err = 9.197452,	val_time = 13.516036

Epoch: 241

Epoch: 242

Epoch: 243

Epoch: 244

Epoch: 245

Epoch: 246

Epoch: 247

Epoch: 248

Epoch: 249

Epoch: 250
TRAIN Iter 250: lr = 0.000067,	loss = 0.000020,	Top-1 err = 90.000000,	Top-5 err = 24.000000,	train_time = 2.245825
TEST Iter 250: loss = 2.292836,	Top-1 err = 45.554140,	Top-5 err = 9.299363,	val_time = 12.948209

Epoch: 251

Epoch: 252

Epoch: 253

Epoch: 254

Epoch: 255

Epoch: 256

Epoch: 257

Epoch: 258

Epoch: 259

Epoch: 260
TRAIN Iter 260: lr = 0.000043,	loss = 0.000018,	Top-1 err = 91.000000,	Top-5 err = 35.000000,	train_time = 2.337025
TEST Iter 260: loss = 2.275743,	Top-1 err = 45.579618,	Top-5 err = 9.579618,	val_time = 12.993665

Epoch: 261

Epoch: 262

Epoch: 263

Epoch: 264

Epoch: 265

Epoch: 266

Epoch: 267

Epoch: 268

Epoch: 269

Epoch: 270
TRAIN Iter 270: lr = 0.000024,	loss = 0.000023,	Top-1 err = 4.000000,	Top-5 err = 0.000000,	train_time = 2.288491
TEST Iter 270: loss = 2.274661,	Top-1 err = 45.401274,	Top-5 err = 9.707006,	val_time = 12.844781

Epoch: 271

Epoch: 272

Epoch: 273

Epoch: 274

Epoch: 275

Epoch: 276

Epoch: 277

Epoch: 278

Epoch: 279

Epoch: 280
TRAIN Iter 280: lr = 0.000011,	loss = 0.000026,	Top-1 err = 26.000000,	Top-5 err = 3.000000,	train_time = 2.315514
TEST Iter 280: loss = 2.290883,	Top-1 err = 45.350318,	Top-5 err = 9.528662,	val_time = 13.158472

Epoch: 281

Epoch: 282

Epoch: 283

Epoch: 284

Epoch: 285

Epoch: 286

Epoch: 287

Epoch: 288

Epoch: 289

Epoch: 290
TRAIN Iter 290: lr = 0.000003,	loss = 0.000017,	Top-1 err = 12.000000,	Top-5 err = 2.000000,	train_time = 2.281242
TEST Iter 290: loss = 2.282894,	Top-1 err = 45.171975,	Top-5 err = 9.248408,	val_time = 12.809925

Epoch: 291

Epoch: 292

Epoch: 293

Epoch: 294

Epoch: 295

Epoch: 296

Epoch: 297

Epoch: 298

Epoch: 299
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  train/Top1 ▂▃▅▄▆▂▅▇▃▃▇▇▇▃▅▅▆▇█▇▂▇▅▆▁▄▆▄█▂▆█▅▇▇▅▇▃▇▁
wandb:  train/Top5 ▂▃▇▆▇▁██▆▆███▆▇█████▇███▁██▇█▁███████▇█▃
wandb: train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  train/loss █▅▅▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    train/lr ███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:   val/epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███
wandb:    val/loss ▄▄▅▇█▃▄▅▂▃▂▂▁▁▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁
wandb:    val/top1 ▁▂▂▄▄▄▄▄▆▅▆▆▇▇▆▇▆▇▇▇▇▇█████████
wandb:    val/top5 ▁▂▄▅▄▅▆▆▇▆▇▇▇▇▇▇▇██████████████
wandb: 
wandb: Run summary:
wandb:  train/Top1 8.0
wandb:  train/Top5 75.0
wandb: train/epoch 299
wandb:  train/loss 2e-05
wandb:    train/lr 0.0
wandb:   val/epoch 299
wandb:    val/loss 2.26481
wandb:    val/top1 54.77707
wandb:    val/top5 90.6242
wandb: 
wandb: 🚀 View run autumn-glitter-411 at: https://wandb.ai/hl57/final_rn18_fkd/runs/wnlzu5r4
wandb: ️⚡ View job at https://wandb.ai/hl57/final_rn18_fkd/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjk3MzkyNjU3/version_details/v39
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231015_202032-wnlzu5r4/logs
TEST Iter 299: loss = 2.264805,	Top-1 err = 45.222930,	Top-5 err = 9.375796,	val_time = 12.901903
