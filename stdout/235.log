/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
r_bn:  0.01
lr:  0.25
bc shape torch.Size([10, 10, 512])
get_images call
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
per-class-batchnorm:  True
------------iteration 0----------
total loss 117.30012363222379
main criterion 92.9682850244357
weighted_aux_loss 24.331838607788086
loss_r_bn_feature 2433.183837890625
Verifier accuracy:  0.0
------------iteration 100----------
total loss 60.63716204512257
main criterion 42.82389910566945
weighted_aux_loss 17.813262939453125
loss_r_bn_feature 1781.3262939453125
Verifier accuracy:  0.0
------------iteration 200----------
total loss 72.73668745194115
main criterion 56.68072393570579
weighted_aux_loss 16.05596351623535
loss_r_bn_feature 1605.5963134765625
Verifier accuracy:  0.0
------------iteration 300----------
total loss 83.9015777170231
main criterion 69.31038642521402
weighted_aux_loss 14.591191291809082
loss_r_bn_feature 1459.119140625
Verifier accuracy:  0.0
------------iteration 400----------
total loss 45.60841884838803
main criterion 30.944189455382656
weighted_aux_loss 14.664229393005371
loss_r_bn_feature 1466.4229736328125
Verifier accuracy:  0.0
------------iteration 500----------
total loss 45.25714728310312
main criterion 30.99988696053232
weighted_aux_loss 14.2572603225708
loss_r_bn_feature 1425.72607421875
Verifier accuracy:  0.0
------------iteration 600----------
total loss 43.829030295869494
main criterion 30.51298834945836
weighted_aux_loss 13.316041946411133
loss_r_bn_feature 1331.604248046875
Verifier accuracy:  0.0
------------iteration 700----------
total loss 43.04884358616705
main criterion 30.49401208134528
weighted_aux_loss 12.554831504821777
loss_r_bn_feature 1255.483154296875
Verifier accuracy:  0.0
------------iteration 800----------
total loss 45.11485351235538
main criterion 32.60536445290714
weighted_aux_loss 12.509489059448242
loss_r_bn_feature 1250.948974609375
Verifier accuracy:  0.0
------------iteration 900----------
total loss 34.20340701214088
main criterion 23.52411242595924
weighted_aux_loss 10.67929458618164
loss_r_bn_feature 1067.929443359375
Verifier accuracy:  0.0
------------iteration 1000----------
total loss 34.51480940945231
main criterion 24.110451499296065
weighted_aux_loss 10.40435791015625
loss_r_bn_feature 1040.435791015625
Verifier accuracy:  0.0
------------iteration 1100----------
total loss 31.97092825344114
main criterion 23.127927841453836
weighted_aux_loss 8.843000411987305
loss_r_bn_feature 884.300048828125
Verifier accuracy:  0.0
------------iteration 1200----------
total loss 32.61695664077115
main criterion 24.322010923913236
weighted_aux_loss 8.29494571685791
loss_r_bn_feature 829.4945678710938
Verifier accuracy:  0.0
------------iteration 1300----------
total loss 28.558267969856168
main criterion 21.667211432227994
weighted_aux_loss 6.891056537628174
loss_r_bn_feature 689.1056518554688
Verifier accuracy:  0.0
------------iteration 1400----------
total loss 52.582686972752626
main criterion 45.96081216348749
weighted_aux_loss 6.621874809265137
loss_r_bn_feature 662.1875
Verifier accuracy:  0.0
------------iteration 1500----------
total loss 25.839679225794605
main criterion 20.145521148554614
weighted_aux_loss 5.69415807723999
loss_r_bn_feature 569.4158325195312
Verifier accuracy:  0.0
------------iteration 1600----------
total loss 26.71161007340912
main criterion 21.8594477122641
weighted_aux_loss 4.8521623611450195
loss_r_bn_feature 485.21624755859375
Verifier accuracy:  0.0
------------iteration 1700----------
total loss 22.50245932251468
main criterion 17.173999582829623
weighted_aux_loss 5.328459739685059
loss_r_bn_feature 532.8460083007812
Verifier accuracy:  0.0
------------iteration 1800----------
total loss 19.272771679569846
main criterion 14.326726757694846
weighted_aux_loss 4.946044921875
loss_r_bn_feature 494.6044921875
Verifier accuracy:  0.0
------------iteration 1900----------
total loss 22.70890415123218
main criterion 18.080625895769533
weighted_aux_loss 4.6282782554626465
loss_r_bn_feature 462.8278503417969
Verifier accuracy:  0.0
=> using pytorch pre-trained model 'resnet18'
process data from ../recover/syn_data/imagenette/235
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 1/300 [00:01<08:09,  1.64s/it]  1%|          | 2/300 [00:02<04:50,  1.03it/s]  1%|          | 3/300 [00:02<03:45,  1.32it/s]  1%|▏         | 4/300 [00:03<03:15,  1.52it/s]  2%|▏         | 5/300 [00:03<02:58,  1.66it/s]  2%|▏         | 6/300 [00:04<02:46,  1.77it/s]  2%|▏         | 7/300 [00:04<02:41,  1.82it/s]  3%|▎         | 8/300 [00:05<02:36,  1.86it/s]  3%|▎         | 9/300 [00:05<02:33,  1.90it/s]  3%|▎         | 10/300 [00:06<02:31,  1.92it/s]  4%|▎         | 11/300 [00:06<02:28,  1.94it/s]  4%|▍         | 12/300 [00:07<02:28,  1.94it/s]  4%|▍         | 13/300 [00:07<02:26,  1.96it/s]  5%|▍         | 14/300 [00:08<02:26,  1.95it/s]  5%|▌         | 15/300 [00:08<02:25,  1.96it/s]  5%|▌         | 16/300 [00:09<02:25,  1.96it/s]  6%|▌         | 17/300 [00:09<02:24,  1.96it/s]  6%|▌         | 18/300 [00:10<02:23,  1.96it/s]  6%|▋         | 19/300 [00:10<02:23,  1.96it/s]  7%|▋         | 20/300 [00:11<02:22,  1.97it/s]  7%|▋         | 21/300 [00:11<02:21,  1.97it/s]  7%|▋         | 22/300 [00:12<02:22,  1.96it/s]  8%|▊         | 23/300 [00:12<02:20,  1.98it/s]  8%|▊         | 24/300 [00:13<02:19,  1.97it/s]  8%|▊         | 25/300 [00:13<02:19,  1.97it/s]  9%|▊         | 26/300 [00:14<02:17,  1.99it/s]  9%|▉         | 27/300 [00:14<02:17,  1.98it/s]  9%|▉         | 28/300 [00:15<02:17,  1.98it/s] 10%|▉         | 29/300 [00:15<02:16,  1.98it/s] 10%|█         | 30/300 [00:16<02:14,  2.00it/s] 10%|█         | 31/300 [00:16<02:12,  2.03it/s] 11%|█         | 32/300 [00:17<02:13,  2.00it/s] 11%|█         | 33/300 [00:17<02:12,  2.02it/s] 11%|█▏        | 34/300 [00:18<02:13,  1.99it/s] 12%|█▏        | 35/300 [00:18<02:12,  2.00it/s] 12%|█▏        | 36/300 [00:19<02:12,  1.99it/s] 12%|█▏        | 37/300 [00:19<02:13,  1.98it/s] 13%|█▎        | 38/300 [00:20<02:12,  1.97it/s] 13%|█▎        | 39/300 [00:20<02:11,  1.98it/s] 13%|█▎        | 40/300 [00:21<02:11,  1.98it/s] 14%|█▎        | 41/300 [00:21<02:10,  1.98it/s] 14%|█▍        | 42/300 [00:22<02:10,  1.97it/s] 14%|█▍        | 43/300 [00:22<02:15,  1.89it/s] 15%|█▍        | 44/300 [00:23<02:25,  1.76it/s] 15%|█▌        | 45/300 [00:24<02:23,  1.77it/s] 15%|█▌        | 46/300 [00:24<02:19,  1.82it/s] 16%|█▌        | 47/300 [00:25<02:20,  1.80it/s] 16%|█▌        | 48/300 [00:25<02:21,  1.78it/s] 16%|█▋        | 49/300 [00:26<02:19,  1.80it/s] 17%|█▋        | 50/300 [00:26<02:17,  1.82it/s] 17%|█▋        | 51/300 [00:27<02:19,  1.79it/s] 17%|█▋        | 52/300 [00:27<02:15,  1.84it/s] 18%|█▊        | 53/300 [00:28<02:13,  1.85it/s] 18%|█▊        | 54/300 [00:29<02:12,  1.85it/s] 18%|█▊        | 55/300 [00:29<02:12,  1.86it/s] 19%|█▊        | 56/300 [00:30<02:10,  1.88it/s] 19%|█▉        | 57/300 [00:30<02:07,  1.91it/s] 19%|█▉        | 58/300 [00:31<02:05,  1.93it/s] 20%|█▉        | 59/300 [00:31<02:03,  1.96it/s] 20%|██        | 60/300 [00:32<02:01,  1.97it/s] 20%|██        | 61/300 [00:32<02:01,  1.96it/s] 21%|██        | 62/300 [00:33<01:59,  1.99it/s] 21%|██        | 63/300 [00:33<01:59,  1.98it/s] 21%|██▏       | 64/300 [00:34<01:59,  1.98it/s] 22%|██▏       | 65/300 [00:34<01:58,  1.98it/s] 22%|██▏       | 66/300 [00:35<01:59,  1.96it/s] 22%|██▏       | 67/300 [00:35<01:58,  1.96it/s] 23%|██▎       | 68/300 [00:36<01:58,  1.96it/s] 23%|██▎       | 69/300 [00:36<01:56,  1.99it/s] 23%|██▎       | 70/300 [00:37<01:57,  1.96it/s] 24%|██▎       | 71/300 [00:37<01:57,  1.95it/s] 24%|██▍       | 72/300 [00:38<01:56,  1.95it/s] 24%|██▍       | 73/300 [00:38<01:55,  1.97it/s] 25%|██▍       | 74/300 [00:39<01:56,  1.94it/s] 25%|██▌       | 75/300 [00:39<02:09,  1.74it/s] 25%|██▌       | 76/300 [00:40<02:05,  1.78it/s] 26%|██▌       | 77/300 [00:41<02:02,  1.83it/s] 26%|██▌       | 78/300 [00:41<02:01,  1.82it/s] 26%|██▋       | 79/300 [00:42<02:00,  1.84it/s] 27%|██▋       | 80/300 [00:42<01:59,  1.84it/s] 27%|██▋       | 81/300 [00:43<02:01,  1.80it/s] 27%|██▋       | 82/300 [00:43<02:03,  1.76it/s] 28%|██▊       | 83/300 [00:44<01:59,  1.81it/s] 28%|██▊       | 84/300 [00:44<01:57,  1.84it/s] 28%|██▊       | 85/300 [00:45<01:55,  1.86it/s] 29%|██▊       | 86/300 [00:45<01:54,  1.87it/s] 29%|██▉       | 87/300 [00:46<01:52,  1.90it/s] 29%|██▉       | 88/300 [00:46<01:50,  1.92it/s] 30%|██▉       | 89/300 [00:47<01:48,  1.94it/s] 30%|███       | 90/300 [00:47<01:47,  1.95it/s] 30%|███       | 91/300 [00:48<01:47,  1.94it/s] 31%|███       | 92/300 [00:48<01:45,  1.98it/s] 31%|███       | 93/300 [00:49<01:45,  1.97it/s] 31%|███▏      | 94/300 [00:49<01:44,  1.96it/s] 32%|███▏      | 95/300 [00:50<01:44,  1.95it/s] 32%|███▏      | 96/300 [00:50<01:42,  1.98it/s] 32%|███▏      | 97/300 [00:51<01:41,  1.99it/s] 33%|███▎      | 98/300 [00:51<01:41,  2.00it/s] 33%|███▎      | 99/300 [00:52<01:40,  2.00it/s] 33%|███▎      | 100/300 [00:52<01:40,  2.00it/s] 34%|███▎      | 101/300 [00:53<01:39,  2.00it/s] 34%|███▍      | 102/300 [00:53<01:38,  2.00it/s] 34%|███▍      | 103/300 [00:54<01:38,  2.00it/s] 35%|███▍      | 104/300 [00:54<01:37,  2.02it/s] 35%|███▌      | 105/300 [00:55<01:37,  1.99it/s] 35%|███▌      | 106/300 [00:55<01:36,  2.01it/s] 36%|███▌      | 107/300 [00:56<01:36,  2.01it/s] 36%|███▌      | 108/300 [00:56<01:36,  2.00it/s] 36%|███▋      | 109/300 [00:57<01:35,  2.00it/s] 37%|███▋      | 110/300 [00:57<01:33,  2.02it/s] 37%|███▋      | 111/300 [00:58<01:33,  2.02it/s] 37%|███▋      | 112/300 [00:58<01:33,  2.02it/s] 38%|███▊      | 113/300 [00:59<01:32,  2.02it/s] 38%|███▊      | 114/300 [00:59<01:31,  2.03it/s] 38%|███▊      | 115/300 [01:00<01:31,  2.03it/s] 39%|███▊      | 116/300 [01:00<01:30,  2.03it/s] 39%|███▉      | 117/300 [01:01<01:29,  2.05it/s] 39%|███▉      | 118/300 [01:01<01:29,  2.04it/s] 40%|███▉      | 119/300 [01:02<01:29,  2.03it/s] 40%|████      | 120/300 [01:02<01:28,  2.03it/s] 40%|████      | 121/300 [01:03<01:28,  2.03it/s] 41%|████      | 122/300 [01:03<01:27,  2.03it/s] 41%|████      | 123/300 [01:04<01:27,  2.01it/s] 41%|████▏     | 124/300 [01:04<01:27,  2.01it/s] 42%|████▏     | 125/300 [01:05<01:27,  2.01it/s] 42%|████▏     | 126/300 [01:05<01:27,  1.99it/s] 42%|████▏     | 127/300 [01:06<01:27,  1.98it/s] 43%|████▎     | 128/300 [01:06<01:27,  1.96it/s] 43%|████▎     | 129/300 [01:07<01:27,  1.96it/s] 43%|████▎     | 130/300 [01:07<01:27,  1.95it/s] 44%|████▎     | 131/300 [01:08<01:27,  1.93it/s] 44%|████▍     | 132/300 [01:08<01:27,  1.93it/s] 44%|████▍     | 133/300 [01:09<01:26,  1.93it/s] 45%|████▍     | 134/300 [01:10<01:26,  1.92it/s] 45%|████▌     | 135/300 [01:10<01:25,  1.93it/s] 45%|████▌     | 136/300 [01:11<01:25,  1.92it/s] 46%|████▌     | 137/300 [01:11<01:24,  1.92it/s] 46%|████▌     | 138/300 [01:12<01:23,  1.93it/s] 46%|████▋     | 139/300 [01:12<01:22,  1.95it/s] 47%|████▋     | 140/300 [01:13<01:23,  1.92it/s] 47%|████▋     | 141/300 [01:13<01:23,  1.90it/s] 47%|████▋     | 142/300 [01:14<01:22,  1.92it/s] 48%|████▊     | 143/300 [01:14<01:21,  1.93it/s] 48%|████▊     | 144/300 [01:15<01:20,  1.93it/s] 48%|████▊     | 145/300 [01:15<01:19,  1.94it/s] 49%|████▊     | 146/300 [01:16<01:19,  1.93it/s] 49%|████▉     | 147/300 [01:16<01:18,  1.94it/s] 49%|████▉     | 148/300 [01:17<01:17,  1.95it/s] 50%|████▉     | 149/300 [01:17<01:16,  1.96it/s] 50%|█████     | 150/300 [01:18<01:16,  1.96it/s] 50%|█████     | 151/300 [01:18<01:16,  1.96it/s] 51%|█████     | 152/300 [01:19<01:15,  1.97it/s] 51%|█████     | 153/300 [01:19<01:14,  1.98it/s] 51%|█████▏    | 154/300 [01:20<01:13,  1.98it/s] 52%|█████▏    | 155/300 [01:20<01:12,  2.00it/s] 52%|█████▏    | 156/300 [01:21<01:12,  1.99it/s] 52%|█████▏    | 157/300 [01:21<01:11,  1.99it/s] 53%|█████▎    | 158/300 [01:22<01:11,  1.98it/s] 53%|█████▎    | 159/300 [01:22<01:11,  1.98it/s] 53%|█████▎    | 160/300 [01:23<01:10,  1.98it/s] 54%|█████▎    | 161/300 [01:23<01:10,  1.97it/s] 54%|█████▍    | 162/300 [01:24<01:10,  1.96it/s] 54%|█████▍    | 163/300 [01:24<01:10,  1.95it/s] 55%|█████▍    | 164/300 [01:25<01:09,  1.95it/s] 55%|█████▌    | 165/300 [01:25<01:09,  1.93it/s] 55%|█████▌    | 166/300 [01:26<01:09,  1.92it/s] 56%|█████▌    | 167/300 [01:26<01:08,  1.93it/s] 56%|█████▌    | 168/300 [01:27<01:07,  1.94it/s] 56%|█████▋    | 169/300 [01:27<01:07,  1.94it/s] 57%|█████▋    | 170/300 [01:28<01:06,  1.95it/s] 57%|█████▋    | 171/300 [01:28<01:06,  1.95it/s] 57%|█████▋    | 172/300 [01:29<01:05,  1.94it/s] 58%|█████▊    | 173/300 [01:30<01:05,  1.93it/s] 58%|█████▊    | 174/300 [01:30<01:04,  1.96it/s] 58%|█████▊    | 175/300 [01:31<01:04,  1.93it/s] 59%|█████▊    | 176/300 [01:31<01:04,  1.93it/s] 59%|█████▉    | 177/300 [01:32<01:03,  1.94it/s] 59%|█████▉    | 178/300 [01:32<01:02,  1.94it/s] 60%|█████▉    | 179/300 [01:33<01:01,  1.96it/s] 60%|██████    | 180/300 [01:33<01:01,  1.95it/s] 60%|██████    | 181/300 [01:34<01:00,  1.97it/s] 61%|██████    | 182/300 [01:34<00:59,  1.99it/s] 61%|██████    | 183/300 [01:35<00:58,  1.99it/s] 61%|██████▏   | 184/300 [01:35<00:57,  2.01it/s] 62%|██████▏   | 185/300 [01:36<00:56,  2.03it/s] 62%|██████▏   | 186/300 [01:36<00:56,  2.02it/s] 62%|██████▏   | 187/300 [01:37<00:55,  2.04it/s] 63%|██████▎   | 188/300 [01:37<00:55,  2.03it/s] 63%|██████▎   | 189/300 [01:38<00:54,  2.03it/s] 63%|██████▎   | 190/300 [01:38<00:54,  2.01it/s] 64%|██████▎   | 191/300 [01:39<00:54,  2.00it/s] 64%|██████▍   | 192/300 [01:39<00:54,  2.00it/s] 64%|██████▍   | 193/300 [01:40<00:53,  1.99it/s] 65%|██████▍   | 194/300 [01:40<00:52,  2.01it/s] 65%|██████▌   | 195/300 [01:41<00:52,  2.01it/s] 65%|██████▌   | 196/300 [01:41<00:51,  2.02it/s] 66%|██████▌   | 197/300 [01:42<00:50,  2.02it/s] 66%|██████▌   | 198/300 [01:42<00:50,  2.03it/s] 66%|██████▋   | 199/300 [01:43<00:49,  2.03it/s] 67%|██████▋   | 200/300 [01:43<00:49,  2.01it/s] 67%|██████▋   | 201/300 [01:44<00:49,  2.00it/s] 67%|██████▋   | 202/300 [01:44<00:49,  1.99it/s] 68%|██████▊   | 203/300 [01:45<00:48,  1.99it/s] 68%|██████▊   | 204/300 [01:45<00:47,  2.01it/s] 68%|██████▊   | 205/300 [01:46<00:47,  2.01it/s] 69%|██████▊   | 206/300 [01:46<00:46,  2.03it/s] 69%|██████▉   | 207/300 [01:46<00:45,  2.02it/s] 69%|██████▉   | 208/300 [01:47<00:45,  2.03it/s] 70%|██████▉   | 209/300 [01:48<00:45,  2.00it/s] 70%|███████   | 210/300 [01:48<00:47,  1.89it/s] 70%|███████   | 211/300 [01:49<00:52,  1.70it/s] 71%|███████   | 212/300 [01:49<00:50,  1.73it/s] 71%|███████   | 213/300 [01:50<00:49,  1.76it/s] 71%|███████▏  | 214/300 [01:50<00:48,  1.79it/s] 72%|███████▏  | 215/300 [01:51<00:46,  1.83it/s] 72%|███████▏  | 216/300 [01:52<00:45,  1.84it/s] 72%|███████▏  | 217/300 [01:52<00:44,  1.85it/s] 73%|███████▎  | 218/300 [01:53<00:44,  1.83it/s] 73%|███████▎  | 219/300 [01:53<00:43,  1.86it/s] 73%|███████▎  | 220/300 [01:54<00:42,  1.88it/s] 74%|███████▎  | 221/300 [01:54<00:41,  1.89it/s] 74%|███████▍  | 222/300 [01:55<00:40,  1.90it/s] 74%|███████▍  | 223/300 [01:55<00:40,  1.89it/s] 75%|███████▍  | 224/300 [01:56<00:40,  1.89it/s] 75%|███████▌  | 225/300 [01:56<00:41,  1.82it/s] 75%|███████▌  | 226/300 [01:57<00:40,  1.83it/s] 76%|███████▌  | 227/300 [01:57<00:39,  1.87it/s] 76%|███████▌  | 228/300 [01:58<00:37,  1.90it/s] 76%|███████▋  | 229/300 [01:58<00:37,  1.90it/s] 77%|███████▋  | 230/300 [01:59<00:36,  1.94it/s] 77%|███████▋  | 231/300 [01:59<00:34,  1.98it/s] 77%|███████▋  | 232/300 [02:00<00:34,  1.99it/s] 78%|███████▊  | 233/300 [02:00<00:33,  2.02it/s] 78%|███████▊  | 234/300 [02:01<00:32,  2.02it/s] 78%|███████▊  | 235/300 [02:01<00:32,  2.02it/s] 79%|███████▊  | 236/300 [02:02<00:31,  2.01it/s] 79%|███████▉  | 237/300 [02:02<00:31,  2.02it/s] 79%|███████▉  | 238/300 [02:03<00:30,  2.01it/s] 80%|███████▉  | 239/300 [02:03<00:30,  1.99it/s] 80%|████████  | 240/300 [02:04<00:30,  1.98it/s] 80%|████████  | 241/300 [02:04<00:30,  1.96it/s] 81%|████████  | 242/300 [02:05<00:29,  1.96it/s] 81%|████████  | 243/300 [02:05<00:28,  1.98it/s] 81%|████████▏ | 244/300 [02:06<00:28,  1.97it/s] 82%|████████▏ | 245/300 [02:06<00:27,  1.99it/s] 82%|████████▏ | 246/300 [02:07<00:27,  1.99it/s] 82%|████████▏ | 247/300 [02:07<00:26,  2.01it/s] 83%|████████▎ | 248/300 [02:08<00:26,  1.99it/s] 83%|████████▎ | 249/300 [02:08<00:25,  1.99it/s] 83%|████████▎ | 250/300 [02:09<00:24,  2.00it/s] 84%|████████▎ | 251/300 [02:09<00:24,  2.01it/s] 84%|████████▍ | 252/300 [02:10<00:23,  2.02it/s] 84%|████████▍ | 253/300 [02:10<00:23,  2.00it/s] 85%|████████▍ | 254/300 [02:11<00:23,  2.00it/s] 85%|████████▌ | 255/300 [02:11<00:22,  1.99it/s] 85%|████████▌ | 256/300 [02:12<00:22,  1.99it/s] 86%|████████▌ | 257/300 [02:12<00:21,  2.00it/s] 86%|████████▌ | 258/300 [02:13<00:20,  2.01it/s] 86%|████████▋ | 259/300 [02:13<00:20,  2.00it/s] 87%|████████▋ | 260/300 [02:14<00:19,  2.00it/s] 87%|████████▋ | 261/300 [02:14<00:19,  2.00it/s] 87%|████████▋ | 262/300 [02:15<00:19,  2.00it/s] 88%|████████▊ | 263/300 [02:15<00:18,  2.01it/s] 88%|████████▊ | 264/300 [02:16<00:18,  2.00it/s] 88%|████████▊ | 265/300 [02:16<00:17,  2.01it/s] 89%|████████▊ | 266/300 [02:17<00:16,  2.01it/s] 89%|████████▉ | 267/300 [02:17<00:16,  2.01it/s] 89%|████████▉ | 268/300 [02:18<00:15,  2.03it/s] 90%|████████▉ | 269/300 [02:18<00:15,  2.03it/s] 90%|█████████ | 270/300 [02:19<00:14,  2.04it/s] 90%|█████████ | 271/300 [02:19<00:14,  2.02it/s] 91%|█████████ | 272/300 [02:20<00:13,  2.01it/s] 91%|█████████ | 273/300 [02:20<00:13,  1.98it/s] 91%|█████████▏| 274/300 [02:21<00:13,  1.95it/s] 92%|█████████▏| 275/300 [02:21<00:12,  1.93it/s] 92%|█████████▏| 276/300 [02:22<00:12,  1.94it/s] 92%|█████████▏| 277/300 [02:22<00:11,  1.95it/s] 93%|█████████▎| 278/300 [02:23<00:11,  1.98it/s] 93%|█████████▎| 279/300 [02:23<00:10,  1.99it/s] 93%|█████████▎| 280/300 [02:24<00:10,  2.00it/s] 94%|█████████▎| 281/300 [02:24<00:09,  2.00it/s] 94%|█████████▍| 282/300 [02:25<00:09,  1.96it/s] 94%|█████████▍| 283/300 [02:25<00:08,  1.98it/s] 95%|█████████▍| 284/300 [02:26<00:08,  1.92it/s] 95%|█████████▌| 285/300 [02:27<00:07,  1.93it/s] 95%|█████████▌| 286/300 [02:27<00:07,  1.94it/s] 96%|█████████▌| 287/300 [02:28<00:06,  1.95it/s] 96%|█████████▌| 288/300 [02:28<00:06,  1.98it/s] 96%|█████████▋| 289/300 [02:29<00:05,  2.00it/s] 97%|█████████▋| 290/300 [02:29<00:04,  2.00it/s] 97%|█████████▋| 291/300 [02:30<00:04,  2.01it/s] 97%|█████████▋| 292/300 [02:30<00:04,  1.99it/s] 98%|█████████▊| 293/300 [02:31<00:03,  2.00it/s] 98%|█████████▊| 294/300 [02:31<00:03,  1.97it/s] 98%|█████████▊| 295/300 [02:32<00:02,  1.97it/s] 99%|█████████▊| 296/300 [02:32<00:02,  1.99it/s] 99%|█████████▉| 297/300 [02:33<00:01,  2.01it/s] 99%|█████████▉| 298/300 [02:33<00:00,  2.03it/s]100%|█████████▉| 299/300 [02:34<00:00,  1.89it/s]100%|██████████| 300/300 [02:34<00:00,  1.85it/s]100%|██████████| 300/300 [02:34<00:00,  1.94it/s]
W&B disabled.
W&B online. Running your script from this directory will now sync to the cloud.
wandb: Currently logged in as: hl57. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /media/techt/One Touch/DD/SRe2L/train/wandb/run-20231006_230456-tq0hoay6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-plasma-402
wandb: ⭐️ View project at https://wandb.ai/hl57/final_rn18_fkd
wandb: 🚀 View run at https://wandb.ai/hl57/final_rn18_fkd/runs/tq0hoay6
======= FKD: dataset info ======
path: ../relabel/FKD_cutmix_fp16/imagenette/235/
num img: 100
batch size: 100
max epoch: 300
================================
load data successfully
=> loading student model 'resnet18'

Epoch: 0
TRAIN Iter 0: lr = 0.001000,	loss = 0.016754,	Top-1 err = 90.000000,	Top-5 err = 51.000000,	train_time = 10.144856
TEST Iter 0: loss = 5.738621,	Top-1 err = 89.783439,	Top-5 err = 46.751592,	val_time = 12.518250

Epoch: 1

Epoch: 2

Epoch: 3

Epoch: 4

Epoch: 5

Epoch: 6

Epoch: 7

Epoch: 8

Epoch: 9

Epoch: 10
TRAIN Iter 10: lr = 0.000997,	loss = 0.015176,	Top-1 err = 66.000000,	Top-5 err = 13.000000,	train_time = 9.861375
TEST Iter 10: loss = 29.352807,	Top-1 err = 84.178344,	Top-5 err = 47.414013,	val_time = 12.176060

Epoch: 11

Epoch: 12

Epoch: 13

Epoch: 14

Epoch: 15

Epoch: 16

Epoch: 17

Epoch: 18

Epoch: 19

Epoch: 20
TRAIN Iter 20: lr = 0.000989,	loss = 0.010205,	Top-1 err = 87.000000,	Top-5 err = 46.000000,	train_time = 9.548891
TEST Iter 20: loss = 10.496188,	Top-1 err = 79.006369,	Top-5 err = 41.987261,	val_time = 12.123772

Epoch: 21

Epoch: 22

Epoch: 23

Epoch: 24

Epoch: 25

Epoch: 26

Epoch: 27

Epoch: 28

Epoch: 29

Epoch: 30
TRAIN Iter 30: lr = 0.000976,	loss = 0.007173,	Top-1 err = 28.000000,	Top-5 err = 3.000000,	train_time = 9.685318
TEST Iter 30: loss = 7.173710,	Top-1 err = 78.471338,	Top-5 err = 38.675159,	val_time = 11.911597

Epoch: 31

Epoch: 32

Epoch: 33

Epoch: 34

Epoch: 35

Epoch: 36

Epoch: 37

Epoch: 38

Epoch: 39

Epoch: 40
TRAIN Iter 40: lr = 0.000957,	loss = 0.006109,	Top-1 err = 45.000000,	Top-5 err = 8.000000,	train_time = 9.656040
TEST Iter 40: loss = 10.553723,	Top-1 err = 70.140127,	Top-5 err = 33.808917,	val_time = 11.894126

Epoch: 41

Epoch: 42

Epoch: 43

Epoch: 44

Epoch: 45

Epoch: 46

Epoch: 47

Epoch: 48

Epoch: 49

Epoch: 50
TRAIN Iter 50: lr = 0.000933,	loss = 0.005157,	Top-1 err = 25.000000,	Top-5 err = 3.000000,	train_time = 9.563143
TEST Iter 50: loss = 9.826612,	Top-1 err = 74.445860,	Top-5 err = 28.585987,	val_time = 12.005575

Epoch: 51

Epoch: 52

Epoch: 53

Epoch: 54

Epoch: 55

Epoch: 56

Epoch: 57

Epoch: 58

Epoch: 59

Epoch: 60
TRAIN Iter 60: lr = 0.000905,	loss = 0.004876,	Top-1 err = 59.000000,	Top-5 err = 8.000000,	train_time = 9.558140
TEST Iter 60: loss = 10.054773,	Top-1 err = 75.210191,	Top-5 err = 27.541401,	val_time = 12.064220

Epoch: 61

Epoch: 62

Epoch: 63

Epoch: 64

Epoch: 65

Epoch: 66

Epoch: 67

Epoch: 68

Epoch: 69

Epoch: 70
TRAIN Iter 70: lr = 0.000872,	loss = 0.005246,	Top-1 err = 85.000000,	Top-5 err = 30.000000,	train_time = 9.830332
TEST Iter 70: loss = 4.265758,	Top-1 err = 62.802548,	Top-5 err = 22.420382,	val_time = 12.223855

Epoch: 71

Epoch: 72

Epoch: 73

Epoch: 74

Epoch: 75

Epoch: 76

Epoch: 77

Epoch: 78

Epoch: 79

Epoch: 80
TRAIN Iter 80: lr = 0.000835,	loss = 0.004572,	Top-1 err = 38.000000,	Top-5 err = 5.000000,	train_time = 9.629216
TEST Iter 80: loss = 4.664209,	Top-1 err = 66.114650,	Top-5 err = 20.382166,	val_time = 13.789120

Epoch: 81

Epoch: 82

Epoch: 83

Epoch: 84

Epoch: 85

Epoch: 86

Epoch: 87

Epoch: 88

Epoch: 89

Epoch: 90
TRAIN Iter 90: lr = 0.000794,	loss = 0.003698,	Top-1 err = 11.000000,	Top-5 err = 2.000000,	train_time = 9.648364
TEST Iter 90: loss = 5.212034,	Top-1 err = 67.541401,	Top-5 err = 18.165605,	val_time = 12.098739

Epoch: 91

Epoch: 92

Epoch: 93

Epoch: 94

Epoch: 95

Epoch: 96

Epoch: 97

Epoch: 98

Epoch: 99

Epoch: 100
TRAIN Iter 100: lr = 0.000750,	loss = 0.003742,	Top-1 err = 5.000000,	Top-5 err = 0.000000,	train_time = 10.079296
TEST Iter 100: loss = 3.180860,	Top-1 err = 59.643312,	Top-5 err = 14.828025,	val_time = 11.991577

Epoch: 101

Epoch: 102

Epoch: 103

Epoch: 104

Epoch: 105

Epoch: 106

Epoch: 107

Epoch: 108

Epoch: 109

Epoch: 110
TRAIN Iter 110: lr = 0.000703,	loss = 0.004758,	Top-1 err = 16.000000,	Top-5 err = 1.000000,	train_time = 9.778418
TEST Iter 110: loss = 3.385576,	Top-1 err = 52.942675,	Top-5 err = 14.012739,	val_time = 12.090629

Epoch: 111

Epoch: 112

Epoch: 113

Epoch: 114

Epoch: 115

Epoch: 116

Epoch: 117

Epoch: 118

Epoch: 119

Epoch: 120
TRAIN Iter 120: lr = 0.000655,	loss = 0.003964,	Top-1 err = 58.000000,	Top-5 err = 2.000000,	train_time = 9.896503
TEST Iter 120: loss = 3.882926,	Top-1 err = 61.732484,	Top-5 err = 17.936306,	val_time = 12.133143

Epoch: 121

Epoch: 122

Epoch: 123

Epoch: 124

Epoch: 125

Epoch: 126

Epoch: 127

Epoch: 128

Epoch: 129

Epoch: 130
TRAIN Iter 130: lr = 0.000604,	loss = 0.004033,	Top-1 err = 48.000000,	Top-5 err = 5.000000,	train_time = 9.965985
TEST Iter 130: loss = 3.489766,	Top-1 err = 59.363057,	Top-5 err = 14.598726,	val_time = 12.149657

Epoch: 131

Epoch: 132

Epoch: 133

Epoch: 134

Epoch: 135

Epoch: 136

Epoch: 137

Epoch: 138

Epoch: 139

Epoch: 140
TRAIN Iter 140: lr = 0.000552,	loss = 0.003336,	Top-1 err = 9.000000,	Top-5 err = 1.000000,	train_time = 9.888531
TEST Iter 140: loss = 4.621263,	Top-1 err = 58.573248,	Top-5 err = 18.980892,	val_time = 12.031707

Epoch: 141

Epoch: 142

Epoch: 143

Epoch: 144

Epoch: 145

Epoch: 146

Epoch: 147

Epoch: 148

Epoch: 149

Epoch: 150
TRAIN Iter 150: lr = 0.000500,	loss = 0.003079,	Top-1 err = 33.000000,	Top-5 err = 1.000000,	train_time = 9.590363
TEST Iter 150: loss = 5.100318,	Top-1 err = 62.675159,	Top-5 err = 18.292994,	val_time = 12.020778

Epoch: 151

Epoch: 152

Epoch: 153

Epoch: 154

Epoch: 155

Epoch: 156

Epoch: 157

Epoch: 158

Epoch: 159

Epoch: 160
TRAIN Iter 160: lr = 0.000448,	loss = 0.002868,	Top-1 err = 81.000000,	Top-5 err = 13.000000,	train_time = 9.683862
TEST Iter 160: loss = 2.933578,	Top-1 err = 50.980892,	Top-5 err = 11.923567,	val_time = 12.205190

Epoch: 161

Epoch: 162

Epoch: 163

Epoch: 164

Epoch: 165

Epoch: 166

Epoch: 167

Epoch: 168

Epoch: 169

Epoch: 170
TRAIN Iter 170: lr = 0.000396,	loss = 0.003159,	Top-1 err = 43.000000,	Top-5 err = 1.000000,	train_time = 9.891440
TEST Iter 170: loss = 4.108855,	Top-1 err = 55.490446,	Top-5 err = 13.375796,	val_time = 12.124025

Epoch: 171

Epoch: 172

Epoch: 173

Epoch: 174

Epoch: 175

Epoch: 176

Epoch: 177

Epoch: 178

Epoch: 179

Epoch: 180
TRAIN Iter 180: lr = 0.000345,	loss = 0.002480,	Top-1 err = 16.000000,	Top-5 err = 2.000000,	train_time = 9.803792
TEST Iter 180: loss = 2.677265,	Top-1 err = 49.936306,	Top-5 err = 10.904459,	val_time = 12.192595

Epoch: 181

Epoch: 182

Epoch: 183

Epoch: 184

Epoch: 185

Epoch: 186

Epoch: 187

Epoch: 188

Epoch: 189

Epoch: 190
TRAIN Iter 190: lr = 0.000297,	loss = 0.003053,	Top-1 err = 19.000000,	Top-5 err = 1.000000,	train_time = 9.770438
TEST Iter 190: loss = 4.337620,	Top-1 err = 61.070064,	Top-5 err = 14.700637,	val_time = 12.179657

Epoch: 191

Epoch: 192

Epoch: 193

Epoch: 194

Epoch: 195

Epoch: 196

Epoch: 197

Epoch: 198

Epoch: 199

Epoch: 200
TRAIN Iter 200: lr = 0.000250,	loss = 0.002330,	Top-1 err = 79.000000,	Top-5 err = 10.000000,	train_time = 9.923122
TEST Iter 200: loss = 3.514137,	Top-1 err = 52.993631,	Top-5 err = 13.299363,	val_time = 12.026635

Epoch: 201

Epoch: 202

Epoch: 203

Epoch: 204

Epoch: 205

Epoch: 206

Epoch: 207

Epoch: 208

Epoch: 209

Epoch: 210
TRAIN Iter 210: lr = 0.000206,	loss = 0.002676,	Top-1 err = 21.000000,	Top-5 err = 1.000000,	train_time = 9.585183
TEST Iter 210: loss = 3.048069,	Top-1 err = 53.146497,	Top-5 err = 11.388535,	val_time = 12.217069

Epoch: 211

Epoch: 212

Epoch: 213

Epoch: 214

Epoch: 215

Epoch: 216

Epoch: 217

Epoch: 218

Epoch: 219

Epoch: 220
TRAIN Iter 220: lr = 0.000165,	loss = 0.002560,	Top-1 err = 5.000000,	Top-5 err = 0.000000,	train_time = 9.622424
TEST Iter 220: loss = 3.021242,	Top-1 err = 52.305732,	Top-5 err = 11.464968,	val_time = 12.132677

Epoch: 221

Epoch: 222

Epoch: 223

Epoch: 224

Epoch: 225

Epoch: 226

Epoch: 227

Epoch: 228

Epoch: 229

Epoch: 230
TRAIN Iter 230: lr = 0.000128,	loss = 0.002375,	Top-1 err = 66.000000,	Top-5 err = 8.000000,	train_time = 9.596775
TEST Iter 230: loss = 2.864074,	Top-1 err = 50.853503,	Top-5 err = 11.464968,	val_time = 12.049852

Epoch: 231

Epoch: 232

Epoch: 233

Epoch: 234

Epoch: 235

Epoch: 236

Epoch: 237

Epoch: 238

Epoch: 239

Epoch: 240
TRAIN Iter 240: lr = 0.000095,	loss = 0.002311,	Top-1 err = 86.000000,	Top-5 err = 15.000000,	train_time = 9.929049
TEST Iter 240: loss = 3.051876,	Top-1 err = 52.331210,	Top-5 err = 12.713376,	val_time = 12.268967

Epoch: 241

Epoch: 242

Epoch: 243

Epoch: 244

Epoch: 245

Epoch: 246

Epoch: 247

Epoch: 248

Epoch: 249

Epoch: 250
TRAIN Iter 250: lr = 0.000067,	loss = 0.002553,	Top-1 err = 49.000000,	Top-5 err = 2.000000,	train_time = 9.997006
TEST Iter 250: loss = 3.129735,	Top-1 err = 51.515924,	Top-5 err = 12.076433,	val_time = 12.161729

Epoch: 251

Epoch: 252

Epoch: 253

Epoch: 254

Epoch: 255

Epoch: 256

Epoch: 257

Epoch: 258

Epoch: 259

Epoch: 260
TRAIN Iter 260: lr = 0.000043,	loss = 0.002454,	Top-1 err = 52.000000,	Top-5 err = 3.000000,	train_time = 9.558686
TEST Iter 260: loss = 2.864748,	Top-1 err = 50.496815,	Top-5 err = 11.490446,	val_time = 12.056098

Epoch: 261

Epoch: 262

Epoch: 263

Epoch: 264

Epoch: 265

Epoch: 266

Epoch: 267

Epoch: 268

Epoch: 269

Epoch: 270
TRAIN Iter 270: lr = 0.000024,	loss = 0.002580,	Top-1 err = 53.000000,	Top-5 err = 5.000000,	train_time = 9.771813
TEST Iter 270: loss = 2.891531,	Top-1 err = 50.343949,	Top-5 err = 11.566879,	val_time = 12.095361

Epoch: 271

Epoch: 272

Epoch: 273

Epoch: 274

Epoch: 275

Epoch: 276

Epoch: 277

Epoch: 278

Epoch: 279

Epoch: 280
TRAIN Iter 280: lr = 0.000011,	loss = 0.002049,	Top-1 err = 9.000000,	Top-5 err = 0.000000,	train_time = 9.506139
TEST Iter 280: loss = 2.847445,	Top-1 err = 50.828025,	Top-5 err = 11.847134,	val_time = 12.065711

Epoch: 281

Epoch: 282

Epoch: 283

Epoch: 284

Epoch: 285

Epoch: 286

Epoch: 287

Epoch: 288

Epoch: 289

Epoch: 290
TRAIN Iter 290: lr = 0.000003,	loss = 0.002580,	Top-1 err = 3.000000,	Top-5 err = 0.000000,	train_time = 9.648108
TEST Iter 290: loss = 2.849460,	Top-1 err = 50.624204,	Top-5 err = 11.821656,	val_time = 12.042939

Epoch: 291

Epoch: 292

Epoch: 293

Epoch: 294

Epoch: 295

Epoch: 296

Epoch: 297

Epoch: 298

Epoch: 299
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  train/Top1 ▁▂▅▂▆▃▄▅▅▆▇▇▇█▆█▆█▃▇▆▁▇▆▆█▄▇▃█▁▂▂█▅▅█▇▁▅
wandb:  train/Top5 ▁▄▇▄█▇▇▇▇▇██████▇█▅██▅████▇█▇█▄▆▆█▇███▃█
wandb: train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  train/loss █▅█▅▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    train/lr ███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:   val/epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███
wandb:    val/loss ▂█▃▂▃▃▃▁▂▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    val/top1 ▁▂▃▃▄▄▄▆▅▅▆▇▆▆▆▆█▇█▆▇▇█████████
wandb:    val/top5 ▁▁▂▃▄▅▅▆▆▇▇▇▇▇▆▇███▇███████████
wandb: 
wandb: Run summary:
wandb:  train/Top1 58.0
wandb:  train/Top5 99.0
wandb: train/epoch 299
wandb:  train/loss 0.00236
wandb:    train/lr 0.0
wandb:   val/epoch 299
wandb:    val/loss 2.87988
wandb:    val/top1 49.65605
wandb:    val/top5 88.10191
wandb: 
wandb: 🚀 View run autumn-plasma-402 at: https://wandb.ai/hl57/final_rn18_fkd/runs/tq0hoay6
wandb: ️⚡ View job at https://wandb.ai/hl57/final_rn18_fkd/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjk3MzkyNjU3/version_details/v37
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231006_230456-tq0hoay6/logs
TEST Iter 299: loss = 2.879884,	Top-1 err = 50.343949,	Top-5 err = 11.898089,	val_time = 12.201473
