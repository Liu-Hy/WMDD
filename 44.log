(hl) ➜  SRe2L git:(39458fb) ✗ bash run.sh -x 301 -y 214 -d imagenette -u 0 -c 1 -r '/media/techt/DATA/data/' -n -w -b 10.0
Traceback (most recent call last):
  File "data_synthesis_new.py", line 11, in <module>
    import torch
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/__init__.py", line 1253, in <module>
    import torch.utils.data
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/__init__.py", line 20, in <module>
    from torch.utils.data.datapipes.datapipe import (
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/datapipes/__init__.py", line 1, in <module>
    from . import iter
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/__init__.py", line 1, in <module>
    from torch.utils.data.datapipes.iter.utils import (
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/utils.py", line 3, in <module>
    from torch.utils.data.datapipes.datapipe import IterDataPipe
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/datapipes/datapipe.py", line 7, in <module>
    from torch.utils.data.datapipes.utils.common import (
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/datapipes/utils/common.py", line 12, in <module>
    from torch.utils.data._utils.serialization import DILL_AVAILABLE
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/_utils/__init__.py", line 52, in <module>
    from . import worker, signal_handling, pin_memory, collate, fetch
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44
    class _MapDatasetFetcher(_BaseDatasetFetcher):
                                                 ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "generate_soft_label.py", line 7, in <module>
    import torch
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/__init__.py", line 1253, in <module>
    import torch.utils.data
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/__init__.py", line 20, in <module>
    from torch.utils.data.datapipes.datapipe import (
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/datapipes/__init__.py", line 1, in <module>
    from . import iter
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/__init__.py", line 1, in <module>
    from torch.utils.data.datapipes.iter.utils import (
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/utils.py", line 3, in <module>
    from torch.utils.data.datapipes.datapipe import IterDataPipe
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/datapipes/datapipe.py", line 7, in <module>
    from torch.utils.data.datapipes.utils.common import (
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/datapipes/utils/common.py", line 12, in <module>
    from torch.utils.data._utils.serialization import DILL_AVAILABLE
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/_utils/__init__.py", line 52, in <module>
    from . import worker, signal_handling, pin_memory, collate, fetch
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44
    class _MapDatasetFetcher(_BaseDatasetFetcher):
                                                 ^
IndentationError: unindent does not match any outer indentation level
Duration: 1 seconds and 95744217 nanoseconds.
Traceback (most recent call last):
  File "train_FKD.py", line 10, in <module>
    import torch
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/__init__.py", line 1253, in <module>
    import torch.utils.data
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/__init__.py", line 20, in <module>
    from torch.utils.data.datapipes.datapipe import (
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/datapipes/__init__.py", line 1, in <module>
    from . import iter
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/__init__.py", line 1, in <module>
    from torch.utils.data.datapipes.iter.utils import (
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/datapipes/iter/utils.py", line 3, in <module>
    from torch.utils.data.datapipes.datapipe import IterDataPipe
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/datapipes/datapipe.py", line 7, in <module>
    from torch.utils.data.datapipes.utils.common import (
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/datapipes/utils/common.py", line 12, in <module>
    from torch.utils.data._utils.serialization import DILL_AVAILABLE
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/_utils/__init__.py", line 52, in <module>
    from . import worker, signal_handling, pin_memory, collate, fetch
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44
    class _MapDatasetFetcher(_BaseDatasetFetcher):
                                                 ^
IndentationError: unindent does not match any outer indentation level
(hl) ➜  SRe2L git:(39458fb) ✗ bash run.sh -x b1 -y 214 -d imagenette -u 0 -c 1 -r '/media/techt/DATA/data/' -n -w -b 10.0
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
r_bn:  10.0
lr:  0.25
r_wb:  1.0
bc loaded
bc shape (10, 1, 512)
Traceback (most recent call last):
  File "data_synthesis_new.py", line 449, in <module>
    main_syn(args, bc, sample_weights)
NameError: name 'sample_weights' is not defined
=> using pytorch pre-trained model 'resnet18'
process data from ../recover/syn_data/imagenette/b1
Traceback (most recent call last):
  File "generate_soft_label.py", line 255, in <module>
    main()
  File "generate_soft_label.py", line 126, in main
    main_worker(args.gpu, ngpus_per_node, args)
  File "generate_soft_label.py", line 201, in main_worker
    train_dataset = ImageFolder_FKD_MIX(
  File "/media/techt/One Touch/DD/SRe2L/relabel/utils_fkd.py", line 155, in __init__
    super(ImageFolder_FKD_MIX, self).__init__(**kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 309, in __init__
    super().__init__(
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 144, in __init__
    classes, class_to_idx = self.find_classes(self.root)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 218, in find_classes
    return find_classes(directory)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 42, in find_classes
    raise FileNotFoundError(f"Couldn't find any class folder in {directory}.")
FileNotFoundError: Couldn't find any class folder in ../recover/syn_data/imagenette/b1.
Duration: 4 seconds and 237741831 nanoseconds.
Traceback (most recent call last):
  File "train_FKD.py", line 379, in <module>
    main()
  File "train_FKD.py", line 105, in main
    train_dataset = ImageFolder_FKD_MIX(
  File "/media/techt/One Touch/DD/SRe2L/train/../relabel/utils_fkd.py", line 155, in __init__
    super(ImageFolder_FKD_MIX, self).__init__(**kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 309, in __init__
    super().__init__(
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 144, in __init__
    classes, class_to_idx = self.find_classes(self.root)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 218, in find_classes
    return find_classes(directory)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 42, in find_classes
    raise FileNotFoundError(f"Couldn't find any class folder in {directory}.")
FileNotFoundError: Couldn't find any class folder in ../recover/syn_data/imagenette/b1.
(hl) ➜  SRe2L git:(39458fb) ✗ bash run.sh -x b1 -y 214 -d imagenette -u 0 -c 1 -r '/media/techt/DATA/data/' -n -w -b 10.0
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
r_bn:  10.0
lr:  0.25
r_wb:  1.0
Computing sample features for class 0
[1.0]
Computing sample features for class 1
[1.0]
Computing sample features for class 2
[1.0]
Computing sample features for class 3
[1.0]
Computing sample features for class 4
[1.0]
Computing sample features for class 5
[1.0]
Computing sample features for class 6
[1.0]
Computing sample features for class 7
[1.0]
Computing sample features for class 8
[1.0]
Computing sample features for class 9
[1.0]
Barycenter compute time: 0.04346942901611328
bc shape (10, 1, 512)
Computing BatchNorm statistics for class 0
Computing BatchNorm statistics for class 1
Computing BatchNorm statistics for class 2
Computing BatchNorm statistics for class 3
Computing BatchNorm statistics for class 4
Computing BatchNorm statistics for class 5
Computing BatchNorm statistics for class 6
Computing BatchNorm statistics for class 7
Computing BatchNorm statistics for class 8
Computing BatchNorm statistics for class 9
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
get_images call
class_per_batch  10 batch_size  100 args.ipc  1
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Traceback (most recent call last):
  File "data_synthesis_new.py", line 450, in <module>
    main_syn(args, bc, sample_weights)
  File "data_synthesis_new.py", line 342, in main_syn
    get_images(args, model_teacher, hook_for_display, bc=bc, weights=weights)
  File "data_synthesis_new.py", line 153, in get_images
    outputs = model_teacher(inputs_jit)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/techt/One Touch/DD/SRe2L/recover/../models/resnet.py", line 207, in forward
    x = self.bn1(x, labels=labels)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1547, in _call_impl
    hook_result = hook(self, args, result)
  File "/media/techt/One Touch/DD/SRe2L/recover/utils.py", line 157, in hook_fn
    weights_reshaped = class_weights.view(num_cls, self.ipc, 1, 1, 1).to(input[0].device)
TypeError: view() takes from 0 to 2 positional arguments but 5 were given
=> using pytorch pre-trained model 'resnet18'
process data from ../recover/syn_data/imagenette/b1
Traceback (most recent call last):
  File "generate_soft_label.py", line 255, in <module>
    main()
  File "generate_soft_label.py", line 126, in main
    main_worker(args.gpu, ngpus_per_node, args)
  File "generate_soft_label.py", line 201, in main_worker
    train_dataset = ImageFolder_FKD_MIX(
  File "/media/techt/One Touch/DD/SRe2L/relabel/utils_fkd.py", line 155, in __init__
    super(ImageFolder_FKD_MIX, self).__init__(**kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 309, in __init__
    super().__init__(
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 144, in __init__
    classes, class_to_idx = self.find_classes(self.root)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 218, in find_classes
    return find_classes(directory)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 42, in find_classes
    raise FileNotFoundError(f"Couldn't find any class folder in {directory}.")
FileNotFoundError: Couldn't find any class folder in ../recover/syn_data/imagenette/b1.
Duration: 34 seconds and 675550267 nanoseconds.
Traceback (most recent call last):
  File "train_FKD.py", line 379, in <module>
    main()
  File "train_FKD.py", line 105, in main
    train_dataset = ImageFolder_FKD_MIX(
  File "/media/techt/One Touch/DD/SRe2L/train/../relabel/utils_fkd.py", line 155, in __init__
    super(ImageFolder_FKD_MIX, self).__init__(**kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 309, in __init__
    super().__init__(
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 144, in __init__
    classes, class_to_idx = self.find_classes(self.root)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 218, in find_classes
    return find_classes(directory)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 42, in find_classes
    raise FileNotFoundError(f"Couldn't find any class folder in {directory}.")
FileNotFoundError: Couldn't find any class folder in ../recover/syn_data/imagenette/b1.
(hl) ➜  SRe2L git:(39458fb) ✗ bash run.sh -x 302 -y 214 -d imagenette -u 0 -c 1 -r '/media/techt/DATA/data/' -n -w -b 10.0
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
r_bn:  10.0
lr:  0.25
r_wb:  1.0
bc and weights loaded
bc shape (10, 1, 512)
Computing BatchNorm statistics for class 0
Computing BatchNorm statistics for class 1
Computing BatchNorm statistics for class 2
Computing BatchNorm statistics for class 3
Computing BatchNorm statistics for class 4
Computing BatchNorm statistics for class 5
Computing BatchNorm statistics for class 6
Computing BatchNorm statistics for class 7
Computing BatchNorm statistics for class 8
Computing BatchNorm statistics for class 9
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
get_images call
class_per_batch  10 batch_size  100 args.ipc  1
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Traceback (most recent call last):
  File "data_synthesis_new.py", line 450, in <module>
    main_syn(args, bc, sample_weights)
  File "data_synthesis_new.py", line 342, in main_syn
    get_images(args, model_teacher, hook_for_display, bc=bc, weights=weights)
  File "data_synthesis_new.py", line 153, in get_images
    outputs = model_teacher(inputs_jit)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/techt/One Touch/DD/SRe2L/recover/../models/resnet.py", line 207, in forward
    x = self.bn1(x, labels=labels)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1547, in _call_impl
    hook_result = hook(self, args, result)
  File "/media/techt/One Touch/DD/SRe2L/recover/utils.py", line 157, in hook_fn
    weights_reshaped = class_weights.view(num_cls, self.ipc, 1, 1, 1).to(input[0].device)
TypeError: view() takes from 0 to 2 positional arguments but 5 were given
=> using pytorch pre-trained model 'resnet18'
process data from ../recover/syn_data/imagenette/302
Traceback (most recent call last):
  File "generate_soft_label.py", line 255, in <module>
    main()
  File "generate_soft_label.py", line 126, in main
    main_worker(args.gpu, ngpus_per_node, args)
  File "generate_soft_label.py", line 201, in main_worker
    train_dataset = ImageFolder_FKD_MIX(
  File "/media/techt/One Touch/DD/SRe2L/relabel/utils_fkd.py", line 155, in __init__
    super(ImageFolder_FKD_MIX, self).__init__(**kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 309, in __init__
    super().__init__(
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 144, in __init__
    classes, class_to_idx = self.find_classes(self.root)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 218, in find_classes
    return find_classes(directory)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 42, in find_classes
    raise FileNotFoundError(f"Couldn't find any class folder in {directory}.")
FileNotFoundError: Couldn't find any class folder in ../recover/syn_data/imagenette/302.
Duration: 20 seconds and 681679956 nanoseconds.
Traceback (most recent call last):
  File "train_FKD.py", line 379, in <module>
    main()
  File "train_FKD.py", line 105, in main
    train_dataset = ImageFolder_FKD_MIX(
  File "/media/techt/One Touch/DD/SRe2L/train/../relabel/utils_fkd.py", line 155, in __init__
    super(ImageFolder_FKD_MIX, self).__init__(**kwargs)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 309, in __init__
    super().__init__(
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 144, in __init__
    classes, class_to_idx = self.find_classes(self.root)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 218, in find_classes
    return find_classes(directory)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 42, in find_classes
    raise FileNotFoundError(f"Couldn't find any class folder in {directory}.")
FileNotFoundError: Couldn't find any class folder in ../recover/syn_data/imagenette/302.
(hl) ➜  SRe2L git:(39458fb) ✗ bash run.sh -x 303 -y 214 -d imagenette -u 0 -c 1 -r '/media/techt/DATA/data/' -n -w -b 10.0
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
r_bn:  10.0
lr:  0.25
r_wb:  1.0
bc and weights loaded
bc shape (10, 1, 512)
Computing BatchNorm statistics for class 0
Computing BatchNorm statistics for class 1
Computing BatchNorm statistics for class 2
Computing BatchNorm statistics for class 3
Computing BatchNorm statistics for class 4
Computing BatchNorm statistics for class 5
Computing BatchNorm statistics for class 6
Computing BatchNorm statistics for class 7
Computing BatchNorm statistics for class 8
Computing BatchNorm statistics for class 9
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
get_images call
class_per_batch  10 batch_size  100 args.ipc  1
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
------------iteration 0----------
total loss 9613.764813893298
main criterion 63.688478515614115
weighted_aux_loss 9550.076335377684
loss_r_bn_feature 955.0076335377684
------------iteration 100----------
total loss 3255.3329654361014
main criterion 62.92541413896166
weighted_aux_loss 3192.40755129714
loss_r_bn_feature 319.240755129714
Each iteration takes 0.022082189522167242 +- 0.003745975234951149 seconds.
------------iteration 200----------
total loss 2686.200704985113
main criterion 63.57613237802952
weighted_aux_loss 2622.624572607084
loss_r_bn_feature 262.2624572607084
Each iteration takes 0.021505317877774214 +- 0.0028652558275790462 seconds.
------------iteration 300----------
total loss 3221.607534181657
main criterion 62.12811552086297
weighted_aux_loss 3159.4794186607937
loss_r_bn_feature 315.94794186607936
Each iteration takes 0.02109786600765596 +- 0.0024732325387618235 seconds.
------------iteration 400----------
total loss 2658.4280129414074
main criterion 63.46481294580483
weighted_aux_loss 2594.9631999956027
loss_r_bn_feature 259.4963199995603
Each iteration takes 0.021035911436390105 +- 0.0021787116923508228 seconds.
------------iteration 500----------
total loss 2506.2888814941657
main criterion 63.513922454564344
weighted_aux_loss 2442.7749590396015
loss_r_bn_feature 244.27749590396013
Each iteration takes 0.021083441085206295 +- 0.001970974866179635 seconds.
------------iteration 600----------
total loss 2916.7684966869265
main criterion 63.502147051266334
weighted_aux_loss 2853.26634963566
loss_r_bn_feature 285.326634963566
Each iteration takes 0.021114313265249852 +- 0.0018282858487081697 seconds.
------------iteration 700----------
total loss 2626.173235954077
main criterion 62.32738227287419
weighted_aux_loss 2563.8458536812027
loss_r_bn_feature 256.38458536812027
Each iteration takes 0.021183808417871233 +- 0.001762686293925244 seconds.
------------iteration 800----------
total loss 4251.951058722884
main criterion 62.0106024476408
weighted_aux_loss 4189.940456275243
loss_r_bn_feature 418.9940456275243
Each iteration takes 0.021185460906201384 +- 0.0016609331820079032 seconds.
------------iteration 900----------
total loss 2280.145471821373
main criterion 63.4856712634624
weighted_aux_loss 2216.659800557911
loss_r_bn_feature 221.66598005579107
Each iteration takes 0.02119717878453872 +- 0.001581917840677041 seconds.
------------iteration 1000----------
total loss 2362.8257993186853
main criterion 64.21361772881687
weighted_aux_loss 2298.6121815898687
loss_r_bn_feature 229.86121815898684
Each iteration takes 0.021194115742579563 +- 0.0015145781113196427 seconds.
------------iteration 1100----------
total loss 2097.827909930862
main criterion 62.579699086922034
weighted_aux_loss 2035.2482108439401
loss_r_bn_feature 203.524821084394
Each iteration takes 0.02119244390135998 +- 0.001458199600458122 seconds.
------------iteration 1200----------
total loss 4390.3832889683
main criterion 62.45461812857375
weighted_aux_loss 4327.928670839726
loss_r_bn_feature 432.79286708397257
Each iteration takes 0.021193698482846936 +- 0.0014071592379059342 seconds.
------------iteration 1300----------
total loss 1942.3749093295157
main criterion 62.37826736375364
weighted_aux_loss 1879.9966419657621
loss_r_bn_feature 187.99966419657622
Each iteration takes 0.02119891465763969 +- 0.0013661709949920897 seconds.
------------iteration 1400----------
total loss 1627.435580838866
main criterion 62.52054033725928
weighted_aux_loss 1564.9150405016067
loss_r_bn_feature 156.49150405016067
Each iteration takes 0.021200071650688178 +- 0.0013314765123280212 seconds.
------------iteration 1500----------
total loss 1686.6675276721978
main criterion 62.44587012013443
weighted_aux_loss 1624.2216575520633
loss_r_bn_feature 162.42216575520632
Each iteration takes 0.021193959568437937 +- 0.001296157124875346 seconds.
------------iteration 1600----------
total loss 3401.9803610452946
main criterion 61.30842638871411
weighted_aux_loss 3340.6719346565806
loss_r_bn_feature 334.0671934656581
Each iteration takes 0.021197225212082872 +- 0.0012661983147191588 seconds.
------------iteration 1700----------
total loss 1427.0759200220643
main criterion 62.23224262215636
weighted_aux_loss 1364.843677399908
loss_r_bn_feature 136.4843677399908
Each iteration takes 0.02119915223275823 +- 0.0012373491642513924 seconds.
------------iteration 1800----------
total loss 2478.844492091643
main criterion 61.33574845783768
weighted_aux_loss 2417.5087436338054
loss_r_bn_feature 241.75087436338052
Each iteration takes 0.021197356891790937 +- 0.001211138385054624 seconds.
------------iteration 1900----------
total loss 3100.6626760148392
main criterion 60.44986528635647
weighted_aux_loss 3040.212810728483
loss_r_bn_feature 304.0212810728483
Each iteration takes 0.02119766217291449 +- 0.0011920391997534653 seconds.
Peak GPU Memory Usage: 0.8738374710083008 GB
=> using pytorch pre-trained model 'resnet18'
process data from ../recover/syn_data/imagenette/303
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:39<00:00,  3.02it/s]
Duration: 162 seconds and 376388735 nanoseconds.
======= FKD: dataset info ======
path: ../relabel/FKD_cutmix_fp16/imagenette/303/
num img: 10
batch size: 10
max epoch: 300
================================
load data successfully
=> loading student model 'resnet18'
Traceback (most recent call last):
  File "train_FKD.py", line 379, in <module>
    main()
  File "train_FKD.py", line 199, in main
    train(model, args, epoch)
  File "train_FKD.py", line 237, in train
    for batch_idx, batch_data in enumerate(args.train_loader):
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
    return self._process_data(data)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/_utils.py", line 644, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 48, in fetch
    mix_index, mix_lam, mix_bbox, soft_label, weight = self.dataset.load_batch_config(possibly_batched_index[0])
ValueError: not enough values to unpack (expected 5, got 4)

Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 63457) is killed by signal: Terminated.
(hl) ➜  SRe2L git:(39458fb) ✗ bash run.sh -x 304 -y 214 -d imagenette -u 0 -c 1 -r '/media/techt/DATA/data/' -n -w -b 10.0
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
r_bn:  10.0
lr:  0.25
r_wb:  1.0
bc and weights loaded
bc shape (10, 1, 512)
Computing BatchNorm statistics for class 0
Computing BatchNorm statistics for class 1
Computing BatchNorm statistics for class 2
Computing BatchNorm statistics for class 3
Computing BatchNorm statistics for class 4
Computing BatchNorm statistics for class 5
Computing BatchNorm statistics for class 6
Computing BatchNorm statistics for class 7
Computing BatchNorm statistics for class 8
Computing BatchNorm statistics for class 9
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
get_images call
class_per_batch  10 batch_size  100 args.ipc  1
/home/techt/anaconda3/envs/hl/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
------------iteration 0----------
total loss 10639.761822847742
main criterion 62.0764920524844
weighted_aux_loss 10577.685330795257
loss_r_bn_feature 1057.7685330795257
------------iteration 100----------
total loss 3852.534672394973
main criterion 62.686531248047146
weighted_aux_loss 3789.8481411469256
loss_r_bn_feature 378.98481411469254
Each iteration takes 0.02435357971946792 +- 0.004020359298925603 seconds.
------------iteration 200----------
total loss 2833.9193115250646
main criterion 62.38372581104152
weighted_aux_loss 2771.535585714023
loss_r_bn_feature 277.1535585714023
Each iteration takes 0.023018111043901585 +- 0.0033557483134039985 seconds.
------------iteration 300----------
total loss 2880.853716588328
main criterion 63.8134821314772
weighted_aux_loss 2817.040234456851
loss_r_bn_feature 281.7040234456851
Each iteration takes 0.02246422149810284 +- 0.0028948426999620743 seconds.
------------iteration 400----------
total loss 4709.415570236421
main criterion 61.45065571439647
weighted_aux_loss 4647.964914522025
loss_r_bn_feature 464.7964914522024
Each iteration takes 0.022157198175825087 +- 0.0025878270886777193 seconds.
------------iteration 500----------
total loss 2408.0939987040697
main criterion 62.51303869964661
weighted_aux_loss 2345.580960004423
loss_r_bn_feature 234.55809600044233
Each iteration takes 0.021957420303436097 +- 0.002380026280169905 seconds.
------------iteration 600----------
total loss 2816.810752962545
main criterion 63.83222767284897
weighted_aux_loss 2752.978525289696
loss_r_bn_feature 275.2978525289696
Each iteration takes 0.02183839961415321 +- 0.0022085917539957775 seconds.
------------iteration 700----------
total loss 3541.4689476584376
main criterion 60.939551156282064
weighted_aux_loss 3480.5293965021556
loss_r_bn_feature 348.05293965021554
Each iteration takes 0.021745079424173787 +- 0.0020773162691370473 seconds.
------------iteration 800----------
total loss 2372.1067013463594
main criterion 62.91041568838464
weighted_aux_loss 2309.196285657975
loss_r_bn_feature 230.9196285657975
Each iteration takes 0.02167503247397967 +- 0.001965498726078726 seconds.
------------iteration 900----------
total loss 2968.5333731339265
main criterion 61.08196987963816
weighted_aux_loss 2907.4514032542884
loss_r_bn_feature 290.74514032542885
Each iteration takes 0.021629813508638133 +- 0.0018808808847694276 seconds.
------------iteration 1000----------
total loss 2069.430549189002
main criterion 63.09322154492191
weighted_aux_loss 2006.33732764408
loss_r_bn_feature 200.633732764408
Each iteration takes 0.021613256557361706 +- 0.001822001018954401 seconds.
------------iteration 1100----------
total loss 1916.5530634755364
main criterion 62.441523082112845
weighted_aux_loss 1854.1115403934236
loss_r_bn_feature 185.41115403934236
Each iteration takes 0.021591558118607107 +- 0.0017628074873745076 seconds.
------------iteration 1200----------
total loss 2563.409942157485
main criterion 61.418266654804306
weighted_aux_loss 2501.9916755026807
loss_r_bn_feature 250.19916755026804
Each iteration takes 0.021568716019019794 +- 0.0017053661527238145 seconds.
------------iteration 1300----------
total loss 1780.8865275695437
main criterion 62.82290637974181
weighted_aux_loss 1718.0636211898018
loss_r_bn_feature 171.8063621189802
Each iteration takes 0.02154779910674744 +- 0.001648561449279457 seconds.
------------iteration 1400----------
total loss 2209.170063221975
main criterion 62.101629981607296
weighted_aux_loss 2147.0684332403675
loss_r_bn_feature 214.70684332403675
Each iteration takes 0.021531474666881358 +- 0.0016009370995615105 seconds.
------------iteration 1500----------
total loss 2232.800535847333
main criterion 61.32380949363414
weighted_aux_loss 2171.4767263536987
loss_r_bn_feature 217.14767263536987
Each iteration takes 0.021516872198878725 +- 0.0015584290063165218 seconds.
------------iteration 1600----------
total loss 1688.1547926503904
main criterion 62.86387479687852
weighted_aux_loss 1625.290917853512
loss_r_bn_feature 162.5290917853512
Each iteration takes 0.021506004077356207 +- 0.0015240895460335976 seconds.
------------iteration 1700----------
total loss 1377.2154424235378
main criterion 62.16156592766988
weighted_aux_loss 1315.0538764958678
loss_r_bn_feature 131.5053876495868
Each iteration takes 0.021495488024963344 +- 0.0014863149823081305 seconds.
------------iteration 1800----------
total loss 1633.185474632593
main criterion 62.19447745506265
weighted_aux_loss 1570.9909971775303
loss_r_bn_feature 157.09909971775303
Each iteration takes 0.021516249088497044 +- 0.0014790581819767912 seconds.
------------iteration 1900----------
total loss 2372.003274703879
main criterion 61.94189687536113
weighted_aux_loss 2310.061377828518
loss_r_bn_feature 231.0061377828518
Each iteration takes 0.021508194533603434 +- 0.0014551311891495967 seconds.
Peak GPU Memory Usage: 0.8738374710083008 GB
=> using pytorch pre-trained model 'resnet18'
process data from ../recover/syn_data/imagenette/304
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:39<00:00,  3.02it/s]
Duration: 162 seconds and 484246218 nanoseconds.
======= FKD: dataset info ======
path: ../relabel/FKD_cutmix_fp16/imagenette/304/
num img: 10
batch size: 10
max epoch: 300
================================
load data successfully
=> loading student model 'resnet18'
TRAIN Iter 0: lr = 0.001000,    loss = 0.016475,        Top-1 acc = 10.000000,  Top-5 acc = 50.000000,  train_time = 3.167428
TEST Iter 0: loss = 8.106975,   Top-1 acc = 9.910828,   Top-5 acc = 48.738854,  val_time = 15.135056
TRAIN Iter 10: lr = 0.000997,   loss = 0.017233,        Top-1 acc = 20.000000,  Top-5 acc = 80.000000,  train_time = 2.100742
TEST Iter 10: loss = 8.810354,  Top-1 acc = 18.369427,  Top-5 acc = 61.401274,  val_time = 15.779058
